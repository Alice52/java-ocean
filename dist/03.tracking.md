[toc]

## overview

1. 理论基础: 谷歌的 dapper 论文
2. 相关技术

   - opentelemetry: 追踪相关标准
   - skywalking: k8s 云原生相关
   - jaeger: k8s 云原生相关
   - mdc + sls: best practice
   - sleuth + zipkin

3. 监控+追踪的实现: 侵入 | 非侵入

4. practice: sls + `mdc || jeager || sleuth`

   - traceid
   - spanid
   - parent_spanid
   - startime/endtime

<!--
1. 方法采集只能是 pubic 的非 static, 非 abstract, 非 native
2. 采用**通配符**或正则表达式
   - \*: 表示一个或多个任意字符
   - ?:表示单个字符
   - &: 分割多个匹配语句
     -->

## tracking

1. 链路追踪的好处

   - 方便**长链路(串行|并行)**(微服务|异构)下的问题排查: 在分布式系统(微服务下), 一次外部请求往往需要内部多个模块, 多个中间件, 多台机器的相互调用才能完成
   - 相关的数据统计分析:
     1. 拓扑分析: 链路|时空调用, 离群分析、循环依赖检测
     2. 流量分析: qps, **time cost**, **http response**, network, api success/fail count 等
     3. 错误分析
     4. 告警通知: sls(error_type & error_type) 实现自定义通知
     5. 性能分析: 根据流量分析得到慢在哪里 | 链路优化(某个服务慢就加服务器等)

2. 核⼼思想: 应用侧(生成传播上报) + server 侧(收集存储展示分析)

   - 在⽤户⼀次完整的分布式调⽤过程中: `将一次分布式请求还原成调用链路(时间+服务)`
   - 将请求在所有⼦系统间的**调⽤过程**和**时空关系**追踪记录下来, 还原成调⽤链路集中展示
   - 信息包括各个服务节点上的**耗时**、请求具体到达哪台**机器**上、每个服务节点的**请求状态**等等

     ![avatar](/static/image/dist/tracking.png)
     ![avatar](/static/image/dist/tracking-dashboard.png)

3. concept

   - trace: traceid

     1. ⼀次(分布式)请求经过的所有局部操作(Span)构成的⼀条完整的**有向⽆环图**

   - span: spanid

     2. ⼀次(分布式)请求过程的⼀个步骤或操作, 代表系统中⼀个**逻辑运⾏单元**, span 之间通过嵌套或者顺序排列建⽴因果关系
     3. name: 操作名称, 用于展示过滤聚合, 如⼀个 rpc 名| 函数名
     4. **starttime/endtime**: 起始时间和结束时间, 操作的⽣命周期, _kv 组成的 Tags_
     5. **parentspanid**: ⽗级 span 的 id
     6. **spancontext**:
        - span 上下⽂内容, 通常⽤于在 span 间传播, 其核⼼字段包括 traceid, **spanid**
        - baggage items: 通用的跨进程/服务传递数据的方式(kv)
     7. attributes: 属性, ⼀组<k,v>键值对构成的集合
     8. event: 操作期间发⽣的事件

   - span 间的两种关系

     9. ChildOf: 父子关系, 父操作在一定程度上依赖于子操作(子操作都完成之后父操作才会完成)
     10. FollowsFrom: 父子关系, 子操作仅仅由父操作触发

     ![avatar](/static/image/dist/tracking-span-call.png)
     ![avatar](/static/image/dist/tracking-span-time.png)

   - span 状态: 一个线程里面可以包含多个 span, 但同一时刻只能有一个 span 处于工作状态

     1. Started
     2. Not Finished
     3. Not Active
     4. **Active Span**: 工作状态下的 span, 状态由 ScopeManager 管理, 但是否实现由开发者决定
     5. 另外 OpenTracing 定义了 Inject 和 Extract 接口来简化 SpanContext 跨进程传递

4. 一般架构: 围绕 Span 的**⽣成**、**传播**、采集(上报)、处理、**存储**、**可视化**、分析, 构建分布式链路追踪系统

   1. ⽣成 Span: 操作开始构建 Span 并填充 StartTime, 操作完成时填充 EndTime 信息, 期间可追加 Attributes、Event 等
   2. 传播 Span: 进程内通过 context.Context | 进程间通过请求的 **header** 作为 SpanContext 的载体
   3. 上报 Span: ⽣成的 Span 通过 tracing **exporter** 发送给 collect agent / back-end server

   ![avatar](/static/image/dist/tracking-artch.png)

5. 实现思路

   - 侵入式: 硬编码 || `通过切面拦截 + 装饰者模式对相关接口进行包装 + 使用包装接口`
   - 非侵入式: 编译阶段/静态织⼊ || 启动阶段/动态织⼊(asm | bytebuddy | javaassist)

     ![avatar](/static/image/dist/tracking-artch-impl.png)

   - 相关要解决的难点

     1. traceid|spanid 唯一性的保证及性能
     2. span 等信息的传播: 线程间 | 进程间
     3. 相关数据的上报: 异步 | 网络通信 | 序列化(数据压缩) | 安全可靠 | io | 高可用 | 存储
     4. 非侵入实现, 易用性, 请求量对应用性能的影响

## mdc 实现: Mapped Diagnostic(调试) Context

1. intros

   - 本质: 内部是 ThreadLocal
   - 代码简洁, 日志风格统一: 不需要手动写 traceid

2. api

   - clear() => 移除所有 MDC
   - get(String key) => 获取当前线程 MDC 中指定 key 的值
   - getContext() => 获取当前线程 MDC 的 MDC
   - put(String key, Object o) => 往当前线程的 MDC 中存入指定的键值对
   - remove(String key) => 删除当前线程 MDC 中指定的键值对

3. 将请求 Id 放入 MDC: HandlerInterceptor

   ```java
   class LogInterceptor implements HandlerInterceptor {
       @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
           MDC.put(Constants.TRACE_ID, traceId);
           return true;
       }

       @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { MDC.remove(Constants.TRACE_ID); }
   }

   // logback.xml
   <property name="pattern">[TRACEID:%X{traceId}] %d{HH:mm:ss.SSS} %-5level %class{-1}.%M()/%L - %msg%xEx%n</property>
   ```

4. traceid 传播相关实现

   - 异步线程

     ```java
     class MdcTaskDecorator implements TaskDecorator {
         @Override public Runnable decorate(Runnable runnable) {
             Map<String, String> context = MDC.getCopyOfContextMap();
             return () -> {
                 Map<String, String> previous = MDC.getCopyOfContextMap();
                 if (context == null)  MDC.clear();
                 else MDC.setContextMap(context);

                 try { runnable.run(); } finally {
                     if (previous == null) MDC.clear();
                     else MDC.setContextMap(previous);
                 }
             };
         }
     }

     executor.setTaskDecorator(new MdcTaskDecorator());
     ```

   - rpc & http 调用

     1. HttpClient

        ```java
        public class HttpClientTraceIdInterceptor implements HttpRequestInterceptor {
            @Override public void process(HttpRequest httpRequest, HttpContext httpContext) { xxx}
        }

        CloseableHttpClient httpClient = HttpClientBuilder.create().addInterceptorFirst(new HttpClientTraceIdInterceptor()).build();
        ```

     2. OKHttp

        ```java
        class OkHttpTraceIdInterceptor implements Interceptor {
            @Override public Response intercept(Chain chain) throws IOException {
                String traceId = MDC.get(Constants.TRACE_ID);
                Request request = null;
                if (traceId != null)  request = chain.request().newBuilder().addHeader(Constants.TRACE_ID, traceId).build();
                return chain.proceed(request);
            }
        }

        OkHttpClient client = new OkHttpClient.Builder().addNetworkInterceptor(new OkHttpTraceIdInterceptor()).build();
        ```

     3. RestTemplate

        ```java
        class RestTemplateTraceIdInterceptor implements ClientHttpRequestInterceptor {
            @Override public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] bytes, ClientHttpRequestExecution clientHttpRequestExecution)  {
                String traceId = MDC.get(Constants.TRACE_ID);
                if (traceId != null) httpRequest.getHeaders().add(Constants.TRACE_ID, traceId);

                return clientHttpRequestExecution.execute(httpRequest, bytes);
            }
        }

        restTemplate.setInterceptors(Arrays.asList(new RestTemplateTraceIdInterceptor()));
        ```

     4. feign
        ```java
        public class FeignInterceptor implements RequestInterceptor {
            @Override public void apply(RequestTemplate requestTemplate) {
                requestTemplate.header(TRACE_ID, (String) MDC.get(Constants.TRACE_ID));
            }
        }
        ```

   - 定时任务
   - _mq 相关_

---

## [framework](https://blog.csdn.net/CSDNwzl/article/details/120961529)

### [~~opentracing+opencensus~~=**opentelemetry**](https://opentelemetry.io/): 云原生基金会的**跨语言**的链路追踪**标准**

![avatar](/static/image/dist/tracking-otel.png)

1. 分布式跟踪(concept): 统一的、可扩展的、无侵入式、高可用的跟踪标准(**标准化 Trace 数据结构和格式=可以切换应用侧实现(不同实现间交互)+更换后端产品**)
   - 插件机制: OpenTelemetry SDK 通过插件机制支持多种后端存储和分析工具, 如 Jaeger、Zipkin 和 Prometheus 等
   - 开发人员可以根据需要选择相应的插件, 并将数据发送到相应的后端系统进行存储和分析
   - go sdk 实现调⽤链拦截的基本思路是: 基于 AOP 的思想, 采⽤装饰器模式, 通过包装替换⽬标包(如 net/http)的核⼼接⼝或组件, 实现在核⼼调⽤过程前后添加 Span 相关逻辑; 具有侵⼊性(需要手动替换原接口为包装接口)
   - 是相关标准接口定义: 与 jdbc | slf4j 类似
2. 性能指标收集: 收集应用指标, 如 CPU 使用率、内存使用量、网络流量和响应时间等
3. 日志记录: 收集应用日志, 且与其他追踪和指标数据关联
4. 自动仪器化: 使用代理或其他方式在低耦合下实现追踪和指标收集, 且实时查询

### **jeager**: uber 开源的链路追踪系统(go 实现), 实现应用侧+server 侧

1. jaeger diagram

   ![avatar](/static/image/dist/tracking-jaeger.png)

2. 应用侧实现(java)是各种拦截器 + reporter

   - 满足 opentelemetry 的链路追踪相关规范
   - 只关注于链路追踪(定位明确): 没有太多涉及性能指标等监控
   - 因为本质是拦截器: 功能没有 skywalking 等直接修改字节码相关的功能强大和灵活(可以监控到很底层) || 反而性能没有多少影响

3. 对 k8s 云原生支持比较友好 + 生态好(支持的语言和集成的工具)

### sleuth(应用侧)+zipkin(server 侧): twitter 开源的链路追踪系统(java 实现)

![avatar](/static/image/dist/tracking-sleth.jpg)

![avatar](/static/image/dist/tracking-zipkin-sluth.png)

1. dependency

   ```xml
   <!-- 负责span的产生传播 -->
   <dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-starter-sleuth</artifactId>
   </dependency>
   <!-- 负责span的上报: 这里会引入 zipkin-reporte[-brave] 的相关实现 -->
   <dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-sleuth-zipkin</artifactId>
   </dependency>
   ```

2. zipkin: client(配置上报地址+消息上报) + server

   - 存储: In-Memory、MySQL、Cassandra 以及 **Elasticsearch**

   ![avatar](/static/image/dist/tracking-zipkin.jpg)

3. sleuth: 是对 brave 的封装扩展

   - brave 提供 span、tracer 产生与传播
   - zipkin-reporter[-brave]: spanreporter(发送数据到 zipkin-server)
   - sleuth 是对上两种的整合, 且提供采样规则、spring cloud 进行集成等功能
   - brave & sleuth 关系:
     1. sleuth 使用的是 brave 的实现, 但是 sleuth 并不一定要依赖 brave 来实现, 完全可以使用其他分布式跟踪系统(span, tracer, reporter)实现
     2. 而 brave(各种 inteceptor+span 产生传播~~上报~~) 也可以独立于 sleuth 使用

4. pratice

   - 需要服务: zipkin-server | nacos-discovery
   - mic-a 和 mic-b 两个微服务:
     1. 需要 zipkin-client 用于配置 zipkin-server 上报的地址和消息格式及具体上报操作
     2. 需要 sleuth 用于生成 span 相关信息及传递: 一旦有服务间调用, 则会被配置的 Sleuth 的监听器监听(生成 Trace 和 Span 信息发送给服务端)
     3. 上报方式有两种: http | **rabbitmq**

### [skywalking](https://www.bilibili.com/video/BV1Zs4y1w7w1): Apache 开源的链路追踪系统(java 实现)

1. skywalking 相关的功能

   - 应用程序性能监测: 指标分析(实例+请求) + 跨度分析(堆栈/方法/sql/异常)
   - 分布式链路追踪
   - 警和预警功能
   - 自动仪器化: 可视化界面

2. 实现核心原理: 基于插件机制(可插拔)的 agent(bytebuddy 修改字节码)自动化埋点

   - 本质还是 javaagent 机制的 hack: 修改字节码后加载进 jvm

3. traceId | spanid 的唯一

   - 雪花 Id: **本地**生成 ID
   - 时钟回拨问题: 上一次生成 Id 的时间大于当前时间则生成一个随机数作为 traceid(**避免过度设计**)
   - 机器标识及数据分布: 10bit 的机器 Id

   ![avatar](/static/image/dist/tracking-skywalking-traceid.png)

4. 跨进程传递: 在 header 中传递 context
5. 自动采集 span 数据: 异步采集上报

   - **插件化 + javaagent** 的形式来实现了 span 数据的自动采集: **修改字节码的方式**
   - 插件化意味着可插拔, 扩展性好(支持多语言), 且**无侵入性**

     ![avatar](/static/image/dist/tracking-skywalking.png)

6. 请求量与应用性能(好于 zipkin 和 pinpoint): 设置采样频率(最上游有是否要采样标识), 默认 定时任务 3s 采样 3 次

   ![avatar](/static/image/dist/tracking-skywalking-performance.png)
   ![avatar](/static/image/dist/tracking-skywalking-performance2.png)

### ~~pinpoint~~

1. 使用 java 实现, 实现原理基于 angent

---

## reference

1. [java-agent](/java/se/v2/agent/agent.md)
