<!--
 该笔记形成于阅读 `MySQL 实战 45 讲`
-->

## MySQL 45 Docs

### 1. MySQL Server 结构

1. Connectors: _用户的权限在次就确定了, 所以修改后需要重新连接才有效_
2. Service: SQL Interface, 连接器, 查询缓存, 分析器, 优化器, 执行器
3. Engines: `插件式`
4. Store

### 2. SQL 查询流程

1. Client
2. Connectors

   - `show processlist` 可以看到所有的连接信息, 默认 `wait_timeout` 8 小时后断开
   - 但是全部使用长连接后, 有些时候 MySQL 占用内存涨得特别快: 是因为 `MySQL 在执行过程中临时使用的内存是管理在连接对象里面的`, 这些资源会在连接断开的时候才释放
   - solution: 执行占用内存的大查询后断开连接或者执行 `mysql_reset_connection` 来重新初始化连接资源[这个过程不需要重连和重新做权限验证]

3. ~~Cache~~

   - 缓存失效时针对表的, 不建议使用
   - sql_no_cache/sql_cache

4. Parser: 让 MySQL 知道做什么

   - `select SQL_CACHE * from T where ID=10;`
   - 词法分析: MySQL 从你输入的 "select" 这个关键字识别出来, 这是一个查询语, 它也要把字符串 T 识别成表名 T , 把字符串 ID 识别成 列 ID
   - 语法分析: 是否满足 MySQL 语法

5. Optimizer: MySQL 决定怎么做

   - 优化器是在表里面有多个索引的时候, 决定使用哪个索引;
   - 或者在一个语句有多表关联的时候, 决定各个表的连接顺序
   - ...

6. Executor: 做事情

   - 判断有无表操作的权限
   - 打开表执行器会根据表的引擎定义, 去使用这个引擎提供的接口获取数据
   - 比如 `4` 的 SQL 且 ID 字段没有索引, 执行器的执行流程
     1. 调用 InnoDB 引擎接口取这个表的第一行, 判断 ID 值是不是 10, 如果不是则跳过, 如果是则将这行存在结果集中;
     2. 调用引擎接口取下一行 , 重复相同的判断逻辑, 直到取到这个表的最后一行
     3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端

   ![avatar](/static/image/db/mysql-sql-execute-flow.png)

### 3. SQL 更新流程

1. Client
2. Connectors
3. ~~Cache~~: 使该表的缓存全部失效
4. Parser: 分析器会通过词法和语法解析知道这是一条更新语句
5. Optimizer: 优化器决定要使用 ID 这个索引
6. Executor: 执行器负责具体执行, 找到这一行, 然后更新
7. Engines:

   - 执行器先`找引擎取` ID=2 这一行: ID 是主键, 引擎直接用树搜索找到这一行, 如果 ID=2 这一行所在的数据页本来就在内存中, 就直接`返回给执行器`; 否则, 需要先从磁盘读入内存, 然后再返回
   - `执行器`拿到引擎给的行数据, 把这个值`加上 1`, 比如原来是 N , 现在就是 N+1 , 得到新的一行数据, 再`调用引擎接口写入这行新数据`
   - `引擎`将这行新数据`更新到内存`中, 同时将这个更新操作`记录到 redo log 里面`, 此时 **redo log 处于 prepare 状态**, 然后`告知执行器执行完成了`, 随时可以提交事务
   - **执行器生成这个操作的 binlog , 并把 binlog 写入磁盘**
   - **执行器调用引擎的提交事务接口, 引擎把刚刚写入的 redo log 改成提交 commit 状态, 更新完成**

8. 与查询流程不一样的是, 更新流程还涉及两个重要的日志模块: `redo log 和 binlog`

   - redo log: `innodb` 中是一快可`重复利用`的`顺序读写`的`固定大小`的`磁盘空间`, 是一种 `Write-Ahead Logging[先写日志]`, `物理日志`[数据页上的修改]

     ![avatar](/static/image/db/mysql-wal.png)

     - write pos 是当前记录的位置, 一边写一边后移, 写到第 3 号文件末尾后就回到 0 号文件开头
     - checkpoint 是当前要擦除的位置, 擦除记录前要把记录更新到数据文件
     - write pos 和 checkpoint 之间的是空着的部分, 可以用来记录新的操作.
     - `如果 write pos 追上 checkpoint, 这时候不能再执行新的更新`, 得停下来等待 checkpoint 推进

   - binlog: service 层的归档日志, 可选择性打开的逻辑日志[记录语句逻辑], 多用于 SM, 无限空间, 追加记录
     - sync_binlog

   ![avatar](/static/image/db/mysql-update-flow.png)

9. crash-safe: 有了 redo log , InnoDB 就可以保证即使数据库发生异常重启, 之前提交的记录都不会丢失
10. `简单说, redo log 和 binlog 都可以用于表示事务的提交状态, 而两阶段提交就是让这两个状态保持逻辑上的一致`

### 3-2 二阶段提交

1. flow

   - 如果 redo log 里面的事务是完整的, 也就是已经有了 commit 标识, 则直接提交
   - 如果 redo log 里面的事务只有完整的 prepare, 则判断对应的事务 binlog 是否存在并完整
     - 如果是, 则提交事务
     - 否则, 回滚事务

2. MySQL 怎么知道 binlog 是完整的

   - statement 格式的 binlog, 最后会有 COMMIT
   - **row 格式的 binlog, 最后会有一个 XID event**

3. redo log 和 binlog 是怎么关联起来的

   - 它们有一个共同的数据字段, 叫 XID
   - 崩溃恢复的时候, 会按顺序扫描 redo log
   - 如果碰到既有 prepare 又有 commit 的 redo log, 就直接提交
   - 如果碰到只有 parepare, 而没有 commit 的 redo log, 就拿着 XID 去 binlog 找对应的事务

4. 处于 prepare 阶段的 redo log 加上完整 binlog, 重启就能恢复, MySQL 为什么要这么设计?

   - 数据与备份的一致性有关
   - 也就是 binlog 写完以后 MySQL 发生崩溃, 这时候 binlog 已经写入了, 之后就会被从库使用
   - 所以, 在主库上也要提交这个事务
   - 采用这个策略, 主库和备库的数据就保证了一致性

5. 为很么不直接写 redo-log 之后再接着写 bin-log

   - 两阶段提交是经典的分布式系统问题
   - 对于 InnoDB 引擎来说, 如果 redo log 提交完成了, 事务就不能回滚{如果这还允许回滚, 就可能覆盖掉别的事务的更新}
   - 而如果 redo log 直接提交, 然后 binlog 写入的时候失败, InnoDB 又回滚不了, 数据和 binlog 日志又不一致了

6. redo log & buffer pool & 落盘

   - redo log 并没有记录数据页的完整数据
   - 如果是正常运行的实例的话, 数据页被修改以后, 跟磁盘的数据页不一致, 称为脏页. 最终数据落盘, 就是把内存中的数据页写盘, 这个过程甚至与 redo log 毫无关系
   - 在崩溃恢复场景中, InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新, 就会将它读到内存, 然后让 redo log 更新内存内容. 更新完成后, 内存页变成脏页, 就回到了第一种情况的状态

7. redo log buffer 是什么

   - 在一个事务的更新过程中，日志是要写多次的

   ```sql
   begin;
   -- 会先插入 redo log buffer
   insert into t1 ...
   insert into t2 ...
   -- 写入 redo-log
   commit;
   ```

### 4. 恢复到指定的时刻的数据

1. 找到最近的一次全量备份, 从这个备份恢复到临时库
2. 从备份的时间点开始, 将备份的 binlog 依次取出来, 重放到指定时刻

### 5. redo-log 日志需要两阶段提交

1. 存储引擎更新数据时会更新内存数据且写 redo log, 并设置为 prepare 阶段
2. 之后会告诉执行器, 执行完成, 执行器会写 bin-log
3. 之后执行器会调用存储引擎提交事务接口, 引擎把刚刚写入的 redo log 改成提交 commit 状态
4. 此时更新操作就算结束, 后续会将 redo log 的内容持久化的磁盘

5. why？

   - 由于 redo log 和 binlog 是两个独立的逻辑
   - `先写 redo log 后写 binlog`: 假设在 redo log 写完, binlog 还没有写完的时候, MySQL 进程异常重启. 由于我们前面说过的, redo log 写完之后, 系统即使崩溃, 仍然能够把数据恢复回来, 所以恢复后这一行的值是 1 . 但是由于 binlog 没写完就 crash 了, 这时候 binlog 里面就没有记录这个语句. 因此, 之后备日志的时候, 存起来的 binlog 里面就没有这条语句. 然后你会发现, 如果需要用这个 binlog 来恢复临时库的话, 由于这个语句的 binlog 丢失, 这个临时库就会少了这一次更新, 恢复出来的这一行 c 的值就是 0 , 与原库的值不同.
   - `先写 binlog 后写 redo log`: 如果在 binlog 写完之后 crash, 由于 redo log 还没写, 崩溃恢复以后这个事务无效, 所以这一行 c 的值是 0. 但是 binlog 里面已经记录了 _把 c 从 0 改成 1_ 这个日志. 所以, 在之后用 binlog 来恢复的时候就多了一个事务出来, 恢复出来的这一行 c 的值就是 1 , 与原库的值不同.

### 6. 强数据一致性相关参数设置

1. `bin-log: sync_binlog`

   - 1[默认值]每次事务提交都调用 fysnc
   - 0 则每次事务提交只是 write 到 page cache, 没有立即调用 fsync
   - N 表示第 N 个事务时才调用 fsync

2. `redo-log: innodb_flush_log_at_trx_commit`

   - 1: 每次事务的 redo log 都直接持久化到磁盘
   - 0: 表示写入 innodb 的 logbuffer, 每秒调用一次 fsync 刷入磁盘
   - 3: 表示直接写入 OS buffer, 每秒调用 fsync 刷入磁盘

### 7. 可重复读的场景

1. 假设你在管理一个个人银行账户表, 一个表存了每个月月底的余额, 一个表存了账单明细
2. 这时候你要做数据校对, 也就是判断上个月的余额和当前余额的差额, 是否与本月的账单明细一致
3. 你一定希望在校对过程中, 即使有用户发生了一笔新的交易, 也不影响你的校对结果
4. 这时候使用 可重复读 隔离级别就很方便

### 8. 可重复读的实现: `mvcc+undo-log`

1. 在 MySQL 中, 实际上每条记录在更新的时候都会同时记录一条回滚操作
2. 记录上的最新值, 通过回滚操作, 都可以得到前一个状态的值
3. 假设一个值从 1 被按顺序改成了 2、3、4, 在回滚

   ![avatar](/static/image/db/mysql-isolation-rr.png)

4. 当前值是 4, 但是在查询这条记录的时候, 不同时刻启动的事务会有不同的 read-view

   - 如图中看到的, 在视图 A, B, C 里面, 这一个记录的值分别是 1, 2, 4,
   - 同一条记录在系统中可以存在多个版本, 就是数据库的多版本并发控制(MVCC)
   - 对于 read-view A , 要得到 1, 就必须将当前值依次执行图中所有的回滚操作得到

5. 即使现在有另外一个事务正在将 4 改成 5, 这个事务跟 read-view A, B, C 对应的事务是不会冲突的

6. 当没有事务再需要用到这些回滚日志时, 回滚日志会被删除
   - `当系统里没有比这个回滚日志更早的 read-view 的时候`

### 9. 长事务问题

1. 长事务意味着系统里面会存在很老的事务视图

   - 由于这些事务随时可能访问数据库里面的任何数据, 所以这个事务提交之前
   - 数据库里面它可能用到回滚记录都必须保留, 这就会导致大量占用存储空间

2. MySQL 5.5 之前回滚日志是跟数据字典一起放在 ibdata 文件里的, 会导致其很大很大
3. 长事务还占用锁资源

### 10. 页分裂&合并

1. 页分裂: 如果所在的数据页已经满了, 根据 B+ 树的算法, 这时候需要申请一个新的数据页, ~~然后

   - 性能自然会受影响
   - 页分裂操作还影响数据页的利用率: 原本放在一个页的数据, 现在分到两个页中

2. 当相邻两个页由于删除了数据, 利用率很低之后, 会将数据页做合并

### 11. 用业务字段直接做主键

1. 只有一个索引: 由于没有其他索引, 所以也就不用考虑其他索引的叶子节点大小的问题
2. 该索引必须是唯一索引: 典型的 KV 场景

### 12. 非聚簇索引的查询过程

```sql
create table T (
   ID int primary key,
   k int NOT NULL DEFAULT 0,
   s varchar(16) NOT NULL DEFAULT '',
   index k(k)
) engine=InnoDB;

insert into T values(100, 1,  'aa'), (200, 2, 'bb'), (300, 3, 'cc'), (500, 5, 'ee'), (600, 6, 'ff'), (700, 7, 'gg');

-- execute flow
select * from T where k between 3 and 5
```

1. 在 k 索引树上找到 k=3 的记录, 取得 ID = 300
2. 再到 ID 索引树查到 ID=300 对应的 R3
3. 在 k 索引树取下一个值 k=5 , 取得 ID=500
4. 再回到 ID 索引树查到 ID=500 对应的 R4
5. 在 k 索引树取下一个值 k=6 , 不满足条件, 循环结束.

   ![avatar](/static/image/db/mysql-index-query.png)

6. `select ID from T where k between 3 and 5`:

   - 在引擎内部使用覆盖索引在索引 k 上其实读了三个记录
   - R3~R5[对应的索引 k 上的记录项], 但是对于 MySQL 的 Server 层来说, 它就是找引擎拿到了两条记录, 因此 MySQL 认为扫描行数是 2

### 13. 索引

```sql
CREATE TABLE `tuser` (
   `id` int(11) NOT NULL,
   `id_card` varchar(32) DEFAULT NULL,
   `name` varchar(32) DEFAULT NULL,
   `age` int(11) DEFAULT NULL,
   `ismale` tinyint(1) DEFAULT NULL,
   PRIMARY KEY (`id`),
   KEY `id_card` (`id_card`),
   KEY `name_age` (`name`,`age`)
) ENGINE=InnoDB
```

![avatar](/static/image/db/mysql-index-practice.png)

1. 覆盖索引
2. 联合索引

   - 第一原则是, 如果通过调整顺序, 可以少维护一个索引, 那么这个顺序往往就是需要优先考虑采用的
   - 考虑的原则就是空间

3. 回表
4. 最左前缀原则
5. 索引下推

   ```sql
   -- 以市民表的联合索引[name, age]
   -- 检索出表中名字第一个字是张, 而且年龄是10岁的所有男孩
   -- name 会用到索引
   select * from tuser where name like '张%' and age=10 and ismale=1;
   ```

   - MySQL 5.6 之前, 只能从 ID3 开始一个个回表: `到主键索引上找出数据行, 再对比字段值`
   - MySQL 5.6 引入的`索引下推优化[index condition pushdown], 可以在索引遍历过程中, 对索引中包含的字段先做判断, 直接过滤掉不满足条件的记录, 减少回表次数`

   ![avatar](/static/image/db/mysql-index-practice-down.png)
   ![avatar](/static/image/db/mysql-index-practice-down-v5.5.png)

### 14. 索引分析案例

```sql
CREATE TABLE `geek` (
   `a` int(11) NOT NULL,
   `b` int(11) NOT NULL,
   `c` int(11) NOT NULL,
   `d` int(11) NOT NULL,
   PRIMARY KEY (`a`,`b`),
   KEY `c` (`c`),
   KEY `ca` (`c`,`a`),
   KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
```

1. 由于历史原因, 这个表需要 a, b 做联合主键, 所以 `index(a, b)`
2. ~~所以 `index(c, a)` for `select * from geek where c=N order by a limit 1;`?~~： this is no use.
3. 所以 `index(c, b)` for `select * from geek where c=N order by b limit 1;`?
4. 分析索引

   - `index(a, b)`:

     |  a  |  b  |  c  |  d  |
     | :-: | :-: | :-: | :-: |
     |  1  |  2  |  3  |  d  |
     |  1  |  3  |  2  |  d  |
     |  1  |  4  |  3  |  d  |
     |  2  |  1  |  3  |  d  |
     |  2  |  2  |  2  |  d  |
     |  2  |  3  |  4  |  d  |

   - `index(c)`: `same as index(c, a)`

     |  c  |  a  |  b  |
     | :-: | :-: | :-: |
     |  2  |  1  |  3  |
     |  2  |  2  |  2  |
     |  3  |  1  |  2  |
     |  3  |  1  |  4  |
     |  3  |  2  |  1  |
     |  4  |  2  |  3  |

   - ~~`index(c, a)`~~: `same as index(c)`

     |  c  |  a  |  b  |
     | :-: | :-: | :-: |
     |  2  |  1  |  3  |
     |  2  |  2  |  2  |
     |  3  |  1  |  2  |
     |  3  |  1  |  4  |
     |  3  |  2  |  1  |
     |  4  |  2  |  3  |

   - `index(c, b)`

     |  c  |  a  |  b  |
     | :-: | :-: | :-: |
     |  2  |  2  |  2  |
     |  2  |  3  |  1  |
     |  3  |  1  |  2  |
     |  3  |  2  |  1  |
     |  3  |  4  |  1  |
     |  4  |  3  |  2  |

### 15. 重建索引

1. 索引可能因为删除, 或者页分裂等原因, 导致数据页有空洞
2. 重建索引的过程会创建一个新的索引, 把数据按顺序插入, 这样页面的利用率最高, 也就是索引更紧凑、更省空间

### 16. 全局锁

1. 全局读锁~~`Flush tables with read lock (FTWRL)`~~: 典型使用场景做全库逻辑备份`mysqldump`
2. **优先使用:** `mysqldump single-transaction` 方法只适用于所有的表使用事务引擎的库

   - 导数据之前就会启动一个事务, 来确保拿到一致性视图
   - 而由于 MVCC 的支持, 这个过程中数据是可以正常更新的
   - `如果有的表使用了不支持事务的引擎, 那么备份就只能通过 FTWRL 方法`
   - FTWRL 命令之后由于客户端发生异常断开, 那么 MySQL 会自动释放这个全局锁, 整个库回到可以正常更新的状态

3. 表加字段操作, 都是会被锁住的: 全局锁

### 17. 表级别的锁: `lock tables … read/write unlock tables`

1. 分类

   - 表锁
   - 元数据锁

2. 元数据锁

   - 在 MySQL 5.5 版本中引入了 MDL, 当对一个表做增删改查操作的时候, 加 MDL 读锁
   - 要对表做结构变更操作的时候, 加 MDL 写锁

3. MDL 锁导致一个小表加个字段, 导致整个库挂了

   ![avatar](/static/image/db/mysql-lock-dml.png)

4. **如何安全地给小表加字段**

   - 首先我们要解决长事务, 事务不提交, 就会一直占着 MDL 锁
   - 在 MySQL 的 information_schema 库的 innodb_trx 表中可以查到当前执行中的事务
   - 如果你要做 DDL 变更的表刚好有长事务在执行, 要考虑先暂停 DDL, 或者 kill 掉这个长事务
   - 但如果要变更的表是一个热点表, 虽然数据量不大, 但是上面的请求很频繁

     - 这时候 kill 可能未必管用, 因为新的请求马上就来了
     - 比较理想的机制是, 在 alter table 语句里面设定等待时间, 如果在这个指定的等待时间里面能够拿到 MDL 写锁最好, 拿不到也不要阻塞后面的业务语句, 先放弃
     - 之后开发人员或者 DBA 再通过重试命令重复这个过程

     ```sql
     -- MariaDB 和 AliSQL 有这样的功能
     ALTER TABLE tbl_name NOWAIT add column ...
     ALTER TABLE tbl_name WAIT N add column ...
     ```

### 18.行锁

1. 两阶段锁协议: 行锁是在需要的时候才加上, 但并不是不需要了就立刻释放, 而是要等到事务结束时才释放
2. **如果你的事务中需要锁多个行, 要把最可能造成锁冲突, 最可能影响并发度的锁尽量往后放**
   - 顾客 A 要在影院 B 购买电影票: `从顾客A账户余额中扣除电影票价 + 给影院B的账户余额增加这张电影票价 + 记录一条交易日志`
   - 如果同时有另外一个顾客 C 要在影院 B 买票, 那么这两个事务冲突的部分就是语句 2 了, 按照 3、1、2 这样的顺序提升了并发度
3. CPU 消耗接近 100%, 整个数据库每秒就执行不到 100 个事务, 是由 死锁和死锁检测 到最后的
4. 死锁: `并发系统`中`不同线程`出现`循环资源依赖`, 涉及的线程都在`等待`别的线程`释放资源`时, 就会导致这几个线程都进入`无限等待`的状态, 称为**死锁**

   ![avatar](/static/image/db/mysql-dead-lock.webp)

   - 直接进入等待, 直到超时: 参数 **innodb_lock_wait_timeout** 来设置 50s
   - 发起死锁检测, 发现死锁后, 主动回滚死锁链条中的某一个事务, 让其他事务得以继续执行: 参数 **innodb_deadlock_detect** 设置为 on
   - 1000 个并发同时更新同一行, 死锁检测操作就是 100 万这个量级`[看它所依赖的线程有没有被别人锁住, 最后判断是否出现了循环等待]`
   - 死锁 CPU 消耗: 临时把死锁检测: 出现超时是业务有损的
   - 死锁 CPU 消耗: 控制并发度[服务端{相同行的更新在进入引擎之前排队}]
   - 死锁 CPU 消耗: 将一行改成逻辑上的多行来减少锁冲突

### 19.mvvc

1. 用于支持 RC 和 RR 隔离级别的实现
2. 事务在启动的时候就 `拍了个快照`: 基于整库的, 并不是物理上的快照, 是基于数据 row 的唯一的`事务ID{严格递增}`
3. 数据表中的一行记录, 其实可能有多个版本(row), 每个版本有自己的 row trx_id, 同时旧的数据版本可以根据新版本 + **undo_log** 得到
4. V1、V2、V3 并不是物理上真实存在的, 而是每次需要的时候根据当前版本和 undo log 计算出来的
   ![avatar](/static/image/db/mysql-mvcc.png)

5. 一个事务在启动时声明: 以我启动的时刻为准, 如果一个数据版本是在我启动之前生成的则可见; 如果是我启动以后才生成的则不可见, 必须要找到它的上一个版本

   - 只要修改就会产生新的版本快照: 最新的版本快照就会变
     ![avatar](/static/image/db/mysql-mvcc-flow.png)
     ![avatar](/static/image/db/mysql-update-node.png)

6. 更新数据都是先读后写的, 只能读当前已提交的值, 称为 "当前读"[current read], 避免之前的写丢失
7. `查找创建版本⼩于或等于当前事务版本, ~~删除版本为空或者⼤于当前事务版本~~`

### 20.唯一索引的使用 & 普通索引

1. 查询过程

   - 在索引树上查找, B+树从树根开始, 按层搜索到叶子节点: `数据页内部通过二分法来定位记录`
   - 普通索引: 查找到满足条件的第一个记录后, 需要查找下一个记录直到碰到第一个不满足 k=5 条件的记录
   - 唯一索引: 索引定义了唯一性, 查找到第一个满足条件的记录后, 就会停止继续检索
   - **但是两者之间几乎没有太大的性能差距**:
     1. InnoDB 的数据是按数据页为单位来读写的: `默认是16KB{一个数据页可以放近千个long的key}`
     2. 当需要读一条记录的时候, 并不是将这个记录本身从磁盘读出来, 而是以页为单位, 将其整体读入内存
     3. 所以都是读取一次数据页到内存, 之后的查找判断是很快的: 除非有大于 16K 的数据才会多次加载数据页

2. 更新过程: **change buffer**{插入一个新记录(4,400)}

   - 该记录对应的**目标页**在内存中
     1. 对于唯一索引来说, 找到 3 和 5 之间的位置, 判断到没有冲突, 插入这个值, 语句执行结束: redo-log + bin-log
     2. 对于普通索引来说, 找到 3 和 5 之间的位置, 插入这个值, 语句执行结束: redo-log + bin-log
   - 该记录对应的**目标页**不在内存中
     1. 对于唯一索引来说, **需要将数据页读入内存{随机读}**, 判断到没有冲突, 插入这个值, 语句执行结束: redo-log + bin-log
     2. 对于普通索引来说, 则是将更新记录在 change buffer{可以新开辟}, 语句执行就结束: **redo-log{记录的是插入一行}** + bin-log
   - 之后的查找
     ![avatar](/static/image/db/mysql-change-buffer-read.png)

3. 唯一索引可以保证业务的数据唯一性
   - **可以转换为逻辑判断**{做不到则就只能使用唯一索引}
   - 但是会导致 内存命中率{更新操作} 下降
   - "归档库"的场景, 可以考虑使用唯一索引的

### 21.change buffer: `可以持久化的数据` + `只有普通索引可以使用`

1. 当需要更新一个数据页时, 如果数据页在内存中就直接更新: 之后就是 redo_log, bin_log 的二阶段提交

2. 当不在内存中的话, 在**不影响数据一致性的前提**下, InooDB 会将更新操作缓存在 change buffer 中, 这样就不需要从磁盘中读入这个数据页
3. 查询时需要访问这个数据页的时候: 将数据页读入内存, 然后执行 change buffer 中与这个页有关的操作 `[merge]`
4. **merge: 将 change buffer 中的操作应用到原数据页, 得到最新结果**
   - 在事务提交的时候, 把 change buffer 的操作也记录到 redo log 里
   - merge: 从磁盘读入数据页到内存[老版本的数据页]
   - merge: 从 change buffer 里找出这个数据页的 change buffer 记录, 依次应用, 得到新版数据页
   - merge: 写 redo log, 这个 redo log 包含了数据的变更和 change buffer 的变更
5. merge 时机: 访问该数据页, 系统后台线程定期 merge, 数据库正常关闭
6. change buffer 的好处:

   - 将更新操作先记录在 change buffer, 减少读磁盘, 语句的执行速度会得到明显的提升
   - 数据读入内存是需要占用 buffer pool 的, 所以这种方式还能够避免占用内存, 提高内存利用率

7. 唯一索引的更新操作都要先判断这个操作是否违反唯一性约束: 就需要将数据也读取到内存判断, 所以不能使用 change buffer
8. change buffer 用的是 buffer pool 里的内存: innodb_change_buffer_max_size 占 bp 的比例
9. 适合的场景: 写多读少, 比如账单类、日志类的系统
10. 写入之后马上会做查询:
    - 将更新先记录在 change buffer
    - 但之后由于马上要访问这个数据页, 会立即触发 merge 过程
    - 这样随机访问 IO 的次数不会减少`{读取到内存才能更新}`, 反而增加了 change buffer 的维护代价
11. redo log & change buffer

    - redo log 主要节省的是随机写磁盘的 IO 消耗[转成顺序写]
    - 而 change buffer 主要节省的则是随机读磁盘的 IO 消耗

### 22. 优化器选错索引

1. 优化器选择索引的目的, 是找到一个最优的执行方案, 并用最小的代价去执行语句

   - 是否会回表
   - 是否排序
   - 临时表
   - 扫描行数
   - 扫描索引代价

2. MySQL 采样统计索引的基数: 是一个近似值

   - 默认会选择 N 个数据页, 统计这些页面上的不同值, 得到一个平均值, 然后乘以这个索引的页面数
   - 数据表是会持续更新的, 所以当变更的数据行数超过 1/M 的时候, 会自动触发重新做一次索引统计
   - `N/M`: **innodb_stats_persistent**, **ON{N20, M10}**, **off{N8, M16}**
   - `analyze table`: 进行一次评估

3. 选错索引的解决办法

   - force index
   - 改 SQL 诱惑优化器: limit
   - 创建新的合适的索引
   - 删除不必要的索引

4. sample

   ![avatar](/static/image/db/mysql-index-error.png)

   - force index(a): 3w+
     1. 这个是因为 前 10w 的数据被删除, 由于 session a 的存在, 并不会真的删除, 所以会有两个版本: `2w`
     2. 新建的 10w 中 [1w, 2w] 区间 有 `1w`, 所以一共 `3w+` 的 rows
   - 全表扫描的 rows: **10w**
     1. 为什么不是 30w? 全表扫描的行数是表的行数, show table status 的值

### 23.创建索引-前缀索引: email 上建立索引

1. alter table SUser add index index1(email);
2. alter table SUser add index index2(email(6));
3. select id,name,email from SUser where email='zhangssxyz@xxx.com' 执行顺序

   - 如果使用的是 index1, 执行顺序是这样的
     1. 从 index1 索引树找到满足索引值是'zhangssxyz@xxx.com'的这条记录, 取得 ID2 的值;
     2. 到主键上查到主键值是 ID2 的行, 判断 email 的值是正确的, 将这行记录加入结果集;
     3. 取 index1 索引树上刚刚查到的位置的下一条记录, 发现已经不满足 email='zhangssxyz@xxx.com'的条件了, 循环结束
     4. 这个过程只需要回主键索引取一次数据, 所以系统认为只扫描了一行
   - 如果使用的是 index2, 执行顺序是这样的
     1. 从 index2 索引树找到满足索引值是 'zhangs' 的记录, 找到的第一个是 ID1
     2. 到主键上查到主键值是 ID1 的行, 判断出 email 的值不是 'zhangssxyz@xxx.com', 这行记录丢弃
     3. 取 index2 上刚刚查到的位置的下一条记录, 发现仍然是 'zhangs', 取出 ID2, 再到 ID 索引上取整行然后判断, 这次值对了, 将这行记录加入结果集
     4. 重复上一步, 直到在 idxe2 上取到的值不是 'zhangs' 时, 循环结束

4. 使用前缀索引, 定义好长度, 就可以做到既节省空间, 又不用额外增加太多的查询成本

   ```sql
   -- 如果确定前缀长度：  95% * count
   select
      count(distinct left(email,4)）as L4,
      count(distinct left(email,5)）as L5,
      count(distinct left(email,6)）as L6,
      count(distinct left(email,7)）as L7,
   from SUser;
   ```

5. 前缀索引就用不上覆盖索引对查询性能的优化

### 24.创建索引: 身份证

1. **倒序存储+创建前缀索引**: 后 6 位一般不会重复{可以使用 count(distinct left(identity,6)）}
2. 也可以用 hash 字段: 新加一个字段, 存放身份证的 crc32{4 字节} + identity 也要带上
3. 都不支持范围查询

### 25.创建索引

1. 直接创建完整索引, 这样可能比较**占用空间**
2. 创建**前缀索引**, 节省空间, 但会增加查询扫描次数, 并且不能使用覆盖索引
3. **倒序存储+再创建前缀索引**, 用于绕过字符串本身前缀的区分度不够的问题, 不支持范围扫描
4. **创建 hash 字段索引**, 查询性能稳定, 有额外的存储和计算消耗, 不支持范围扫描

### 26.内存刷脏页 & flush RedoLog

1. 当内存数据页跟磁盘数据页内容不一致的时候, 我们称这个**内存页为 "脏页"**: change buffer
2. 内存数据写入到磁盘后, 内存和磁盘上的数据页的内容就一致了, 称为"干净页"
3. flush 时机

   - InnoDB 的 redo log 写满: **系统会停止所有更新操作**, 把 checkpoint 往前推进, redo log 留出空间可以继续写
   - 系统内存不足: 当需要新的内存页且内存不够用的时候, 就要淘汰一些数据页, 如果淘汰的是 "脏页", 就要将脏页写到磁盘
     1. 一个查询要淘汰的脏页个数太多, 会导致查询的响应时间明显变长
   - 系统空闲的时候:
   - MySQL 正常关闭: 内存的脏页都 flush 到磁盘上

4. innodb_io_capacity: 主机的 IO 能力{InnoDB 全力刷脏页时速度}

   - 建议: `磁盘的IOPS`
   - `fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest`

5. 脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total
6. MySQL 刷脏页, 如果发现旁边的数据页刚好是脏页会一起刷掉{蔓延}: `innodb_flush_neighbors`
7. 设计策略控制刷脏页的速度
   - 脏页比例: `innodb_max_dirty_pages_pct{0.75}`
   - redo log 写盘速度

### 27.简单删除数据空间回收

1. innodb_file_per_table:[5.7,~) 都是开启的
   - OFF: 在系统共享表空间, 跟数据字典在一起{不会删除表结构}
   - ON: 在 `.ibd` 文件中, drop table 会直接删除文件{空间会被回收}

### 28.删除数据的过程

1. 查找过程
2. 标记删除

   - InnoDB 引擎只会把该记录标记为删除
   - 如果之后要再插入一个 ID 在之间的记录时, 可能会复用这个位置{**记录的复用**}
   - 但是磁盘文件的大小并不会缩小

3. 如果我们删掉了一个数据页上的所有记录则该**数据页可以复用**
4. 如果相邻的两个数据页利用率都很小, 系统就会把这两个页上的数据合到其中一个页上, 另外一个数据页就被标记为可复用
5. 如果用 delete 命令把整个表的数据删除, 则所有的数据页都会被标记为可复用, 但是磁盘上, 文件不会变小
6. 空洞: 这些可以复用而没有被使用的空间{删除插入都会造成空洞}
7. 经过大量增删改的表, 都是可能是存在空洞的, 所以如果能够把这些空洞去掉, 就能达到收缩表空间的目的

   - **重建表: `alter table t engine=InnoDB,~~ALGORITHM=inplace~~;`** +`不建议在线上环境使用{可以使用gh-ost}`
   - alter 语句在启动的时候需要获取 MDL 写锁
   - 在真正拷贝数据之前就退化成读锁: 为了实现 Online, MDL 读锁不会阻塞增删改操作 + 禁止其他线程对这个表同时做 DDL
   - `alter table t add FULLTEXT(field_name);`: 这个是会 block 的
   - DDL 过程如果是 Online 的, 就一定是 inplace 的; 反过来就不一定了
   - 在重建表的时候, InnoDB 不会把整张表占满, 每个页留了 1/16 给后续的更新用

   ![avatar](/static/image/db/mysql-recreate-flow.png)

8. 重建表的流程

   - 建立一个临时文件, 扫描表 A 主键的所有数据页
   - 用数据页中表 A 的记录生成 B+树, 存储到临时文件中**{5.6 之后 innodb 内}+ 需要空间**
   - **生成临时文件的过程中, 将所有对 A 的操作记录在一个日志文件[row log]中, 对应的是图中 state2 的状态**
   - 临时文件生成后, 将日志文件中的操作应用到临时文件, 得到一个逻辑数据上与表 A 相同的数据文件, 对应的就是图中 state3 的状态
   - 用临时文件替换表 A 的数据文件

9. 重建表的方式
   - alter table t engine = InnoDB: 关注点在数据页{空间}
   - analyze table t: 重现统计索引信息, 不修改数据
   - optimize table t: `recreate + analyze`

### 29. `count(*) 问题`

1. 为什么不直接记录一下总数呢
   - 因为即使是在同一个时刻的多个查询, 由于 MVCC 的原因, InnoDB 表返回行数是不确定的{事务设计有关}
   - 每一行对当前事务是否可见都是不一定的
2. MySQL 优化器会找到最小的那棵树来遍历

   - 在保证逻辑正确的前提下, **尽量减少扫描的数据量**, 是数据库系统设计的通用法则之一

3. `count(*)`

   - MyISAM 表虽然 count(\*)很快, 但是不支持事务{没有 where 时}
   - show table status 命令虽然返回很快, 但是不准确
   - InnoDB 表直接 count(\*) 会遍历全表, 虽然结果准确, 但会导致性能问题

4. 解决办法: {自己记下来}

   - 用缓存系统保存计数: 缓存可能丢失{重启时执行一次 count(\*)} + 逻辑上不精确的{获取总数和获取记录不是原子的}
   - 在数据库保存计数: 单独的一张计数表 C{不会丢失} + 一个事务内是 RR, 所以是精确的

5. count 性能问题

   - server 层要什么就给什么
   - InnoDB 只给必要的值
   - 现在的优化器只优化了 count(\*)的语义为 "取行数"
   - `count(字段)<count(主键id)<count(1)≈count(*)`

### 30. order by

1. https://github.com/Alice52/java-ocean/issues/218

### 31. rand()

- sort_buffer_size

```sql
-- 1w rows
explain select word from t_words order by rand() limit 3; {Using temporary; Using filesort}
```

1. order by rand() 执行过程: 扫描行数很多有性能有问题的

   - 创建一个临时表{内存/磁盘}: memory 引擎的{**tmp_table_size** 值大于会被放入的值}, R(), W{字段长度}
   - 从 words 表中, 按主键顺序取出所有的 word 值, 插入临时表, **扫描 1w 行**
   - 现在临时表有 10000 行数据, 按照字段 R 排序
   - 初始化 sort_buffer{double 类型, 整型}: sort_buffer_size 会影响排序算法{归并排序算法[临时文件], 优先队列排序算法}
   - 临时表中一行一行地取出 R 值和位置信息存入 sort_buffer[对内存临时表做全表扫描], **扫描 +1w 行**
   - 在 sort_buffer 中根据 R 的值进行排序
   - 排序完成后, 取出前三个结果的位置信息, 依次到内存临时表中取出 word 值, 返回给客户端, **扫描 +3 行**
   - 这个过程中, 总扫描行数变成了 20003

2. **order by rand()使用了内存临时表, 内存临时表排序的时候使用了 rowid 排序方法{优先队列排序算法}**

   - 内存临时表: 这个适合参数 tmp_table_size 有关
   - rowid: 这个是因为内存临时表, 不会回表问题
   - 优先队列排序算法: sort_buffer_size 大于 limit{真实需要的字段大小{这里就是 rowid+R} \* limit}

3. 随机排序方法

   - `M=max(id), N=min(id), X = (M-N)*rand() + N` + 取不小于 X 的第一个 ID 的行

     1. 这个会使用索引, 不会大量扫描数据
     2. 但是并不是真正的随机
     3. code

     ```sql
     select max(id),min(id) into @M,@N from t ;
     set @X= floor((@M-@N+1)*rand() + @N);
     select * from t where id >= @X limit 1;
     ```

   - C=count(`*`) + `Y = floor(C `\*` rand())`+`limit Y,1`
     1. 一共会扫描 C+Y+1 行: count(\*) 扫描 C 行 + `limit Y,1` 会扫描 Y+1 行
     2. 但是由于是 id primary, 代价比 order by random() 小很多

---

## mysql 参数

1. innodb_buffer_pool_size: `物理内存 * 3/4`, cache table and index data.

---

## question list

1. CPU 一直 100%

   - show processlist: 有一个一直再执行, 临时表一直在创建, CPU 一直很高
   - kill 不掉{只发出指令}, 是个 bug 就直接重启数据库

   ```sql
   show processlist ;
   select  * from information_schema.INNODB_TRX;
   kill query  263607;

   show global status like '%created_tmp%';
   show variables like '%table_size%';
   ```

2. [Innodb 缓冲池命中率计算](https://hdm.console.aliyun.com/dbMonitor/MySQL#/performance/instance/rm-2zefr83ok57101uxm/detail)

   ```sql
   show global status like 'innodb%read%';
   ```

   - Innodb_buffer_pool_reads: 表示从物理磁盘读取页的次数
   - Innodb_buffer_pool_read_ahead: 预读的次数
   - Innodb_buffer_pool_read_ahead_evicted: 预读的页, 但是没有读取就从缓冲池中被替换的页的数量, 一般用来判断预读的效率
   - Innodb_buffer_pool_read_requests: 从缓冲池中读取页的次数
   - Innodb_data_read: 总共读入的字节数
   - Innodb_data_reads: 发起读取请求的次数, 每次读取可能需要读取多个页

   - **Innodb 缓冲池命中率计算: (Innodb_buffer_pool_read_requests - Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests**
   - InnoDB Buffer Pool 使用率: **innodb_buffer_pool_pages_data / (innodb_buffer_pool_pages_data + innodb_buffer_pool_pages_free)**

3. 读取索引页和数据页的数据量

   ```sql
   select index_name, count(*)
   from information_schema.INNODB_BUFFER_PAGE
   where INDEX_NAME in('idx_recordid', 'primary') and  TABLE_NAME='all_star_online_pk_record_detail'
   group by index_name;
   ```

4. **唯一索引的使用弊端**
