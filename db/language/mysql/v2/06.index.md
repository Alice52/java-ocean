## index

### 1. 索引简介

1. 定义:

   - **索引是数据结构： `排好序`的快速`查找` `数据结构`**
   - 在数据之外, 数据库还维护了维护了满足特定**查询算法**的数据结构, 这些数据结构以某种方式引用**指向数据**, 就可以在这些数据结构的基础上实现高级查找算法, 这样的数据结构就是索引
   - 实际上 index 也是一张表, 保存了主键与索引字段, 并指向实体表的记录
   - 一般来说索引本身也很大{**一般在内存中**}, 但索引最终还是会以文件形式存储在硬盘上[idb]
   - 选取`b+树`作为存储结构

     ![avatar](/static/image/db/mysql-b+tree.png)

     ![avatar](/static/image/db/mysql-index-practice.png)

2. 分类: 尽量使用 `复合索引`; 不要超过 5 个;

   ![avatar](/static/image/db/mysql-index-v2.png)

   - `聚簇索引/非聚簇索引`
   - 单值索引/主键索引/唯一索引/复合索引{**允许有空值且可以重复**}

   ![avatar](/static/image/db/mysql-index-concept.png)

3. 相关概念

   - innodb 是将索引与数据放在一起的: `innodb 在插入数据时, 数据必须和某个索引列放在一起`
   - 在不同存储引擎中数据的组织形式也是不同的, myisam 索引与数据是分开放的: 所以 myisam 只有非聚簇索引
   - 聚簇索引: 数据和索引放在一起的叫聚簇索引
   - 非聚簇索引: 数据和索引不放在一起的叫非聚簇索引, **要查 2 颗 b+树**
   - 覆盖索引
   - 复合/联合索引
     1. 第一原则是, 如果通过调整顺序, 可以少维护一个索引, 那么这个顺序往往就是需要优先考虑采用的
     2. 考虑的原则就是空间
   - 最左前缀原则
   - 回表: 根据非主键索引查询到的结果并没有查找的字段值, 此时就需要再次根据主键从聚簇索引的根节点开始查找, 这样再次查找到的记录才是完成的
   - 索引下推: 5.7

     ```sql
     -- 以市民表的联合索引[name, age]
     -- 检索出表中名字第一个字是张, 而且年龄是10岁的所有男孩
     -- name 会用到索引
     select * from tuser where name like '张%' and age=10 and ismale=1;
     ```

     - MySQL 5.6 之前, 只能从 ID3 开始一个个回表: `到主键索引上找出数据行, 再对比字段值`
     - MySQL 5.6 引入的`索引下推优化[index condition pushdown], 可以在索引遍历过程中, 对索引中包含的字段先做判断, 直接过滤掉不满足条件的记录, 减少回表次数`

     ![avatar](/static/image/db/mysql-index-practice-down.png)
     ![avatar](/static/image/db/mysql-index-practice-down-v5.5.png)

4. 优点

   - 类似大学图书馆建书目索引, 提高数据检索效率, 降低数据库 io 成本
   - 通过索引列对数据进行排序, 降低数据排序成本, 降低了 cpu 的消耗

5. 缺点

   - `[空间]`实际上 index 也是一张 table, 保存了主键与索引字段, 并指向实体表的记录, `需要一定的空间`
   - `[修改代价]`index 虽然提高了 query 的速度, 但是却降低了 `update/insert/delete` 的效率: `当 update/insert/delete 时就需要处理 data 和 index 两个部分`
   - `[建立索引难]`需要花时间去建立优秀的 index
   - `[回表代价]`最后是回表的代价

6. 使用

   - 适合创建索引

     1. pk: 主键自动建立唯一索引
     2. `频繁作为查询`的条件的字段应该创建索引
     3. 查询中与其他表关联的字段, `外键关系建立索引`
     4. 查询中`排序的字段`, 排序字段若通过索引去访问将大大提高排序的速度
     5. 分组字段
     6. 单值/复合索引的选择问题: **在高并发下倾向创建复合索引**

   - 不适合创建索引

     1. 表记录`太少`
     2. `where` 条件里用不到的字段不创建索引
     3. `频繁更新`的字段不适合创建索引: 因为每次更新不单单是更新了记录还会更新索引, 加重 io 负担
     4. 数据`重复`且`分布平均`的表字段: 如果某个数据列包含许多重复的内容, 为它建立索引就没有太大的实际效果

7. 索引选择: 每张表最终只能使用一个 index

   - 单表: `where 顺序无关`

     ![avatar](/static/image/db/mysql-index.png)

   - order by: 尽量使用 index 方式排序, 避免使用 filesort 方式排序

     ![avatar](/static/image/db/mysql-order-by.png)

     1. 符合最佳左前缀法则
     2. 复合升序降序排序会使用 using filesort
     3. order by 中间不能断, 且**可以和 where 之后一起不断也可以**
     4. 当无法使用索引列, 增大 max_length_for_sort_data 参数的设置 + 增大 sort_buffer_size 参数的设置

   - group by

     1. group by 实质是先排序后进行分组
     2. 遵照索引建的最佳左前缀
     3. where 高于 having, 能写在 where 限定的条件就不要去 having 限定
     4. 当无法使用索引列, 增大 max_length_for_sort_data 参数的设置 + 增大 sort_buffer_size 参数的设置

8. [索引使用建议](./98.optimize.md)

9. syntax

   ```sql
   -- 1. create index
   create [unique] index index_name on table_name(column_name);
   alter table table_name add [unique] index [index_name] on table_name(column_name);
   -- unique and not null
   alter table table_name add primary key(column_name)
   -- unique and can null, and null can more times
   alter table table_name add unique index_name(column_name)
   -- common index, can more time one value
   alter table table_name add index index_name(column_name)
   -- use in full text search
   alter table table_name add fulltext index_name(column_name)

   -- 2. delete index
   drop index [index_name] on table_name

   -- 3. show  index
   show index from table_name
   ```

### 2. 为什么 使用 b+ 树

1. hash 的缺点

   - **Hash 索引在等值查询上比 B+ 树效率更高**
   - hash 时相邻的两个值可能会相邻很远, **所以需要全值匹配**
   - hash 算法影响比较大, 而且 hash 碰撞可能导致数据不均匀, 可能是链表
   - 需要大量的空间
   - hash 不支持范围查询: 必须逐个匹配
   - Hash 索引不支持最左侧原则
   - B+ 树支持 order by 排序, Hash 索引不支持
   - Hash 索引根本无法进行模糊查询

2. avl/二叉树/红黑树

   - 都是树, 每个节点只有两个节点
   - 导致深度变深[io 次数变多查询变慢]
   - 局部性原理: 时间局部性和空间局部性, 数据和程序都有聚集成群的倾向, 之前读取过的数据可能会被再次读取的可能性大
   - 磁盘预读: 如果从磁盘中读取 a 字符并不是直接读取 a 字符的; 内存和磁盘进行数据交互的时候有一个最基本的数据单元[页一般 4/8k], 每次读取的时候应该是页大小的整数倍, innodb 默认每次读取 16k 数据

3. b 树: 每个节点都包含 key&data

   ![avatar](/static/image/db/mysql-index-b.png)

   - 如果 data 大的话, 那么每页(16k)上能存储的数据个数就会减少, 树深增加, IO 次数增加, 效率低下

4. b+ 树

   ![avatar](/static/image/db/mysql-index-b+.png)

   - 数据都记录在**同一层**的叶子节点上 + 非叶子节点只存储 key = 树高度小 + 查询的稳定(读的是 key-每次读取的数据差不多)
   - 叶子节点是有序链表`{数据页间是双向链表, 数据之间是单项链表}`, 全表扫描时方便[区间数据], **缓存的命中率也会比 B 树高**(一次读取 16k 里面多需要的数据)

### 3.唯一索引的使用 & 普通索引

1. 查询过程

   - 在索引树上查找, B+树从树根开始, 按层搜索到叶子节点: `数据页内部通过二分法来定位记录`
   - 普通索引: 查找到满足条件的第一个记录后, 需要查找下一个记录直到碰到第一个不满足 k=5 条件的记录
   - 唯一索引: 索引定义了唯一性, **查找到第一个满足条件的记录后, 就会停止继续检索**
   - **但是两者之间几乎没有太大的性能差距**:
     1. InnoDB 的数据是按数据页为单位来读写的: `默认是16KB{一个数据页可以放近千个long的key}`
     2. 当需要读一条记录的时候, 并不是将这个记录本身从磁盘读出来, 而是以页为单位, 将其整体读入内存
     3. 所以都是读取一次数据页到内存, 之后的查找判断是很快的: 除非有大于 16K 的数据才会多次加载数据页

2. 更新过程: **change buffer**{插入一个新记录(4,400)}

   - 该记录对应的**目标页**在内存中
     1. 对于唯一索引来说, 找到 3 和 5 之间的位置, 判断到没有冲突, 插入这个值, 语句执行结束: redo-log + bin-log
     2. 对于普通索引来说, 找到 3 和 5 之间的位置, 插入这个值, 语句执行结束: redo-log + bin-log
   - 该记录对应的**目标页**不在内存中
     1. 对于唯一索引来说, **需要将数据页读入内存{随机读}**, 判断到没有冲突, 插入这个值, 语句执行结束: redo-log + bin-log
     2. 对于普通索引来说, 则是将更新记录在 change buffer{可以新开辟}, 语句执行就结束: **redo-log{记录的是插入一行}** + bin-log
   - 之后的查找
     ![avatar](/static/image/db/mysql-change-buffer-read.png)

3. 唯一索引可以保证业务的数据唯一性
   - **可以转换为逻辑判断**{做不到则就只能使用唯一索引}
   - 但是会导致 内存命中率{更新操作} 下降
   - "归档库"的场景, 可以考虑使用唯一索引的{**唯一索-查询场景, 普通索引-插入场景**}

### 4.change buffer: `可以持久化的数据` + `只有普通索引可以使用`

1. 当需要更新一个数据页时, 如果数据页在内存中就直接更新: 之后就是 redo_log, bin_log 的二阶段提交

2. 当不在内存中的话, 在**不影响数据一致性的前提**下, InooDB 会将更新操作缓存在 change buffer 中, 这样就不需要从磁盘中读入这个数据页
3. 查询时需要访问这个数据页的时候: 将数据页读入内存, 然后执行 change buffer 中与这个页有关的操作 `[merge]`
4. **merge: 将 change buffer 中的操作应用到原数据页, 得到最新结果**
   - 在事务提交的时候, 把 change buffer 的操作也记录到 redo log 里
   - merge: 从磁盘读入数据页到内存[老版本的数据页]
   - merge: 从 change buffer 里找出这个数据页的 change buffer 记录, 依次应用, 得到新版数据页
   - merge: 写 redo log, 这个 redo log 包含了数据的变更和 change buffer 的变更
5. merge 时机: 访问该数据页, 系统后台线程定期 merge, 数据库正常关闭
6. change buffer 的好处:

   - 将更新操作先记录在 change buffer, 减少读磁盘, 语句的执行速度会得到明显的提升
   - 数据读入内存是需要占用 buffer pool 的, 所以这种方式还能够避免占用内存, 提高内存利用率

7. 唯一索引的更新操作都要先判断这个操作是否违反唯一性约束: 就需要将数据也读取到内存判断, 所以不能使用 change buffer
8. change buffer 用的是 buffer pool 里的内存: innodb_change_buffer_max_size 占 bp 的比例
9. 适合的场景: 写多读少, 比如账单类、日志类的系统
10. 写入之后马上会做查询:
    - 将更新先记录在 change buffer
    - 但之后由于马上要访问这个数据页, 会立即触发 merge 过程
    - 这样随机访问 IO 的次数不会减少`{读取到内存才能更新}`, 反而增加了 change buffer 的维护代价
11. redo log & change buffer

    - redo log 主要节省的是随机写磁盘的 IO 消耗[转成顺序写]
    - 而 change buffer 主要节省的则是随机读磁盘的 IO 消耗

### 5.插入缓冲

1. 对于非聚集索引的插入或者是更新操作, 不是每一次直接插入索引页中
2. 而是先判断插入的非聚集索引页是否在缓冲池中, 如果在就直接插入,
3. 如果不在就先放入一个插入缓冲池中, 再以一定的频率执行插入缓冲和非聚集索引页子节点的合并操作,
4. 这是时候通常可以把多个插入合并到一个操作中, 大大提高了对非聚集索引执行插入和修改的性能
5. 插入缓冲的使用必须满足两个条件
   - 索引不是唯一的
   - 是辅助索引

### 5.优化器选错索引

1. 优化器选择索引的目的, 是找到一个最优的执行方案, 并用最小的代价去执行语句

   - 是否会回表
   - 是否排序
   - 临时表
   - 扫描行数
   - 扫描索引代价

2. MySQL 采样统计索引的基数: 是一个近似值

   - 默认会选择 N 个数据页, 统计这些页面上的不同值, 得到一个平均值, 然后乘以这个索引的页面数
   - 数据表是会持续更新的, 所以当变更的数据行数超过 1/M 的时候, 会自动触发重新做一次索引统计
   - `N/M`: **innodb_stats_persistent**, **ON{N20, M10}**, **off{N8, M16}**
   - `analyze table`: 进行一次评估

3. 选错索引的解决办法

   - force index
   - 改 SQL 诱惑优化器: limit
   - 创建新的合适的索引
   - 删除不必要的索引

4. sample

   ![avatar](/static/image/db/mysql-index-error.png)

   - force index(a): 3w+
     1. 这个是因为 前 10w 的数据被删除, 由于 session a 的存在, 并不会真的删除, 所以会有两个版本: `2w`
     2. 新建的 10w 中 [1w, 2w] 区间 有 `1w`, 所以一共 `3w+` 的 rows
   - 全表扫描的 rows: **10w**
     1. 为什么不是 30w? 全表扫描的行数是表的行数, show table status 的值

### 6.创建索引-前缀索引: email 上建立索引

1. alter table SUser add index index1(email);
2. alter table SUser add index index2(email(6));
3. select id,name,email from SUser where email='zhangssxyz@xxx.com' 执行顺序

   - 如果使用的是 index1, 执行顺序是这样的
     1. 从 index1 索引树找到满足索引值是'zhangssxyz@xxx.com'的这条记录, 取得 ID2 的值;
     2. 到主键上查到主键值是 ID2 的行, 判断 email 的值是正确的, 将这行记录加入结果集;
     3. 取 index1 索引树上刚刚查到的位置的下一条记录, 发现已经不满足 email='zhangssxyz@xxx.com'的条件了, 循环结束
     4. 这个过程只需要回主键索引取一次数据, 所以系统认为只扫描了一行
   - 如果使用的是 index2, 执行顺序是这样的
     1. 从 index2 索引树找到满足索引值是 'zhangs' 的记录, 找到的第一个是 ID1
     2. 到主键上查到主键值是 ID1 的行, 判断出 email 的值不是 'zhangssxyz@xxx.com', 这行记录丢弃
     3. 取 index2 上刚刚查到的位置的下一条记录, 发现仍然是 'zhangs', 取出 ID2, 再到 ID 索引上取整行然后判断, 这次值对了, 将这行记录加入结果集
     4. 重复上一步, 直到在 idxe2 上取到的值不是 'zhangs' 时, 循环结束

4. 使用前缀索引, 定义好长度, 就可以做到既节省空间, 又不用额外增加太多的查询成本

   ```sql
   -- 如果确定前缀长度：  95% * count
   select
      count(distinct left(email,4)）as L4,
      count(distinct left(email,5)）as L5,
      count(distinct left(email,6)）as L6,
      count(distinct left(email,7)）as L7,
   from SUser;
   ```

5. 前缀索引就用不上覆盖索引对查询性能的优化

### 7.创建索引: 身份证

1. **倒序存储+创建前缀索引**: 后 6 位一般不会重复{可以使用 count(distinct left(identity,6)）}
2. 也可以用 hash 字段: 新加一个字段, 存放身份证的 crc32{4 字节} + identity 也要带上
3. 都不支持范围查询
