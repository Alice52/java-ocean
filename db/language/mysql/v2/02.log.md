## MySQL - LOG

1. [innodb]undo-log: idb 文件
2. [innodb]redo-log
3. [mysql-server]bin-log: 数据备份相关, 需要自己开启, 并指定模式[语句, **row**, mixed]
4. [mysql-server]slow-log: 慢查询日志, 需要自己开启
5. [mysql-server]relay-log: slave
6. [mysql-server]log-error: 错误信息相关
7. 数据安全: 双 1 操作

   - binlog: `sync_binlog`
   - redolog: `innodb_flush_log_at_trx_commit`

### undo-log

1. 逻辑日志: 记录的是每一条数据的修改, **不是针对数据页**[**针对的是行记录**] 物理日志是修改加载进内存的最小的逻辑单元`页`, 如果记录的是页的修改则是物理日志
2. 实现事务的原子性
3. 用于实现 mvcc:
4. 在任何操作之前, _首先将数据备份到一个地方[undo-log], 然后对事物进行修改,_ 如果出错或 rollback 则利用 undo-log 中的备份将数据恢复到事务开始之前的状态: `可以近似按以下方法理解`

   - delete 时则向 undo-log 中插入 insert 一条数据
   - insert 则在 undo-log 中记录一条 delete 语句
   - update 则在 undo-log 中记录一条反向的 update 语句

5. 在 MySQL 中, 实际上每条记录在更新的时候都会同时记录一条回滚操作
6. 记录上的最新值, 通过回滚操作, 都可以得到前一个状态的值
7. 假设一个值从 1 被按顺序改成了 2、3、4, 在回滚

   ![avatar](/static/image/db/mysql-isolation-rr.png)

8. 当前值是 4, 但是在查询这条记录的时候, 不同时刻启动的事务会有不同的 read-view

   - 如图中看到的, 在视图 A, B, C 里面, 这一个记录的值分别是 1, 2, 4,
   - 同一条记录在系统中可以存在多个版本, 就是数据库的多版本并发控制(MVCC)
   - 对于 read-view A , 要得到 1, 就必须将当前值依次执行图中所有的回滚操作得到

9. 即使现在有另外一个事务正在将 4 改成 5, 这个事务跟 read-view A, B, C 对应的事务是不会冲突的

10. 当没有事务再需要用到这些回滚日志时, 回滚日志会被删除
    - `当系统里没有比这个回滚日志更早的 read-view 的时候`

### redo log

1. 定义: `innodb` 中是一快可`重复利用`的`顺序读写`的`固定大小`的`磁盘空间`, 是一种 `Write-Ahead Logging[先写日志]{将来会出现的数据}`, `物理日志`[数据页上的修改]

   - 是 innodb 中的概念
   - 顺序写: 速度极快
   - WAL: 先写日志
   - commit 前不需要将数据整合到真正的数据表{随机写}
   - 固定大小: redo-log 只能循环写, 不能满了就创建新的
   - 数据页上的修改
   - **redo log 是数据页, 因此一旦 commit 就不能回滚, 否则会导致其他事务的写丢失**

2. 作用:

   - redo-log + bin-log **二阶段提交**保证数据安全 + crash safe

3. redo log buffer: 全局共用{MySQL 的内存中}

   - 是一块内存, 保存修改数据但是还没有 commit 的 redo log: 在一个事务的更新过程中, 日志是要写多次的
   - 事务在执行过程中, 生成的 redo log 是要先写到 redo log buffer
   - **不需要**每次改动都持久化到磁盘, 但是可能会被持久化到磁盘: 因为事务没提交{宕机的话也没影响}
   - innodb_log_buffer_size 控制大小
   - buffer 使用空间达到 1/2 的 innodb_log_buffer_size 时会写入 page cache

     ```sql
     begin;
     insert into t1 ... -- 会先插入 redo log buffer
     insert into t2 ... -- 会先插入 redo log buffer
     commit; -- 写入 redo-log
     ```

4. WAL

   ![avatar](/static/image/db/mysql-wal.png)

   - write pos 是当前记录的位置, 一边写一边后移, 写到第 3 号文件末尾后就回到 0 号文件开头
   - checkpoint 是当前要擦除的位置, 擦除记录前要把记录更新到数据文件
   - write pos 和 checkpoint 之间的是空着的部分, 可以用来记录新的操作.
   - `如果 write pos 追上 checkpoint, 这时候不能再执行新的更新`, 得停下来等待 checkpoint 推进

5. flow

   - 存在 redo log buffer 中: 物理上是在 MySQL 进程内存中
   - write 但是没有 fsync: 数据在 FS page cache 中
   - fsync 持久化到磁盘: 数据在 hard disk

   ![avatar](/static/image/db/mysql-redolog-flow.png)

6. 相关配置: `innodb_flush_log_at_trx_commit`

   - 在事务提交之前不需要将数据持久化到数据表的磁盘, 只需要记录到 Redolog 中就行
   - 当系统崩溃时, 虽然数据没有持久化到数据表的磁盘, 但是系统可以根据 redo-log 里的内容将数据恢复到最新的状态
   - innodb_flush_log_at_trx_commit:
     1. 0: 表示写入 innodb 的 logbuffer
     2. **默认值是 1**: 表示每次都将数据直接写到 os buffer 并调用 fsync 刷入磁盘{prepare 阶段就需要持久化}
     3. 2: 表示直接写入 OS buffer{page cache}

7. 将 innodb_flush_log_at_trx_commit 设置为 2

   - **风险: 主机宕机时会丢数据**

8. InnoDB 有一个后台线程: 每隔 1 秒

   - redo log buffer 中的日志 write 写到文件系统的 page cache
   - 调用 fsync 持久化到磁盘
   - **一个没有提交的事务的 redo log, 也是可能已经持久化到磁盘的**

9. 没提交事务的 redo log 被写入磁盘的场景: _回滚时使用 undolog 恢复磁盘数据_

   - InnoDB 每秒一次的后台线程: buffer -> fs page cache -> disk
   - buffer 使用空间达到 1/2 的 innodb_log_buffer_size 时会写入 page cache
   - 并行的事务提交的时候, 顺带将这个事务的 redo log buffer 持久化到磁盘

### binlog

1. binlog: service 层的归档日志, 可选择性打开的逻辑日志[记录语句逻辑], 多用于 SM, 无限空间, 追加记录

   - 顺序写
   - _组提交机制_: 可以大幅度降低磁盘的 IOPS 消耗

2. 指定模式

   - 语句
   - **row**
   - mixed

3. binlog cache{一片内存}

   - 每个线程一个
   - binlog_cache_size 设置单个线程被分配的内存
   - 如果超过了这个参数规定的大小, 就要暂存到磁盘
   - 每个线程有自己 binlog cache, 但是共用同一份 binlog 文件

4. 保存 binlog 的流程

   - 事务执行过程中, 先把日志写到 binlog cache
   - 事务提交的时候, 再把 binlog cache 写到 binlog 文件中, 并清空 binlog cache
   - **一个事务的 binlog 是不能被拆开的, 因此不论这个事务多大也要确保一次性写入{binlog cache}**

   ![avatar](/static/image/db/mysql-binlog.png)

5. sync_binlog: 都会 write() 写入 fs page cache

   - 0: 不调用 fsync, 交给系统做主 + 后台任务
   - 1: 每个事务都调用 fsync
   - N: n 个事务之后才会调用 fsync

6. 将 sync_binlog 设置为大于 1 的值[比较常见是 100~1000]

   - 风险: 主机宕机时会丢 binlog 日志且不能回滚事务{主备不一致}

7. binlog: statement 与 row 的区别

   - row 是数据级别的, statement 是语句
   - 集群数据一致问题
   - 可重复读下的问题
     ![avatar](/static/image/db/mysql-binlog-format.png)
   - 我们一般不管, format 默认都是 row, 像这种只 match 到, 没有 update 到数据的, 最后结果都是快照读
   - lock in share mode: 当前读, 读锁[select * from xx 是不会产生读锁]
   - for update: 当前读
   - select \* from xx: 快照读

### 二阶段提交

1. 宕机恢复流程

   - 如果 redo log 里面的事务是完整的, 也就是已经有了 commit 标识, 则直接提交
   - 如果 redo log 里面的事务只有完整的 prepare, 则判断对应的事务 binlog 是否存在并完整

     - 如果是, 则提交事务
     - 否则, 回滚事务

2. MySQL 怎么知道 binlog 是完整的

   - statement 格式的 binlog, 最后会有 COMMIT
   - **row 格式的 binlog, 最后会有一个 XID event**

3. redo log 和 binlog 是怎么关联起来的

   - 它们有一个共同的数据字段, 叫 XID
   - 崩溃恢复的时候, 会按顺序扫描 redo log
   - 如果碰到既有 prepare 又有 commit 的 redo log, 就直接提交
   - 如果碰到只有 parepare, 而没有 commit 的 redo log, 就拿着 XID 去 binlog 找对应的事务

4. 处于 prepare 阶段的 redo log 加上完整 binlog, 重启就能恢复, MySQL 为什么要这么设计?

   - 数据与备份的一致性有关
   - 也就是 binlog 写完以后 MySQL 发生崩溃, 这时候 binlog 已经写入了, 之后就会被从库使用
   - 所以, 在主库上也要提交这个事务
   - 采用这个策略, 主库和备库的**数据就保证了一致性**

5. 为很么不直接写 redo-log 之后再接着写 bin-log

   - 两阶段提交是经典的分布式系统问题
   - 对于 InnoDB 引擎来说, **如果 redo log 提交完成了, 事务就不能回滚**{如果这还允许回滚, 就可能覆盖掉别的事务的更新}
   - 而如果 redo log 直接提交, 然后 binlog 写入的时候失败, InnoDB 又回滚不了, 数据和 binlog 日志又不一致了

6. 事务执行期间, 还没到提交阶段, 如果发生 crash 的话, redo log 肯定丢了, 这会不会导致主备不一致呢?

   - 不会, 因为这时候 binlog{整体的} 也还在 binlog cache 里, 没发给备库
   - crash 以后 redo log 和 binlog 都没有了, 从业务角度看这个事务也没有提交, 所以数据是一致的

7. redo log & **buffer pool** & 落盘

   - _redo log 并没有记录数据页的完整数据_
   - 如果是正常运行的实例的话, 数据页被修改以后, 跟磁盘的数据页不一致, 称为**脏页**. 最终数据落盘, 就是把内存中的数据页写盘, 这个过程与 redo log 毫无关系
   - 在崩溃恢复场景中, InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新, 就会将它读到内存, 然后让 redo log 更新内存内容. 更新完成后, 内存页变成脏页, 就回到了第一种情况的状态

8. binlog cache 是每个线程自己维护的, 而 redo log buffer 是全局共用的

   - 一个事务的 binlog 是不能被拆开的, 要整个事务完成后, 再一起写到文件里
   - binlog 存储是以 statement 或者 row 格式存储的: 只跟当前事务相关
   - redo log 并没有这个要求, redo log buffer 中的日志可以在其他事务提交的时候可以被一起写到磁盘中
   - redo log 是以 page 页格式存储的: page 格式, 天生就是共有的

### [组提交](https://blog.csdn.net/weixin_34847632/article/details/113599866)

1. 双一操作保证了数据安全, 但导致每个事务都需要等两次 io **刷盘**操作

   - [顺序写]redo log 的 prepare 持久化: 支持组提交
   - [顺序写]binlog 的持久化: 支持组提交
   - `SQL 返回的前提是redolog & binlog 已经提交, 否则就会一直等待`
   - 好处: 可以大幅度降低磁盘的 IOPS 消耗

2. 日志逻辑序列号

   - LSN 是单调递增的: 用来对应 redo log 的一个个写入点
   - 每次写入长度为 length 的 redo log, LSN 的值就会加上 length
   - 也会写到 InnoDB 的数据页中: **确保数据页不会被多次执行重复的 redo log**

3. 组提交的过程: **三个并发事务(trx1, trx2, trx3)在 prepare{完整的 redolog} 阶段**

   ![avatar](/static/image/db/mysql-group-commit.png)

   - trx1 是第一个到达的, 会被选为这组的 leader
   - 等 trx1 要开始写盘的时候, 这个组里面已经有了三个事务, 这时候 LSN 也变成了 160
   - trx1 去写盘的时候, 带的就是 LSN=160, 因此等 trx1 返回时, 所有 LSN 小于等于 160 的 redo log, 都已经被持久化到磁盘
   - 这时候 trx2 和 trx3 就可以直接返回了{节约磁盘 IOPS}
   - mysql 组提交的优化

     ![avatar](/static/image/db/mysql-group-commit-optimize.png)

     - 第 3 步执行得会很快, 所以 binlog 的组提交优化不如 redolog 明显

4. 组提交的三个阶段: 每个阶段都有一个队列, 每个队列都有一把锁保护, 第一个进入队列的事务会成为 leader, leader 领导所在队列的所有事务, 全权负责整队的操作, 完成后通知队内其他事务操作结束

   ![avatar](/static/image/db/mysql-config-group.gif)

   - flush 阶段

     1. 首先获取队列中的事务组
     2. 将 redo log 中 prepare 阶段的数据刷盘(图中 flush redo log)
     3. 将 binlog 数据写入文件, 当然此时只是写入文件系统的缓冲, 并不能保证数据库崩溃时 binlog 不丢失 (图中 write binlog)
     4. **flush 阶段队列的作用是提供了 redo log 的组提交**
     5. 如果在这一步完成后数据库崩溃, 由于协调者 binlog 中不保证有该组事务的记录, 所以 mysql**可能**会在重启后**回滚**该组事务

   - Sync 阶段

     1. 这里为了增加一组事务中的事务数量, 提高刷盘收益, MySQL 使用两个参数控制获取队列事务组的时机: 有一个满足就会 fsync
        - binlog_group_commit_sync_delay=N: 表示延迟多少微秒后才调用 fsync`{如无需要则不要修改, 会导致一些简单操作也要等这么久才能发挥}`
        - binlog_group_commit_sync_no_delay_count=N: 累积多少次以后才调用 fsync 直接开始刷盘
     2. Sync 阶段队列的作用是支持 binlog 的组提交
     3. 如果在这一步完成后数据库崩溃, 由于协调者 binlog 中已经有了事务记录, MySQL 会在重启后通过 Flush 阶段中 Redo log 刷盘的数据继续进行事务的提交

   - Commit 阶段

     1. 首先获取队列中的事务组
     2. 依次将 Redo log 中已经 prepare 的事务在引擎层提交(图中 InnoDB Commit)
     3. Commit 阶段不用刷盘, 如上所述, Flush 阶段中的 Redo log 刷盘已经足够保证数据库崩溃时的数据安全了
     4. Commit 阶段队列的作用是承接 Sync 阶段的事务, 完成最后的引擎提交, 使得 Sync 可以尽早的处理下一组事务, 最大化组提交的效率

5. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数

   - 减少 binlog 的写盘次数
   - 可能会增加语句的响应时间, 但**没有丢失数据的风险**
