## 调优 & 实战 & 常规建议

1. sql 执行慢的原因: `架构优化 -- 硬件优化 -- DB优化 -- SQL优化`

   - 架构优化: 分布式缓存{高性能/高并发}, 读写分离{读多写少}, 分库分表{数据量大}
   - 硬件优化: `cpu + io + config: top + free + iostat + vmstat`
   - MySQL 服务调优: bp, 连接, 缓冲/**线程数**/buffer 等
   - SQL 优化: **表结构优化**, 查询语句写的烂, **索引失效/错选/不选**, **关联查询太多 join** + **分库分表{数据量}**
   - 调用: 减少数据访问(合理的数据类型) - 返回尽量少的数据(带宽) - 减少交互次数(连接/复合操作)

2. 调优过程: `找到 - 分析 - 调优 - 验证(并发)`

   - 慢查询的开启并捕获
   - explain + 慢 sql 分析
   - show profile 查询 sql 在 mysql 服务器里面的执行细节和生命周期情况
   - sql 数据库服务器的参数调优

3. **云上服务尽量多看看系统监控 和 数据库监控**: 很有用
4. 慢 SQL 的表现: **IO / CPU / 内存**

   - 真实的慢 SQL 往往会伴随着**大量的行扫描**
   - **临时文件排**
   - 者频繁的磁盘 flush
   - **大面积执行超时: 这里会导致非慢 SQL 的超时**

### 找到: 慢查询日志 || _profile_ || general_log || 高 CPU

#### 慢查询日志

1. 慢查询日志

   - mysql 默认没有开启
   - 且 10s **以上**的 query 才算慢查询 [long_query_time]
   - _不建议平时开启, 会有一定的性能影响_

2. 慢查询日志相关配置

   - slow_query_log: {crud 都会记录}是否开启慢查询日志, 1 表示开启, 0 表示关闭
   - slow-query-log-file: 慢查询日志存储路径(默认 host_name-slow.log)
   - long_query_time: 慢查询阈值 **`>` **
   - log_queries_not_using_indexes: 未使用索引的查询也被记录到慢查询日志中[可选项]

   ```sql
   -- 查看是否启用
   show variables like '%slow_query_log%'

   -- 命令行启用: 重启失效, 且只针对当前数据库有效
   set global slow_query_log=1;
   -- 配置启用: 重启之后才生效
   vim /etc/mysql/mysql.conf.d/mysqld.cnf
         slow_query_log = 1
         slow_query_log_file = /var/lib/mysql/mysql-ubuntu.log
         long_query_time = 2
         log_output = file


   -- 大于指定时间才会记录为慢查询
   show variables like '%long_query_time%';

   -- 命令行设置: 需要新的链接{session}才会生效
   set global long_query_time = 3;


   -- 查看慢查询数量
   show global status like '%slow_queries%';
   ```

3. 慢查询日志分析: mysqldumpslow

   - s: 是表示按何种方式排序
     - c: 访问次数
     - l: 锁定时间
     - r: 返回记录
     - t: 查询时间
     - al: 平均锁定时间
     - ar: 平均返回记录数
     - at: 平均查询时间
   - t: 即为返回前面多少条的数据
   - g: 后边搭配一个正则匹配模式, 大小写不敏感的

   ```shell
   # 得到返回记录集最多的10个sql
   mysqldumpslow -s r -t 10 /var/ib/mysq/atguigu-slow.log
   # 得到访问次数最多的10个sql
   mysqldumpslow -s c -t 10 /var/lib/mysql/atguigu-slow.log
   # 得到按照时间排序的前10条里面含有左连接的查询语句
   mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysq/atguigu-slow.log
   # 另外建议在使用这些命令时结合|和more使用, 否则有可能出现爆屏情况
   mysqldumpslow -s r -t 10 /var/ib/mysql/atguigu-slow.log | more
   ```

#### general_log

1. globel query log

   - 将执行的所有 sql 全部保存到 mysql.general_log 表中.
   - 配置

     ```sql
     show variables like '%general_log%';
     set global general_log = 1;
     set global log_output = 'table'
     ```

#### profile: **执行线程的状态和时间角度**

1. [简介](http://www.360doc.com/content/21/0602/15/65839694_980126908.shtml)

   - 用来分析**当前会话**中语句执行的资源消耗情况
   - 可以用于 sql 的调优测量
   - 参数处于关闭状态, 并保存最近 15 次的运行结果

2. profile 配置

   ```sql
   -- 查看是否启用
   show variables like '%profiling%';
   -- 命令行启用: 需要新的 session 才会生效
   set global profiling = 1;
   set profiling_history_size = 1000;

   -- 查看结果
   show profiles;
   show profile all for query number_id;
   -- all 字段
      -- block io[IO开销]: Block_ops_in + Block_ops_out
      -- context switches[上下文切换]: Context_voluntary(上下文主动切换) + Context_involuntary(上下文被动切换)
      -- cpu[cpu]: CPU_user + CPU_system
      -- ipc[发送接收开销]: messages_sent + messages_received
      -- memory
      -- page faults[显示页面错误相关开销]: Page_faults_major(主分页错误) + Page_faults_minor
      -- source: source_function + source_file + source_line
      -- swaps[交换次数开销]: swaps
   ```

   ![avatar](/static/image/db/mysql-optimize-profile.jpg)

   - status 详情
     1. starting
     2. checking permission
     3. opening tables
     4. init
     5. system **lock**
     6. **optmizing**
     7. statistucs
     8. preparing
     9. Creating tmp table: 创建临时表
     10. **executing**
     11. sorting result
     12. **sending data**: 磁盘读取(接收存储引擎返回的数据) + limit 优化
     13. writing to net: 发送到网络(server 发送发到客户端)
     14. end
     15. querty end
     16. waiting for handler commit
     17. closing tables
     18. freeing items
     19. cleaning up
     20. ~~converting heap to myisam 查询结果太大, 内存都不够用了往磁盘上搬了~~
     21. _copying to tmp table on disk 把内存中临时表复制到磁盘, 危险_

3. 核心参数

   - 主要看 executing 的时间消耗
   - 排序 sending data
   - CPU 相关值
   - Context 相关值
   - Block 相关值

#### cananical question

1. 实时查找高 CPU 消耗的 SQL

   ```sql
   -- 定位线程
   pidstat -t -p <mysqld_pid> 1  5

   -- performance_schema 这个默认是不开启的: 监控MySQL在一个较低级别的运行过程中的资源消耗/资源等待等情况
   -- https://blog.csdn.net/f746262041/article/details/123548671
   select * from performance_schema.threads where thread_os_id = xx ;
   select * from information_schema.`PROCESSLIST` where  id=`threads.processlist_id`
   ```

   ![avatar](/static/image/db/mysql-opt-cpu.png)

### 分析: explian(执行计划) || optimizer_trace

#### explian

1. 语法 & 解析

   ```sql

   explain select * from account_member;
   ```

   | 字段 |        id        | select_type | table  | partitions |     type     | possible_keys |    key     |   key_len    |     ref      |     rows     | filtered | extra |
   | :--: | :--------------: | :---------: | :----: | :--------: | :----------: | :-----------: | :--------: | :----------: | :----------: | :----------: | :------: | :---: |
   | 解释 | **大到小读取表** |   读类型    | 数据表 |     --     | 查询使用类型 |  可能的索引   | 真使用索引 | 使用索引长度 | 索引被使用列 | 被扫描的行数 | 越小越好 |  --   |

2. id: select 查询的序列号, 表示查询中操作表的顺序

   - id 相同认为是一组, 从上往下执行
   - id 不同则 **id 越大越先执行**
   - derived: 衍生

3. select_type: 查询类型-`区别普通查询、联合查询、子查询等`

   - simple: 简单查询[不包含子查询/union]
   - primary: 查询中若包含任何复杂的子部分, `最外层查询则被标记为 primary`
   - [dependent] subquery: 在 select 或者 where 列表中包含的子查询 + dependent{关联子查询}
   - derived: [alias] 在 from 列表中包含的子查询被标记为 derived; mysql 会递归执行这些子查询, 把结果放在临时表里
   - union: 若第二个 select 出现在 union 之后, 则被标记为 union; 若 union 包含在 from 子句的子查询中, 外层 select 将被标记为 derived
   - union result: 从 union 表获取结果的 select

4. table: 显示这一行的数据是关于哪张表的(表的别名或者临时表)
5. type: **关联类型或访问类型**

   - `[system > const > eq_ref > ref > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > all]`: 查询尽量达到 range 级别, 最好达到 ref
   - system: 表只有一行记录(等于系统表), 这是 const 类型的特例, 可以忽略不计
   - const: 表示通过索引**一次**就找到了, **命中了 primary key 或唯一索引**
   - eq_ref: 在**表连接情况下**基于聚簇索引或者非 null 值的唯一索引进行数据扫描
   - ref: **非唯一索引扫描**, 返回所有匹配某个单独值的行; 然而它可能会找到多个符合条件的行, 所以他应该属于`查找和扫描的混合体`
   - ref_or_null: 类似于 ref, 区别在于 MySQL 会额外搜索包含 NULL 值的行
   - index_merge: or 的索引失效问题
   - unique_subquery: 在 where 条件中的关于 in 的子查询条件集合
   - index_subquery: 区别于 unique_subquery, 用于非唯一索引, 可以返回重复值
   - range: 使用一个索引且只检索给定范围的行`{只需要扫描部分索引}`, 一般出现于 `between < > in` 等的查询
   - index: 遍历索引树
   - all: 全表扫描{将遍历全表以找到匹配的行}

6. possible_keys: 可能被使用到的索引[参与优化 cost 比较的], 但不一定被查询实际使用
7. key: 实际使用的索引; 如果为 null 则没有使用索引
8. key_len: 越大越好

   - _表示索引中被使用的字节数, 可通过该列计算查询中使用的索引的长度_
   - _group by / order by 使用的不会被计算在内_

9. ref: 哪些列或常量被用于查找索引列上的值{const/func/null}
10. rows: 根据表统计信息及索引选用情况, 大致`估算出找到所需的记录所需要读取的行数`
11. filtered: 越小越好, 表示查询**符合**条件的数据占表的行数百分比
12. extra

    - using filesort: 会有性能问题[及时速度很快, 还是有可能在并发下吃 cpu], 对数据使用外部的索引排序{文件排序}, 常见于**复合升序降序排序会使用**
    - using temporary: 会有性能问题[及时速度很快, 还是有可能在并发下吃 cpu], 临时表保存中间结果; group by 字段没有索引 || 常见于排序 order by 和分组查询 group by 字段和索引不一致
    - using index condition: 表示索引作为条件(**索引下推**)
    - using index
      ```sql
      1. 如果同时出现 using where, 表明索引被用来执行索引键值的查找: 在存储引擎之后进行过滤
      2. 如果没有同时出现 using where, 表明索引用来读取数据而非执行查找动作(覆盖索引)
      ```
    - using where: 表明使用了 where 过滤
    - using join buffer: 使用了连接缓存
    - impossible where: where 子句的值总是 false, 不能用来获取任何元组
    - select tables optimized away
    - distinct: **在找到第一匹配的元组后即停止找同样值的工作**

13. **读取索引页和数据页的数据量**

    ```sql
    select index_name, count(*)
    from information_schema.INNODB_BUFFER_PAGE
    where INDEX_NAME in('idx_recordid', 'primary') and TABLE_NAME='all_star_online_pk_record_detail'
    group by index_name;
    ```

#### optimizer_trace

1. sql: 开启优化追踪

   ```sql
   set optimizer_trace="enabled=on",end_markers_in_json=off;
   set optimizer_trace_max_mem_size=1000000;
   select * from information_schema.optimizer_trace;
   ```

2. 索引选择: **在有多个索引的情况下, 在查询数据前, MySQL 会选择成本最小原则来选择使用对应的索引**
3. 成本问题

   - IO 成本: 读取一数据页(16k)的 IO 成本是 1 cost
   - CPU 成本: 内存中要检测数据是否满足**条件和排序**等 CPU 操作的成本, 默认检测一行记录的成本是 0.1{`配置的mysql.server_cost`} cost

4. `count(*)` cost 成本计算示例

   ```sql
   show table status like 'person'

   -- rows: 100147, filter: 100
   explain format =json select count(*) from person;
   ```

   |  Name  | Engine | Version | Row_format |  Rows  | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free |
   | :----: | :----: | :-----: | :--------: | :----: | :------------: | :---------: | :-------------: | :----------: | :-------: |
   | person | InnoDB |   10    |  Dynamic   | 100147 |       57       |   5783552   |        0        |   8421376    |  4194304  |

   ```json
   {
     "query_block": {
       "select_id": 1,
       "cost_info": {
         "query_cost": "10102.95"
       },
       "table": {
         "table_name": "person",
         "access_type": "index",
         "key": "create_time",
         "used_key_parts": ["create_time"],
         "key_length": "4",
         "rows_examined_per_scan": 100147, // show table status like 'person' 的行数
         "rows_produced_per_join": 100147,
         "filtered": "100.00",
         "using_index": true,
         "cost_info": {
           "read_cost": "88.25", // ??? io cost -- todo (18.34{索引cost}  + 64.25{回表cost}=82.59)
           "eval_cost": "10014.70", // cpu cost, row 相关 / 10
           "prefix_cost": "10102.95", // read_cost+eval_cost
           "data_read_per_join": "99M" // 每行 space * 行数
         }
       }
     }
   }
   ```

### 调优: 建议

1. 适合建立索引情况 + 不适合建立索引情况: `6 + 4`
2. 表结构优化:

   - 字段类型的选择: tinyint, smallint + unsigned, 而非直接 int/bigint
   - 字段类型的选择: char & navarchar || timestamp & dataetiem & ipv4/6
   - 字段类型大小的限制
   - 拆分字段
   - 字段数量: 一张表尽量不要超过 20 个字段: 否则分表
   - 字段默认值: 新建字段一定要有默认值: 非 NULL
   - **合理的增加冗余字段**

3. 索引失效:

   ![avatar](/static/image/db/mysql-index-invalid-orderby.png)

   - 隐式字符编码转换
   - 涉及类型转换
   - 计算函数
   - 范围: <> != notin exists: 连续数值请使用 _bettween_
   - like: `x%x%`可以, 但是之后失效, `%xx%` 都失效
   - ~~is null 索引一直会失效: 覆盖索引时也失效~~: 不会失效
   - is not null 在非覆盖索引才会失效
   - `覆盖索引指向的字段 >= 380 时, 覆盖索引也会失效`
   - 断层后失效: in(可能走 range) /最左前缀
   - **or 可能会 index_merge**: 存在一个没有索引则会索引失效

4. 索引失效解决

   - in 之后值不多是可以拆开写之后合并
   - like 一定要使用 `%x%`时可以使用 FullText, 或直接使用 ES, SOLR 等

5. 多表: 4

   - 尽量不要超过 3 表 join
   - 小表驱动大表: 相关子查询小表在前, 非相关子查询小表在后[in/exist]

     ```sql
     -- b should little: b will load first
     select * from a where id in (select id from b)
     -- a should little: a will load first
     select * from a where exists (select 1 from b where a.id = b.id)
     ```

   - on 条件上都要加索引
   - 优先优化 nestedloop 的内层循环
   - 避免索引失效[行锁变表锁]: 5+4

6. 尽量每张表不要超过 5 个索引, 不要超过 80 个字段

   - **id 自增**: 页分裂
   - 全值匹配
   - 最左前缀: 条件顺序
   - groupby 要和 orderby 一起: 执行时需要有序, 否则就可能用到临时表或文件排序
   - 索引失效考虑

7. 创建索引时, 应该尽量将过滤性好的字段放在前面
8. 尽可能通过分析统计信息和调整 query 的写法来达到选择合适索引的目的: 不要一味的建立索引
9. union 会去重, 且根据默认规则排序; union all 有重复且不排序
10. 禁止 `select \*`: 尤其时使用框架时

    - 覆盖索引下 index 是永远不会失效的
    - `*` 也会占用网络带宽

11. 如果 order by 上不适合建立索引, 则一定要深度过滤: 在高并发下还是有问题
12. on 高于 where: 但是注意含义是不一样的
13. where 高于 having, 能写在 where 限定的条件就不要去 having 限定
14. **高并发场景下减少对唯一对唯一索引的使用: 尽量使用覆盖索引 + 业务逻辑判断**
15. 尽量不要按照两张表的两个字段 group: 数量级上来之后一定会变慢
16. ORDER BY 尽量避免复合升序降序: 建立索引时也要这么做
17. 考虑使用`读已提交`的事物隔离级别
18. 尽量索引轻量级的字段: 比如能索引 int 字段就不要索引 varchar 字段
19. 索引字段也可以是部分前缀, 在创建的时候指定字段索引长度
20. 针对长文本的搜索, 可以考虑使用 Elasticsearch 等专门用于文本搜索的索引数据库
21. 真的需要的话: 可以考虑使用外键
22. 创建索引
    - 直接创建完整索引, 这样可能比较**占用空间**
    - [邮箱/身份证]创建**前缀索引**, 节省空间, 但会增加查询扫描次数, 并且不能使用覆盖索引
    - **倒序存储+再创建前缀索引**, 用于绕过字符串本身前缀的区分度不够的问题, 不支持范围扫描
    - **创建 hash 字段索引**, 查询性能稳定, 有额外的存储和计算消耗, 不支持范围扫描
23. 合理的增加冗余字段
24. 所有字段都要有默认值: null 的影响
25. force index() 防止优化器选错索引
26. 尽量不要使用关联子查询: 过程就慢
27. **适当增加冗余字段**: 不是所有的东西都能解决的{有时候需要业务的妥协}
28. 最小数据长度 + 最简单数据类型: 不要把字段定义的很大
29. 如果查询包括 GROUP BY 但你并不想对分组的值进行排序, 你可以指定 ORDER BY NULL 禁止排
30. in/notin 转换为 join 快是因为不需要临时表(子查询)
31. 长事务意味着系统里面会存在很老的事务视图, 导致当前读的慢
    - RR 下, tx_A 开始, tx_B 也开始执行大量更新[tx_B 先提交], A 是`当前读`, 就要依次执行 undo log, 直到找到事务 B 开始前的值
32. 脏页问题+redolog 配置太小: 性能一卡一卡

### 典型案例

1. `b varchar(10) DEFAULT NULL` + 身上有索引 + 值为 1234567890 的有 10w

   - `select * from table_a where b='1234567890abcd';`
   - mysql 会字符截断: 因为引擎里面这个行只定义了长度是 10, 所以只截了前 10 个字节, 就是 '1234567890' 进去做匹配
   - 这样满足条件的数据有 10 万行
   - 因为是 `select *,` 所以要做 10 万次回表
   - 但是每次回表以后查出整行, 到 server 层一判断, b 的值都不是’1234567890abcd’
   - 返回结果是空
   - 执行过程中可能经过函数操作, 最终在拿到结果后, server 层还是要做一轮判断的

2. 唯一索引的并发影响
3. 扣库存

   - 多个并发事务操作同一行的同一个字段
   - 针对同一行数据, 一个事务必须要等上另一个事务执行完成之后才能执行自己的更新语句, 所以越来越慢(行锁)
   - solution:
     1. 看看能不能拆分成多条记录: 把这一个锁, 变成多个锁
     2. 预减库存: 先过滤一下流量, 放进了的多是有效流量
