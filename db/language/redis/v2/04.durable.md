### durable: 默认开启 RDB[断电丢数据问题]

1. 持久化

   - AOF: 指令级别的, 设置多久改动一次就执行一次 aof; redis 重启时数据恢复很慢[数据量大的话]
     - aof 文件重写: 将多次操作 key 的指令把柄成一个[为了恢复数据嘛]
   - RDB: 数据级别的, 快照, 设置多久改动一次就执行一次快照, 会丢数据, 数据恢复快
   - 4.0 之后可同时打开 AOF 和 RDB, 但是没有打开 混合持久化 时重启会使用 AOF 策略
   - 混合持久化: 需要保证 aof 和 rdb 都打开

     ```js
     aof-use-rdb-preamble no
     ```

     - bgrewriteaof: 会将 此时的 rdb 文件写入 aof[为了快速重启], 重写期间的新命令会在内存中, 直到重写结束后才会 以 aof 文件的方式写入 aof 文件

   ![avatar](/static/image/db/redis-duration-overview.png)

#### RDB: 会丢数据, 但是恢复快[只在 Slave 上持久化 RDB 文件]

1. RDB 快照不会在事务执行时执行: 即使宕机也能保持事务数据的一致性
2. rdb 存盘的是某一时刻的数据:

   - ~~单线程阻塞不对外提供服务~~
   - linux 的父子进程, 常规上是数据隔离的

     ```shell
     echo $$ | more # 输出父进程ID, 原因是 $$ 优先级高于 |
     echo $BASHPID | more # 输出子进程ID

     num=1
     echo $num       # 1
     /bin/bash       # 开启子进程
     echo $num       # --, 此时可以 export num 就可以看见了
     exit
     echo $num       # 1

     # export 的变量 子进程修改对父进程不可见
     # export 的变量 父进程修改对子进程不可见
     ```

   - 创建子进程的问题: fork
     1. 速度
     2. 内存空间问题
   - rbd: 二进制 + 数据压缩

3. 相关命令: `save/bgsave`

   - 目录配置
     1. 默认是 rdb 文件名为 dump.rdb
     2. dir
     3. dbfilename
     4. 存储的文件: dbfilename + dir
   - 触发快照: 一个执行完后一个才能执行, 顺讯写
     1. 手动触发 save <seconds> <change>: 阻塞{比如关机维护}
     2. 手动触发 bgsave(fork): 非阻塞
     3. 配置文件中 save: 其实触发的是 bgsave
     4. `save ""` 标识禁用 rdb
     5. flushall 也会产生 dump.rdb 文件, 但是内容 null

4. 概念

   - 在指定时间隔内将内存中的数据集快照写入磁盘, 恢复时直接将快照文件读到内存
   - redis 会单独创建[fork]一个子线程来进行持久化, 先将数据写到一个临时文件中, 带到持久化结束后替换场次的持久化文件
   - 父进程继续接收并处理客户端发来的命令, 而子进程开始将内存中的数据写入硬盘中的临时文件
   - 持久化过程, 主线程不进行任何 IO[fork 结束之后就可以对外提供服务, 其他的 IO 操作由子进程进行]

5. fork[指针+cow]: {与数据量相关}速度快, 占用空间小

   - 复制一个与当前进程完全一样的进程[**变量, 环境变量, 程序计数器**]等, 并且作为原进程的子进程`[会造成间断性的暂停服务] + master 不要有rdb操作`
   - fork 进程时 redis 是不对外提供服务的, fork 进程完成的瞬间对内存是没有明显的影响的
   - 在执行 fork 的时候操作系统[Unix]会使用写时复制[copy-on-write]策略, 即**fork 函数发生的一刻父子进程共享同一内存数据**, 当父进程要更改其中某片数据时[如执行一个写命令], _操作系统会将该片数据复制一份并修改原数据, 子进程读取数据副本保证数据不受影响_, 所以新的 RDB 文件存储的是执行 fork 一刻的内存数据
   - 而子进程开始将内存中的数据写入硬盘中的临时文件, 完成后替换原文件
   - 为此需要确保 Linux 系统允许应用程序申请超过可用内存[物理内存和交换分区]的空间, 方法是在/etc/sysctl.conf 文件加入 vm.overcommit_memory = 1, 然后重启系统或者执行 sysctl vm.overcommit_memory=1 确保设置生效
   - RDB 文件是经过压缩[可以配置 rdbcompression 参数以禁用压缩节省 CPU 占用]的二进制格式, 所以占用的空间会小于内存中的数据大小, 更加利于传输
   - **fork 出子进程的过程是阻塞的**

6. feature

   - 优点: 适合大规模的数据恢复
   - 缺点: 只有一个 rdb 文件, 要是坏了就糟了
   - 缺点: 对数据的完整性要求不高, 丢数据可能性大一点
   - ~~fork 时需要 2 倍的内存~~: 这个是错误的
   - **不能过于频繁的执行 bgsave/save, 和数据的完整性有一定的冲突: 磁盘写入压力太大[任务堆积且执行时间长 cow 机制会导致占用更多的内存] + frok 子进程是需要资源的**
   - bgsave/save 会触发 IO 操作, 所以也不会让一个 redis 的内存过于大

7. 执行时机

   - 手动执行 bgsave
   - 手动执行 save
   - 自动执行 save
   - 从节点连接到主节点发送 sync 命令, master 会执行 bgsave
   - shutdown/flushall

8. conclusion

   ![avatar](/static/image/db/redis-rdb.png)

#### AOF

1. 概念: **全量**

   - 以**写后日志**的形式来记录每个`写操作`的顺序指令序列, 重启时从头到尾执行一遍
   - aof 文件很大的话会很慢

   ![avatar](/static/image/db/redis-aof-proc.png)

2. 存储的文件

   - 开启: appendonly yes/no
   - 文件名称: appendfilename

3. aof 文件恢复

   - 备份被写坏的 aof 文件
   - redis-check-aof --fix
   - restart

4. aof 的写操作

   - **是由主线程完成写操作的: 线程阻塞后续的写操作** + 所以出现了写回策略[控制写回磁盘]
   - bgwriteaof 是其他非主线程操作的
   - aof 是写后日志, 会存在内存数据修改成功, 但是没有记录到日志的情况
   - redis 的解决方案: 写回策略

5. aof 写回策略: 调用 flush 进行刷盘

   - appendfsync always: [性能差] + 同步写回, 写指令执行完毕立马将 aof_buf 缓冲区中的内容刷写到 AOF 文件
   - **appendfsync everysec**: [折中] + 日志只会同步写到 AOF 文件缓冲区[不是 1s 内数据汇总的指令], ~~异步~~每秒一个且 buffer 满了会自动刷盘, 所以最多丢 min(1buffer, 1sdata)
   - appendfsync no: [丢数据多] + 交给系统决定, **不是不同步**, 可能会丢失一个 buffer 大小的数据
   - 根据系统对高性能和高可靠性的要求，来选择写回策略

6. rewrite

   - redis 会当 aof 文件大于 64M 且 size{重写后的 size} 翻倍时重写
   - bgrewriteaof: fork 出来一个子进程, 将 aof 文件重写[先写入临时文件(新:不会污染原来的文件)]: 遍历内存将内存转换为 redis 指令, 在写入 aof 文件, 完成后替换原来的 aof 文件
   - bgrewriteaof: 重写期间的新命令会在旧的 aof 缓冲区和 aof 重写缓冲区, _直到重写结束后才会将 aof 重写缓冲区内容写入 新的 aof 文件_
   - aof 重写 redis 会先执行一个内存的 copy[**为什么不共用一片内存呢** *次数少 + 耗时(即使使用 cow 也会有很多复制分配空间) + 不阻塞主线程(对内存有独立的控制权)*], 用于生产新的记录; 使用两个日志[旧的 aof 日志/缓冲区 + 新的 aof 重写日志/缓冲区]保证数据一致性和重写数据的不丢失
   - 使用两个日志: 避免父子进程竞争 + aof 重写失败不会污染源文件数据

   - 4.0 之前会 fork 出一个新的进程将文件重写[先写入临时文件]: ~~是删除抵消的命令 + 合并重复的命令~~
   - 4.0 之后会 rbd + aof

7. feature

   - 数据丢失概率小
   - 如果同时开启了 RDB 和 AOF, 数据恢复时只会使用 AOF
   - aof 文件大于 rdb 时重启恢复慢: bgrewriteaof
   - no 时效率与 rdb 相同
   - flushall 发生之后且没有发生 rewriteaof 数据是可以恢复的

8. conclusion

   ![avatar](/static/image/db/redis-aof.png)

#### 混合持久化{4.0}: RDB 的快 + AOF 的全量

1. 需要保证 aof 和 rdb 都打开

   ![avatar](/static/image/db/redis-durable.png)

   ```js
   aof-use-rdb-preamble no
   ```

2. rdb 文件写入 aof[为了快速重启] + rewrite
3. 触发时机
   - rdb 触发
   - bgwriteaof 也会触发
4. 总结
   - 重启 Redis 时, 很少使用 rdb 来恢复内存状态, 因为会丢失大量数据, 但是重放 AOF 日志性能相对 rdb 来说要慢很多
   - Redis 4.0 使用混合持久化将 rdb 文件的内容和增量的 AOF 日志文件存在一起
   - AOF 日志不再是全量的日志, 而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志, 通常这部分 AOF 日志很小
   - 于是在 Redis 重启的时候, 可以先加载 rdb 的内容[本来就快], 然后再重放增量 AOF 日志[少, 所以快]就可以完成
   - **所以 RDB 内存快照以稍微慢一点的频率执行, 在两次 RDB 快照期间使用 AOF 日志记录期间发生的所有「写」操作**: aof 文件就不会变的很大

#### 日志

1. 写前日志[WAL]: 在实际写数据之前, 将修改的数据写到日志文件中, 故障恢复得以保证
   - mysql 的 redolog 就是典型的 wal + bin log 实现二阶段提交/回滚
2. 写后日志: 先执行写指令[redis 修改内存数据], 之后记录日志
   - 简单, 不需要做语法等检查, 否则记录出错误的命令
   - 不会阻塞当前写操作
3. 写回策略
   - 为了提高文件的写入效率, 当用户调用 write 函数, 将一些数据写入到文件的时候, 操作系统通常会将写入数据暂时保存在一个内存缓冲区里面, 等到缓冲区的空间被填满、或者超过了指定的时限之后, 才真正地将缓冲区中的数据写入到磁盘里面
   - 这种做法虽然提高了效率, 但也为写入数据带来了安全问题, 因为如果计算机发生停机, 那么保存在内存缓冲区里面的写入数据将会丢失
   - 为此, 系统提供了 fsync 和 fdatasync 两个同步函数, 它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面, 从而确保写入数据的安全性
