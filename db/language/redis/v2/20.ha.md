## HA

1. 高可用的宽泛定义

   - 数据尽量不丢失: 单机不丢失 + 集群间不丢失
   - 服务尽可能提供服务: 发生网络节点故障分区, 宕机也要对外提供服务

2. 单机/单节点/单实例的问题: `高可用 --> 解决单点故障 --> 加机器[主备/主从{读写(写操作)分离}/主主] --> 有可能引起数据一致性问题[cp/ap]`

   - 单节点故障: keepalived || AKF
     1. x 轴(加机器): 主备(镜像全量) || 水平扩展
     2. y 轴(拆业务): 业务上拆分为多个独立单元
     3. z 轴(做分片): 对某个业务进行分片处理
   - 容量问题
   - 压力问题: 并发/连接

   ![avatar](/static/image/dist/dist-akf.jpg)

   - 最终的解决方案: 主从 -- 其中的主单点(否则彼此同步有资源竞争/时效等问题) --> **主(主备)从 / 主从+哨兵**

3. 主备带来数据一致性问题

   - 同步强一致性{破坏可用性}: client 写之后 server 所有节点阻塞到数据完全一致{成功/失败}
   - 异步弱一致性{异步 + 容忍数据丢失一部分}: client 写之后主节点成功则返回, 主节点将信息已给交给备机, 如果交给备机之前主机宕机, 备机生主机, 则数据丢失
   - 最终数据一致性{解决丢失问题的一种方案/可能取到不一致性的数据}: client 写之后主节点, 主节点将数据丢给 kafka{可靠[集群]/响应快}之后才返回, 备机可以通过 kafka 拿到所有的数据

4. 集群中的节点数量一般是奇数个, 且投票抉择是需要半数以上节点的{否则会脑裂问题}

   - 3 个节点需要至少 2 票, 能容忍一个出问题{分区[包含宕机]}
   - 4 个节点需要至少 3 票, 能容忍一个出问题, 但是 4 台机器出问题的风险比 3 台大
   - 另外 4 比 3 台更容易投出僵持结果: 3 台是只有每个人都的一票是才会僵持; 4 台是没人一票会僵持, 两个两票也会僵持

5. redis ha 的方案
   - sm
   - sentinel: Raft
   - cluster: Raft

### master-slave: 主从复制

1. 简介

   - redis 使用默认的异步复制: 低延迟+高性能
   - 从机拿到[加载或执行] rdb 中的 key 已经过期的时, 则会删除该 key

2. 概念: `配从不配主`

   - master: 写为主, slave: 读为主
   - 读写分离
   - 容灾恢复

3. 主从同步的问题

   - **故障恢复无法自动化**
   - 写操作无法负载均衡
   - 存储能力受到单机的限制
   - 并发连接问题

4. 主从复制的作用

   - 故障恢复: 当主节点宕机, 其他节点通过手动或者字段的方式依然可以提供服务保证数据安全性
   - 负载均衡: Master 节点提供写服务, Slave 节点提供读服务, 分担压力{横向扩展的系统的读负载}
   - 高可用基石: 是哨兵和 cluster 实施的基础

5. 手动故障恢复大概流程
   - 选定一个从节点对其执行 slaveofnoone 命令, 使其变成一个新的主节点
   - 将其他从节点变成新主节点的从节点, 执行命令 slaveof 新 IP 新 port
   - 更新客户端的 Redis 连接信息, 重启应用
   - 启动发送了故障的主节点, 执行 slaveof 新 IP 新 port 使其变成新主节点的从节点

#### 操作手册

1. `slaveof ip port`: `info replication`

   - 每次断开与 master 的链接都会使得 slave 失效, 或者可以改配置文件 `replicaof <masterip> <masterport>`
   - 中途变更会清除之前的数据并重新开始拷贝

2. 一主二从:

   - 从机是只读的
   - 从机全量复制
   - 主机 shutdown 从机还是原地待命
   - 主机恢复依旧是主机
   - 从机 down 没有关系

3. 薪火相传

   - 上面的把所有 slave 都挂到同一个主机上, 会影响主机的写性能
   - master - salve[salve] -slave

4. 反客为主
5. salveof no one: 恢复为主机

#### 复制原理

1. 主从库第一次**全量复制**: 建立连接 + 主库同步数据到从库 + 发送之后同步期间的命令到从库

   - slave 启动执行 replicaof 成功, 连接到 master 后会发送一个 psync 命令[runid+offset]: 告诉主库需要同步, 主库回复确认就可以同步
     1. runid: redis 实例的唯一标识, 第一次不知道主库 id 则设置为?
     2. offset: -1 表示第一次同步, 其他则表示复制偏移量
   - master 会回应 fullresync[标识全量同步] 并带上 runid+offset: 从库会记下以待下次使用
   - master 启动后台的存盘进程[bgsave(fork)], 生成 rdb 文件, master 将传送整个数据文件到 slave
   - 同时 master 会为每一个 slave 都创建一块 replication buffer`[保证主从数据一致性]` 的缓冲器: 记录着生成 rdb 文件之后的所有写命令
   - slave 服务在接收到数据库文件数据后, 将其存盘, 清空当前数据库数据, 并加载到内存中, 之后通知 master buffer 可以继续同步
   - master 继续将新的所有收集到的修改命令[rep-buf]依次传给 slave, 完成同步

   ![avatar](/static/image/db/redis-ha-sm-full.png)

   - repl-diskless-sync no: 作用于全量复制过程中, 无盘复制{主节点不再先把数据写入 RDB 文件, 而是直接写入 slave 的 socket 中}
   - repl-diskless-sync-delay 5: 作用于全量复制过程中, 当主节点使用 diskless 复制时, 决定主节点向从节点发送之前停顿的时间[单位是秒]
     1. 向 slave 的 socket 的传输一旦开始, 新连接的 slave 只能等待当前数据传输结束, 才能开始新的数据传输
     2. 多个从节点有较大的概率在短时间内建立主从复制
   - client-output-buffer-limit slave 256MB 64MB 60: 与全量复制阶段主节点的缓冲区大小有关

2. 主从库间网络断开重连同步: 2.8 之前是会重新进行全力同步的; 之后采取增量复制进行同步

   - repl-timeout: 超过时间主节点会认为从节点出现故障不可达

3. 增量复制同步

   - 用于网络中断等情况后的复制, 只将中断期间主节点执行的写命令发送给从节点, 与全量复制相比更加高效
   - repl_backlog_buffer: master **的环形数组**+记录写操作+全局一个 salve 公用, master_repl_offset 记录自己写到的位置偏移量, slave_repl_offset 记录已经读取到的偏移量
   - 当主从连接断开之后, slave 会先发送 **psync** 命令[runID/slave_repl_offset]给 master
   - master 判断如果 master_repl_offset 与 slave_repl_offset 差大于分配的内存, 则直接进行全量同步
   - 否则 master 会将之间的命令同步给从库即可

   ![avatar](/static/image/db/redis-ha-psync.png)

4. 主从正常运行期间的同步

   - 完成全量同步后 sm 之间会一直维护一个网络[长连接的命令传播]连接: master 通过连接将后续陆续收到的命令操作再同步给从库, 长连接避免频繁建立连接开销
   - [sm 心跳]m --> s: ping , 为了让从节点判断是否超时
   - **[sm 心跳]**s --> m: REPLCONF ACK, s 每秒一次想 master 发送 `REPLCONF ACK <replication_offset>`
     1. 检测主从网络
     2. 辅助实现 min-slaves
     3. 检测命令丢失: 主节点通过 repl_backlog_buffer 推送缺失数据

5. 判断是否是全量同步

   ![avatar](/static/image/db/redis-ha-sm-full-part.png)

6. replication buffer: 传播写命令到从库 + 保证主从数据的一致性

   - **主从全量同步时使用**
   - 记录 rdb 文件之后的所有写命令
   - master 为每个 slave 都开辟一块内存
   - 数据内容是
     1. master 执行 bgsave 产生 RDB 的期间的写操作
     2. master 发送 rdb 到 slave 网络传输期间的写操作
     3. slave load rdb 文件把数据恢复到内存的期间的写操作
   - 配置: client-output-buffer-limit, 值太小则会导致主从复制断开

7. repl_baklog_buffer:

   - **为了支持从库增量复制**
   - master **的环形数组{连续内存}** + 全局一个 salve 公用
   - 记录 master 得写操作偏移量 + 不同 slave 的复制偏移量
   - repl_backlog_buffer 值也要大, 避免 slave 还没有读取就被覆盖 = 2 \* second \* write_size_per_second
   - repl-backlog-size 是配置, 默认是 1M
   - repl-backlog-ttl 3600: 当主节点没有从节点时, 复制积压缓冲区保留的时间

   ![avatar](/static/image/db/redis-ha-sm-buffer.png)

8. 主从同步断开的情况

   - salveof no one
   - repl-timeout
   - repl-ping-slave-period 10: 与命令传播阶段主从节点的超时判断有关
   - client-output-buffer-limit, 值太小则会导致主从复制断开
   - 主节点数据量较大, 或者主从节点之间网络延迟较大导致的该**缓冲区的大小超过了限制**, 此时主节点会断开与从节点之间的连接
   - [改大 rep-buf]可能引起全量复制 -> replication buffer 溢出导致连接中断 -> 重连 -> 全量复制 -> replication buffer 缓冲区溢出导致连接中断……的循环
   - 主从连接断开之后 master 会释放连接相关的数据 rep-buf 也释放了

9. 主从复制使用 rdb 原因

   - RDB 文件是二进制文件且小: 网络传输 RDB 和写入磁盘的 IO 效率都要比 AOF 高
   - 从库进行数据恢复的时候, RDB 的恢复效率也要高于 AOF

10. 每个 client 连上 Redis 后, Redis 都会分配一个专有 client buffer, 所有数据交互都是通过这个 buffer 进行的

    - redis 先把数据写到这个 buffer 中, 然后再通过网络发送出去, 这样就完成了数据交互

#### 主从应用

1. 读写分离的问题

   - slave 数据过期问题
     1. 从 slave 节点读取数据会执行惰性删除策略
     2. redis: 惰性删除、定时删除
   - sm 数据不一致问题 & 延迟问题
     1. 主从节点的网络环境
     2. 监控从节点的延迟性, 如果延迟过大, 则通知应用不从该节点读取数据: 一般不使用
     3. 从节点的 slave-serve-stale-data: 控制着从节点对读请求的响应情况{Y-接受客户端命令; N-只接受 info/slaveof 少数的命令}
   - 从节点故障

2. 单机内存大小限制: 单机内存不要太大

   - 单机 10G, 主从同步则需要几分钟
   - 且 slave 过多会导致 master 压力很大: push 数据模式, 影响性能
   - 数据大, 全量同步时产生 rdb 则会更耗时: slave 超时则会触发重试。之后循环
   - bgsave 是 cow: 过程耗时长则也会导致内存的很多消耗, 一般为 bgsave 留 30-45%的内存

3. 要避免全量复制

   - 流程[长]: `建立连接 ---> 生成 RDB 文件 ---> 发送 RDB 文件 ---> 清空旧数据 ---> 加载新数据`
   - 全量复制: 第一次复制 || 节点运行 ID 不匹配(重启会变){修改主节点配置要安全冲去-debug reload} || 复制偏移量 offset 不在复制积压缓冲区中{变大些}
   - `复制积压缓冲区大小 > 平均中断时长 * 平均写命令字节数`
   - **主从切换 || 重启时: PSYNC2 也会优先部分复制**

4. 规避复制风暴

   - 大量从节点对同一主节点或者同一台服务器的多个主节点短时间内发起全量复制的过程: 复制风暴会导致主节点消耗大量的 CPU、内存、宽带, 所以我们需要尽可能的规避复制风暴
   - 单一主节点: 减少从节点数量 || 做薪火传递
   - 单一机器: 加机器 || 避免故障恢复后的密集复制

5. 主从复制配置汇总

   - slaveof ip
   - repl-timeout 60: 主从节点连接超时判断有关
   - 主节点

     1. repl-diskless-sync no: 作用于全量复制阶段, 控制主节点是否使用 diskless 复制, 默认是关闭
     2. repl-diskless-sync-delay 5: 作用于全量复制阶段, 当主节点使用 diskless 复制时，该配置决定主节点向从节点发送之前停顿的时间
     3. client-output-buffer-limit slave 256MB 64MB 60: 全量复制阶段主节点的缓冲区大小有关
     4. repl-disable-tcp-nodelay no: 与命令传播阶段的延迟有关
     5. masterauth: 与连接建立阶段的身份验证有关
     6. repl-ping-slave-period 10: 与命令传播阶段主从节点的超时判断有关
     7. repl-backlog-size 1mb: 复制积压缓冲区的大小
     8. repl-backlog-ttl 3600: 当主节点没有从节点时, 复制积压缓冲区保留的时间, 断开的从节点重新连进来时则可判断是否全量复制; 0-永不释放
     9. min-slaves-to-write 3 与 min-slaves-max-lag 10: 规定了主节点的最小从节点数目, 及对应的最大延迟

   - 从节点
     1. slave-serve-stale-data yes: 与从节点数据陈旧时是否响应客户端命令有关
     2. slave-read-only yes: 从节点是否只读; 默认是只读的. 由于从节点开启写操作容易导致主从节点的数据不一致, 因此该配置尽量不要修改

### sentinel: 高可用(故障转移)

1. diagram

   ![avatar](/static/image/db/redis-sentinel.png)

2. 功能

   - 集群监控: 负责监控 redis master[确定 master 真宕机/假死] and slave 是否运行正常
   - 消息通知: 某个 redis 实例有故障, 那么哨兵负责发送消息负责报警发送给管理员或程序
   - 故障转移: 如果 master 挂了, 则自动转移到 slave[选择谁], 并将其他 slave 配置到该 master + 通知 client 新的 master 地址
   - 配置中心: sentinel 充当客户端服务发现的来源, 客户端连接到哨兵以获取服务地址[出现故障后 哨兵会报告新的服务地址]

3. **哨兵可以同时监视多个主从服务器**
4. 问题

   - 由于所有的写操作都是先在 Master 上操作, 然后同步更新到 Slave 上, 所以从 Master 同步到 Slave 机器有一定的延迟, 当系统很繁忙的时候, 延迟问题会更加严重, Slave 机器数量的增加也会使这个问题更加严重
   - 内存: 内存很难搞到很大: 一台 主从 电脑 嘛
   - 并发问题: 理论上 10w+ 就到极限了
   - 瞬断问题: master 挂了, 需要时间取选举出新的 master, 此时 redis 不能对外提供服务

5. 大概的流程

   - 主节点出现故障导致不可用, 从节点和客户端都与其失去联系
   - Sentinel 节点通过定时监控发现主节点出现了故障, 判断其不可用[可能是某个节点主观认为不可用], 当大多数 Sentinel 对主节点的故障判断达成一致时, 就会选举一个 Sentine-1 节点作为领导者来负责故障转移
   - Sentinel-1 通过一定规则选择其中一个从节点作为新的主节点, 然后整个过程就和上面手动恢复一致了(过程中也是优先部分复制{PSYNC2}), 只不过它是又 sentinel-1 来自动完成的

#### 操作手册 配置: 一组 sentinel 能同时监控多个 master

1. 哨兵的格式一般配置为单数: 资源 + 故障概率
2. 投票需要超过半数: 避免脑裂
3. 反客为主的自动版, 能够后台监控主机是否故障, 如果故障了根据投票数自动将从库转换为主库
4. 调整结构, 6379 带着 80、81
5. 自定义的/myredis 目录下新建 sentinel.conf 文件, 名字绝不能错
6. 配置哨兵, 填写内容

   ```conf
   # 绑定IP
   bind 0.0.0.0
   # 后台运行
   daemonize yes
   # 默认yes, 没指定密码或者指定IP的情况下, 外网无法访问
   protected-mode no
   # 哨兵的端口, 客户端通过这个端口来发现redis
   port 26380
   # 这个文件会自动生成（如果同一台服务器上启动, 注意要修改为不同的端口）
   pidfile /var/run/redis-sentinel-26380.pid
   # sentinel monitor: 代表监控
   # mymaster: 代表主节点的名称, 可以自定义
   # 127.0.0.1: 代表监控的主节点 ip
   # 6379: 代表端口
   # 2: 法定数量, 代表只有两个或两个以上的哨兵认为主节点不可用的时候, 才会把 master 设置为客观下线状态, 然后进行 failover 操作
   sentinel monitor mymaster 127.0.0.1 6379 2
   # 当有 N 个哨兵实例时, 该数字要是 N/2 + 1 个

   # Sentinel 判断实例进入主观下线所需的时间长度
   # 且要保证所有哨兵该值是一致的: 防止哨兵集群一直没有达成 master 故障的共识
   # sentinel down-after-milliseconds <master-name> <milliseconds>
   ```

7. 启动哨兵

   - Redis-sentinel /myredis/sentinel.conf
   - 上述目录依照各自的实际情况配置, 可能目录不同

8. 正常主从演示
9. 原有的 master 挂了
10. 投票新选
11. 重新主从继续开工, `info replication` 查查看
12. 问题: 如果之前的 master 重启回来, 会变成 slave

#### 选举原理

1. 监控

   - 防止假死[客观下线(一定数量{Quorum}哨兵认为节点下线)/主观下线(某个哨兵认为的节点宕机)]
   - 主观下线: 哨兵发现 slave 没有在规定时间内应答, 则将其标识位`主观下线`[集群正常工作不受影响]
   - 客观下线: 哨兵发现 master 没有在规定时间内应答, 则不能标记为主观下线[影响太大], 需要半数以上的哨兵都认为下线才会被标记为客观下线[大多数人认为这个客观事实了]
   - 只有客观下线才会触发哨兵主导的主从切换
   - **降低哨兵误判率**: 误判一般会发生在集群网络压力较大、网络拥塞, 或者是主库本身压力较大的情况下 + [解决]多人(引入集群)投票(客观下线)

2. 切换时选取 slave 的规则

   - 下线的 slave 不选
   - 评估网络连接状态: 经常断连的不选 + 超过该 `down-after-milliseconds * 10` 时间
   - 余下的 slave 评分: 打分会按照三个规则进行三轮打分
     - slave 优先级: 通过 slave-priority 配置, 优先级高的直接晋级为新 master
     - 比较 slave 与旧 master 复制进度的差距: slave_repl_offset 与 master_repl_offset 进度差距, 如果一样就继续下一个规则
     - slave runID: 在优先级和复制进度都相同的情况下, ID 号最小的从库得分最高, 会被选为新主库

3. 哨兵之间的通信

   - pub/sub 实现哨兵间通信和发现 slave
   - 哨兵通过订阅 master 的 pub/sub 频道: 哨兵会发布自己信息[ip+port], 从而相互发现建立连接并交互

4. 哨兵做的事情

   - 哨兵向 master 发送 INFO 命令: 10s 一次, 获取集群信息[主要是哨兵], 之后哨兵会与每一个 slave 建立连接[通过该连接监控 slave]
   - 每隔 2 秒, sentinel 节点都会向主从节点的 `_sentinel_:hello` 频道发送自己的信息: 发现新的 sentinel 节点 & sentinel 节点之间交换主节点的状态[作为后面客观下线以及领导者选择的依据]
   - 每隔一秒, 哨兵会每个主从节点、Sentinel 节点发送 PING 命令: 运行状态监控, 哨兵领导者的选举等细节操作

5. **选取出执行切换的哨兵**: raft -- epoch+quorum

   - 任意一个 哨兵 发现 master 主观下下后, 就会给其他哨兵发送: `is-master-down-by-addr`
   - 其他哨兵会根据自己与 master 的链接情况作出应答: Y(赞成 master 宕机)/N(反对)
   - 当超过半数赞成票之后 master 则会被标记为客观下线,
   - 之后想其他哨兵发送命令: **表明自己想要执行主从切换**, 其他哨兵进行投票[leader 选举]

     - 成为 leader 必须有半数以上的哨兵的赞成票
     - 且赞成票数量大于配置文件中的 quorum 值`[哨兵单数]`: 没选出来则进行下一轮
     - 获取票: 这一票没有投给其他人, 每一轮每个哨兵只有一票

   - flow sample:

     1. 加入有 A、B、C、D 四个节点构成 Sentinel 集群
     2. 加入 A 率先完成客观下线, 则 A 会向 B、C、D 发出成为领导者的申请, 由于 B、C、D 没有同意过其他 Sentinel 节点, 所以会将投票给 A，A 得到三票,
     3. B 则向 A、C、D 发起申请, 由于 C、D 已经同意了 A, 所以会拒绝, 但是他会得到 A 的同意, 所以 B 得到一票, 同理 C、D 得到零票, 如下图:

        | 节点 | 得到的票数 |
        | ---- | ---------- |
        | A    | B 、C、D   |
        | B    | A          |
        | C    |            |
        | D    |            |

        ![avatar](/static/image/db/redis-ha-sentinal-leader.png)

     4. 所以 A 会成为领导者, 进行故障转移工作

6. 通知客户端新 master

   - 通过 pub/sub 实现, 客户端可以定于哨兵的消息, 从而获取最新的 master 信息

7. flow

   - 初始化 sentinel, 将普通的 redis 代码替换成 sentinel 专⽤代码
   - 初始化 masters 字典和服务器信息, 服务器信息主要保存 ip:port, 并记录实例的地址和 ID
   - 创建和 master 的两个连接, 命令连接和订阅连接, 并且订阅 `__sentinel:hello__` 频道
   - 每隔 10 秒向 master 发送 info 命令, 获取 master 和它下⾯所有 slave 的当前信息
   - 当发现 master 有新的 slave 之后, sentinel 和新的 slave 同样建⽴两个连接, 同时每个 10 秒发送 info 命令, 更新 master 信息
   - sentinel 每隔 1 秒向所有服务器发送 ping 命令, 如果某台服务器在配置的响应时间内连续返回⽆效回复, 将会被标记为下线状态[主观下线]
   - 选举出领头 sentinel[选 leader 过程], 领头 sentinel 需要半数以上的 sentinel 同意
   - 领头 sentinel 从已下线的的 master 所有 slave 中挑选⼀个, 将其转换为 master
   - 让所有的 slave 改为从新的 master 复制数据
   - 将原来的 master 设置为新的 master 的从服务器, 当原来 master 重新回复连接时, 就变成了新 master 的从服务器

### redis 高可用集群: 3.x 扩展性(内存/连接/并发)

![avatar](/static/image/db/redis-ha.png)

1. 解决的问题:

   - 内存[横竖]: 每个集群 50 G \* 200 个 = 1T redis 空间
   - 并发: 每个主从 10w+ \* 200 个
   - 瞬断问题: 只有瞬断的哪一个在选举期间不能提供服务, 其他的主从 redis 小集群是可以提供服务的

2. 内存解决: 横竖两个方向

   - 横: 增加 redis 个数[分布式集群]
   - 竖: 升级 redis 配置, 但是大内存会导致 fork 慢等问题, 且大内存成本会急剧上升, 且在并发方向没有太大优势

3. cluster 集群时一种**去中心化**分布式数据库方案, 听过分配来进行数据的管理[分治思想], 并提高恢复和故障转移功能

   - 16384 个槽位[server]: crc16 理论上最多可以有 2^16=65536 个
   - 16384 的原因: 实际中不能会太多[多了网络就会有问题了] + 心跳信息会小[**16384 bit/8=2k**]大了会导致网络的占用 + 槽位信息是由 bitmap 保存的[槽位少 bitmap 填充率就低, 压缩就更好]

4. 如果某个主节点没有从节点, 那么当它发生故障时, 集群将完全处于不可用状态
   - 16384 个槽位都必须有人负责
   - 可以修改配置为 `cluster-require-full-coverage no` 做到允许部分节点宕机下正常工作

#### 操作手册

1. redis 安装:

   ```shell
   # http://redis.io/download 安装步骤
   # 安装gcc
   yum install gcc
   # 把下载好的redis-5.0.8.tar.gz放在/usr/local文件夹下, 并解压
   wget http://download.redis.io/releases/redis-5.0.8.tar.gz tar xzf redis-5.0.8.tar.gz
   cd redis-5.0.8
   # 进入到解压好的 redis-5.0.8 目录下, 进行编译与安装
   make & make install
   # 启动并指定配置文件 src/redis-server redis.conf[注意要使用后台启动, 所以修改 redis.conf 里的 daemonize 改为 yes
   # 验证启动是否成功
   ps -ef | grep redis
   # 进入 redis 客户端
   cd /usr/local/redis/bin/redis-cli
   # 退出客户端 quit
   # 退出redis服务: pkill redis-server; kill 进程号; src/redis-cli shutdown
   ```

2. redis 集群搭建: use redis directly || in docker

   - redis 集群需要至少要三个 master 节点, 并且给每个 master 再搭建一个 slave 节点, 每台机器一主一从, 搭建集群的步骤如下:

     ```shell
     # 第一步: 在第一台机器的 `/usr/local` 下创建文件夹 redis-cluster, 然后在其下面分别创建2个文件夾如下
     mkdir -p /usr/local/redis-cluster
     mkdir 8001
     mkdir 8004

     # 第二步: 把之前的 redis.conf 配置文件 copy 到 8001 下, 修改如下内容:
     #  1. 集群配置
         # 启动集群模式:
         # cluster-enabled yes
         # 集群节点信息文件, 这里800x最好和port对应上:
         # cluster-config-file nodes-8001.conf
         # cluster-node-timeout 5000
         # #replicaof 127.0.0.1 9000   # 注释 cluster 集群下不允许复制
     # 2. 其他配置
         # daemonize yes      # 后台启动
         # port 8001          # 分别对每个机器的端口号进行设置
         # dir /usr/local/redis-cluster/8001/  # 分别指定不同的数据文件存放位置
         # # bind 127.0.0.1   # 去掉 bind 绑定访问 ip 信息

         # protected-mode no  # 关闭保护模式
         # appendonly yes
     # 3. 密码配置
         # requirepass zhuge  # 设置redis访问密码
         # masterauth zhuge   # 设置集群节点间访问密码

     # 第三步: 把修改后的配置文件, copy到8002, 修改第 2、3、5 项里的端口号, 可以用批量替换:
     #    :%s/源字符串/目的字符串/g

     # 第四步: 另外两台机器也需要做上面几步操作, 第二台机器用8002和8005, 第三台机器用8003和8006

     # 第五步: 分别启动 6 个 redis 实例, 然后检查是否启动成功
     /usr/local/redis-5.0.8/src/redis-server /usr/local/redis-cluster/800*/redis.conf
     ps -ef | grep redis # 查看是否启动成功

     # 第六步: 用 redis-cli 创建整个 redis 集群[redis5 以前的版本集群是依靠 ruby 脚本 redis-trib.rb 实现]
         # --cluster-replicas 2: 2 表示一主二从
     /usr/local/redis-5.0.8/src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 # 代表为每个创建的主服务器节点创建一个从服务器节点

     # 第七步: 验证集群
     #  1. 连接任意一个客户端即可:
     /usr/local/redis-5.0.8/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 800*  # [-a访问服务端密码, -c 表示集群模式, 指定 ip 地址和端口号
     #  2. 进行验证:
     cluster info # 查看集群信息
     cluster nodes # 查看节点列表
     #  3. 进行数据操作验证
     #  4. 关闭集群则需要逐个进行关闭, 使用命令:
     /usr/local/redis/bin/redis-cli -a zhuge -c -h 192.168.0.60 -p 800* shutdown
     ```

   - cluster command

     ```shell
     1. create: 创建一个集群环境host1:port1 ... hostN:portN
     2. call: 可以执行redis命令
     3. add-node: 将一个节点添加到集群里, 第一个参数为新节点的ip:port, 第二个参数为集群中任意一个已经存在的节点的ip:port
     4. del-node: 移除一个节点
     5. reshard: 重新分片
     6. check: 检查集群状态
     ```

   - cluster maintain

     ```shell
     /usr/local/redis-5.0.2/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 8001
     # 查看集群状态
     192.168.0.61:8001> cluster  nodes
     # 增加redis实例
     /usr/local/redis-5.0.2/src/redis-cli --cluster add-node 192.168.0.64:8007 192.168.0.61:8001
     # 当添加节点成功以后, 新增的节点不会有任何数据, 因为它还没有分配任何的slot(hash槽), 我们需要为新节点手工分配hash槽
     /usr/local/redis-5.0.2/src/redis-cli --cluster reshard 192.168.0.61:8001
     - 个数
     - 从哪来
     # 配置8008为8007的从节点
     /usr/local/redis-5.0.2/src/redis-cli --cluster add-node 192.168.0.64:8008 192.168.0.61:8001
     /usr/local/redis-5.0.2/src/redis-cli -c -h 192.168.0.64 -p 8008
     192.168.0.61:8008> cluster replicate eb57a5700ee6f9ff099b3ce0d03b1a50ff247c3c # 先进入 8008 cli

     # 删除8008从节点
     /usr/local/redis-5.0.2/src/redis-cli --cluster del-node 192.168.0.64:8008 1805b6339d91b0e051f46845eebacb9bc43baefe
     # 删除8007主节点
     ## 必须先把8007里的hash槽放入到其他的可用主节点中去, 然后再进行移除节点操作
     /usr/local/redis-5.0.2/src/redis-cli --cluster reshard 192.168.0.64:8007
     /usr/local/redis-5.0.2/src/redis-cli --cluster del-node 192.168.0.64:8007    eb57a5700ee6f9ff099b3ce0d03b1a50ff247c3c
     ```

#### 相关细节及原理

1. cluster 集群建立的过程

   ![avatar](/static/image/db/redis-ha-cluster-connect.png)

2. **crc16 不是一致性哈希算法**

   - 一致性哈希算法, 在一定程度上解决了容错性[节点宕机带来的影响]+友好的扩展性[只影响最多一个机器的]
   - 但是 一致性哈希算法有很严重的数据倾斜问题: **可以通过虚拟节点一定程度上解决**
   - 哈希槽 crc16 的本质和⼀致性哈希算法⾮常相似, **但是对 哈希空间的定义 不同**

     - ⼀致性哈希的空间是⼀个圆环, 节点分布是基于圆环的, ⽆法很好的控制数据分布
     - ⽽ redis cluster 的槽位空间是⾃定义分

   - 容错和扩展上, 两者是一致的: 都是对受影响的数据进行转移

3. redis 集群节点采用 Gossip 协议来广播自己的状态以及自己对整个集群认知的改变

   - 集群中的每个实例都有所有哈希槽与实例之间的映射关系信息

4. 槽位定位算法 & key mapping slot:

   - 根据键值对的 key, 使用 CRC16 算法, 计算出一个 16 bit 的值
   - 然后用这个整数值对 16384(2^14) 进行**取模**来得到具体槽位
   - `HASH_SLOT = CRC16(key) mod 16384`
   - 其他: redis 也允许通过在 key 字符串里嵌入 tag 标记指定到某个槽位

5. 哈希槽又是如何映射到 Redis 实例

   - cluster create 默认会根据集群数量平分所有槽位
   - 或 CLUSTER MEET 创建集群[下线状态的{必须 16384 个槽位都分配了集群才能正常工作}] + cluster addslots [指定每个实例上的哈希槽个数]
   - 手动分配的原因: 每台机器的配置可能不一样

6. 集群下使用 get key 的流程

   - jedission 在创建 jedission 池时会获取 redis 服务器集群 ip 和 slot 信息
   - jedission 对 key 进行 crc16 处理, 计算[16384 对其取模]得到处理该 key 的 server ip
   - 命令到达指定 redis 服务器
   - 在该服务器中, 服务器将对已定位值的键进行哈希处理
   - 如果 redis server cluster 扩容之后, jedission 的 slot 和 ip 实例节点信息解释错误的了
   - 因此会发生一次重定位, 并 server 会给 jedission 一份新的 slot + ip 的数据
   - 重定位之后 jedission 会重新发送一次请求到包含这个 key 的 server
   - 在该服务器中，服务器将对已定位值的键进行哈希处理

   ![avatar](/static/image/db/redis-ha-cluster-client.png)

7. 跳转重定位

   - 当客户端向一个错误的节点发出了指令, 该节点会发现指令的 key 所在的槽位并不归自己管理
   - 这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址, 告诉客户端去连这个节点去获取数据: MOVED 错误、ASK 错误
   - 客户端收到指令后除了跳转到正确的节点上去操作, 还会同步更新纠正本地的槽位映射表缓存, 后续所有 key 将使用新的槽位映射表
   - [会触发客户端缓存更新]MOVED 错误: 负载均衡，数据已经迁移到其他实例上
   - [不触发客户端缓存更新]ASK 错误: [slot 上数据多-没做完呢]客户端请求的 key 所在的哈希槽正在迁移, client 先给目标 server 发送一个 ASKING 命令, 接着发送操作命令

8. 网络抖动

   - 网络抖动就是非常常见的一种现象, 突然之间部分连接变得不可访问, 然后很快又恢复正常.
   - 为解决这种问题, Redis Cluster 提供了一种选项 cluster-node-timeout: 表示当某个节点持续 timeout 的时间失联时, 才可以认定该节点出现故障, 需要进行主从切换. 如果没有这个选项, 网络抖动会导致主从频繁切换(数据的重新复制)

9. 故障转移: slave 发现自己的 master 下线状态后, slave 会开始故障转移

   - 从下线的 master 及节点的 slave 节点列表选择一个节点成为新主节点
   - 新主节点会撤销所有对已下线主节点的 slot 指派, 并将这些 slots 指派给自己
   - 新的主节点向集群广播一条 PONG 消息: 让集群中的其他节点知道自己变成主节点, 且已经接处理那些槽位
   - 新的主节点开始接收处理槽有关的命令请求, 故障转移完成

10. redis 集群选举原理分析[raft]: 由于挂掉的 master 可能会有多个 slave, 从而存在多个 slave 竞争成为 master 节点的过程, 其过程如下:

    - slave 发现自己的 master 变为 pFAIL: 从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举, 而是有一定延迟, 一定的延迟确保我们等待 FAIL 状态在集群中传播, slave 如果立即尝试选举, 其它 masters 或许尚未意识到 FAIL 状态, 可能会拒绝投票

      1. 延迟计算公式: `DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms`
      2. SLAVE_RANK 表示此 slave 已经从 master 复制数据的总量的 rank
      3. Rank 越小代表已复制的数据越新. 这种方式下, 持有最新数据的 p slave 将会首先发起选举[理论上]

    - 将自己记录的集群 currentEpoch[集群的配置纪元, 默认是 0] 加 1, 并广播 clustermsg_type_failover_auth_request 信息
    - 集群中其他节点收到该信息, 只有 master 响应, 判断请求者的合法性, 并发送 clustermsg_type_failover_auth_ack, 对每一个 epoch 只发送一次 ack
    - 尝试 failover 的 slave 收集 clustermsg_type_failover_auth_ack
    - 如果收集到的票 >= (N/2) + 1 支持, 那么这个从节点就被选举为新主节点
    - 如果在一个配置纪元里面 currentEpoch 没有从节点能收集到足够多的支持票, 则重复直到选出新的主节点为止

    ![avatar](/static/image/db/redis-ha-cluster-leader.png)

11. 集群数量限制

    - 集群几点尽量不要超过 1k: 网络问题[彼此心跳/通信 Gossip(知道所有槽位谁在处理)]
    - Gossip 协议工作原理大概如下

      - 从集群中随机选择一些实例按照一定的频率发送 PING 消息发送给挑选出来的实例: 用于检测实例状态以及交换彼此的信息
      - PING 消息中封装了发送者自身的状态信息、部分其他实例的状态信息、Slot 与实例映射表信息
      - 实例接收到 PING 消息后, 响应 PONG 消息, 消息包含的信息跟 PING 消息一样

    - 所以在有新节点加入, 节点故障, slot 映射变更都可以通过 PING/PONG 的消息传播完成集群状态在每个实例的传播同步

12. 集群数量限制原因: 通信消息[13] + 心跳 + slot 的 bitmap [压缩]

    - Gossip: **节点彼此不断通信交换信息, 一段时间后所有的节点都会知道集群完整的信息**
    - struct

    ```c
    typedef struct {
       char nodename[CLUSTER_NAMELEN];  //40字节
       uint32_t ping_sent; //4字节
       uint32_t pong_received; //4字节
       char ip[NET_IP_STR_LEN]; //46字节
       uint16_t port;  //2字节
       uint16_t cport;  //2字节
       uint16_t flags;  //2字节
       uint32_t notused1; //4字节
    } clusterMsgDataGossip;
    ```

    - 1 个 Gossip 消息就需要发送 104 字节, 如果集群是 1000 个实例, 那么每个实例发送一个 PING 消息则会占用大约 10KB
    - 除此之外, 实例间在传播 Slot 映射表的时候, 每个消息还包含了 一个长度为 16384 bit 的 Bitmap: 16384bit/8=2k
    - 所以 1000+的实例 ping 一次会有 12kb 的消息

13. 正常情况下的通信: 随机 5 台每 1s 发送一次 ping[少发] + 100ms 定时扫描的发送 ping

    - Redis Cluster 的实例启动后, 默认会每秒从本地的实例列表中随机选出 5 个实例, 再从这 5 个实例中找出一个最久没有收到 PING 消息的实例, 把 PING 消息发送给该实例
    - 有的实例可能一直没有收到消息, 导致他们维护的集群信息早就过期了

      - Redis Cluster 的实例每 100 ms 就会扫描本地实例列表, 当发现有实例最近一次收到 PONG 消息的时间 > cluster-node-timeout / 2
      - 那么就立刻给这个实例发送 PING 消息, 更新这个节点的集群状态信息

    - 为了避免过多的心跳消息占用集群宽带, 将 cluster-node-timeout 调成 20 秒或者 30 秒, 这样 PONG 消息接收超时的情况就会缓解
    - 但是也不能设置的太大, 否则就会导致实例发生故障了， 却要等待 cluster-node-timeout 时长才能检测出这个故障， 影响集群正常服务

#### 集群应用

1. 常见的集群方案: 无感知水平扩展+高可用+可维护性

   - 客户端分片: 部署独立机器, client 通过 hash || 一致性哈希算法 决定该 key 需要访问哪个 server
   - [proxy]codis: 转发请求 || 管理中心(分发规则/故障恢复/扩容缩容/数据迁移) || 集群管理等
   - [proxy]twemproxy: Twitter,重点**客户端分片的逻辑统一放到了 Proxy 层**
   - [proxy]predixy: 性能比较好
   - ~~redis-cerberus~~
   - **redis cluster{大家都是由这个了}**: 去中心化的思路{请求转发逻辑一部分放在客户端, 一部分放在了服务端, 它们之间互相配合完成请求的处理}

   ![avatar](/static/image/db/redis-ha-proxy.png)

2. proxy: [中心化思想]在客户端和服务端中间增加一个代理层, client 只操作代理层, 代理层进行转发请求处理
   - 就需要保证 proxy 的高可用: Keepalive
