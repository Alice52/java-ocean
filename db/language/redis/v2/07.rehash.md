### 16.渐进式 rehash 机制

1. 范围: 是整个 redis 的所有对象
   - 整个数据库就是一个全局哈希表
   - 根据 key 计算出 hash 桶的编号, 桶内元素是链表
   - 所以 Redis 为了追求快, 使用了两个全局哈希表: 用于 rehash 操作, 增加现有的哈希桶数量, 减少哈希冲突
2. redis 是通过 Dict 存储 K-V, 底层是 hashtable, 存放不同的 K-V, 但是存在 hash 冲突, 就会 rehash
   - 达到一定条件才会触发 rehash 操作, 且这个过程是渐进式的
3. 采取分而治之的方式, 将 rehash 键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上, 从而避免了集中式 rehash 而带来的庞大计算量

   ```c#
   typedef struct dict {
      dictType *type;         // 指向 dictType 结构的指针
      void *privdata;         // 保存了需要传给那些类型特定函数的可选参数
      dictht ht[2];           // 在字典内部, 维护了两张哈希表
                              // 一般情况下,  字典只使用 ht[0] 哈希表
                              // ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用
      long rehashidx;         // 记录了 rehash 目前的进度, -1标识不在 rehash
      unsigned long iterators; /* number of iterators currently running */
   } dict;

   // This is our hash table structure. Every dictionary has two of this as we
   // implement incremental rehashing, for the old to the new table.
   typedef struct dictht {
      dictEntry **table;         // 哈希表数组, 数组的每个项是dictEntry链表的头结点指针
      unsigned long size;        // 哈希表大小；在redis的实现中, size也是触发扩容的阈值
      unsigned long sizemask;    // 哈希表大小掩码, 用于计算索引值；总是等于 size-1 ；
      unsigned long used;        // 哈希表中保存的节点的数量
   } dictht;

   typedef struct dictEntry {
      void *key;                //键
      union {
         void *val;            //值
         uint64_t u64;
         int64_t s64;
         double d;
      } v;
      struct dictEntry *next; //指向下一个节点, 形成链表
   } dictEntry;
   ```

4. rehash 扩容: 哈希表的负载因子=以保存节点数 / hash 表大小

   - redis 中, 每次插入键值对时, 都会检查是否需要扩容。如果满足扩容条件, 则进行扩容
   - 在 redis 中 hash 表也是采用延迟初始化策略: 创建时没分配内存, 当第一次插入时才分配内存
   - rehash 条件: 则将哈希表大小扩容为原来的两倍
     - 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 1
     - 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 5

5. rehash 缩容

   - 条件:
     - 当哈希表的负载因子小于 0.1 时
     - 如果当前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 则不进行缩容
   - 缩容后的哈希表大小为当前哈希表中 key 数量的 2 的 n 次方, 最小容量为 4

6. 渐进式 rehash

   - 在 dict 层打开 rehash 的标志, 并分配新的 hashtable 内存
   - 操作辅助 rehash: 每一个增删改查命令中都会判断数据库字典中的哈希表是否正在进行渐进式 rehash, 如果是则帮助执行一次, 分散到多个请求上
   - 定时辅助 rehash: 服务器比较空闲, redis 数据库将很长时间内都一直使用两个哈希表, 有字典正在进行渐进式 rehash 操作, 则会花费 1 毫秒的时间, 帮助一起进行渐进式 rehash 操作

7. 小结

   - 在 redis 中, 扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面, 但是 rehash 动作并不是一次性、集中式地完成的, 而是分多次、渐进式地完成的: 服务器性能[集中式 rehash 而带来的庞大计算量]
   - rehash 步骤
     - 为 ht[1] 分配空间: 让字典同时持有 ht[0] 和 ht[1] 两个哈希表
     - rehashidx=0: 它的值设置为 0, 表示 rehash 工作正式开始
     - 在 rehash 进行期间, 每次对字典执行添加、删除、查找或者更新操作时, 程序除了执行指定的操作以外, 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] , 当 rehash 工作完成之后, 程序将 rehashidx 属性的值增一
     - 随着字典操作的不断执行, 最终在某个时间点上, ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1 , 表示 rehash 操作已完成, ht[1]变为 ht[0]
     - 因为在进行渐进式 rehash 的过程中, 字典会同时使用 ht[0] 和 ht[1] 两个哈希表, 所以在渐进式 rehash 进行期间, 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行[ 要在字典里面查找一个键的话, 程序会先在 ht[0] 里面进行查找, 如果没找到的话, 就会继续到 ht[1] 里面进行查找]
     - 在渐进式 rehash 执行期间, 新添加到字典的键值对一律会被保存到 ht[1] 里面, 而 ht[0] 则不再进行任何添加操作
   - 同时有两个 hash 表在使用, 会使得 redis 内存使用量瞬间突增: 在 Redis 满容状态下由于 Rehash 会导致大量 Key 驱逐

![avatar](/static/image/db/redis-data-hash.png)

---

## reference

1. [rehash](https://www.cnblogs.com/williamjie/p/11205593.html)
