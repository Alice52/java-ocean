## 内存相关: `单机4-6G`

0. redis 中一个字母就占用一个 byte: Redis 是 C 语言开发的, char 占用一个 字节
1. 配置中 maxmemory 配置最大使用内存, 内存超出则会淘汰之前的数据, 如果无法淘汰则会报错

   - ~~也可以配置当 Redis 内存超出物理内存限制时, 内存的数据会开始和磁盘产生频繁的交换 (swap)~~
   - 内存满了会触发缓存淘汰, 之后内存还是不够就会报错
   - 不配置默认(0) 64 位机器默认使用最大内存+ 32bit 隐式 3G: 单位是字节 byte
   - 查看: info memory / config maxmemory / 配置文件

2. 过期策略: `redis 使用了 惰性删除 和 定期删除(Redis 每秒 10 次)`

   - [省内存耗性能]定时删除{定时器}: 数据过期后马上就被删除, CPU 要时刻计算着过期的 key 压力过大
   - [耗内存省性能]惰性删除(阻塞): 数据过期不处理, 等到下次使用的时候判断是否过期, 会导致有很多不被访问的 Key
   - {**主线程执行 4.0 之后可以配置成异步的 lazyfree-xx**}定期删除: 是对上两种的折中, 每 1s 时间执行 10 次删除, 限制删除操作的时长和频率减少删除操作对 CPU 的影响

     - 周期性轮询, 随机抽取[一部分 key]{20 个}, 删除其中过期的 key, 如果过期占比大于 25%, 则继续抽样过期(利用占比控制删除频率)
     - **检测频率时长可以自定义**, 内存压力也不大
     - 还是可能导致一些 key 到期不会被删除
     - 使用前还是需要看是否过期[惰性检查]

     ![avatar](/static/image/db/redis-memory-job.png)

3. Redis 是使用了 惰性删除 + 定期删除

   - key 过期信息是用 Unix 绝对时间戳表示的: 这里就会涉及主从同步机器的时钟问题(可能导致两台机器同一个 key 的过期时间不一样)
   - 定期删除: 定期扫描只会扫描设置了过期时间的键, 设置过期时间的 Key Redis 会单独存储
   - volatile 表示设置过期时间的 key
   - redis 会记录对象最后一次被应用程序访问的时间, 一个 key 到期了并不是马上就被删除
   - 数据太多, 定时删除无法删除完全([有可能]每次删除完过期的 key 还是超过 25%), 也不会被访问了: 这些 key 的删除走的是内存淘汰策略

4. 缓存淘汰策略: 8

   - noeviction: 不在提供写服务, 只提供读删除操作; 满了之后会 set 操作会 OOM
   - volatile-lru: 针对设置了过期时间的 key least recent used
   - allkeys-lru: 针对所有 key
   - volatile-lfu
   - allkeys-lfu
   - volatile-random: 随机淘汰带有过期时间的 key
   - allkeys-random: 是随机的淘汰 key
   - volatile-ttl: Remove the key with the nearest expire time (minor TTL)
   - _noeviction 之外策略会删除 key 释放空间, 如果释放的空间不足则报错_

   ```C
   typedef struct redisObject {
     unsigned type:4;//对象类型（4位=0.5字节）
     unsigned encoding:4;//编码（4位=0.5字节）
     unsigned lru:LRU_BITS;//记录对象最后一次被应用程序访问的时间（24位=3字节）
     int refcount;//引用计数。等于0时表示可以被垃圾回收（32位=4字节）
     void *ptr;//指向底层实际的数据存储结构, 如：SDS等(8字节)
   } robj;
   ```

5. Redis 的 LRU: 一种常用的页面置换算法[hash + 双向链表]

   - redis 的 LRU 算法并不是真实的 LRU 算法
     - **通过抽样的方式进行删除: Redis 随机取出若干 key 在进行最近最少使用**
     - LRU 需要额外的空间进行存储[pre/next]: LRU=DLinkedList + HashMap
     - 可能存在某些 key 值使用很频繁, 但是最近没被使用, 从而被 LRU 算法删除
   - maxmemory-samples: 5
     - 3 最快, 内存少, 但是准确性太差
     - 5 平衡的好
     - 10 接近 LRU 但是耗内存
   - LRU 实现的数据类型的选择

     - DLinkedList: 新来的放入 head 单链表也可以, 但是淘汰最后一个单链表就需要遍历[因此需要使用 DlinkedList]
     - HashMap: 保存和查找都是 hash O(1)
     - 实现思路:
       1. save(key, value): 在 HashMap 找到 Key 对应的节点
          - 如果节点存在, 更新节点的值, 并把这个节点移动队头
          - 如果不存在, 需要构造新的节点, 并且尝试把节点塞到队头
          - 如果 LRU 空间不足, 则通过 tail 淘汰掉队尾的节点, 同时在 HashMap 中移除 Key
       2. get(key): 通过 HashMap 找到 LRU 链表节点
          - 因为根据 LRU 原理, 这个节点是最新访问的, 所以要把节点插入到队头, 然后返回缓存的值
     - **缺点**:
       1. 需要额外的空间进行存储 + 频繁的移动节点: **通过抽样的方式进行删除**
       2. 可能存在某些 key 值使用很频繁, 但是最近没被使用, 从而被 LRU 算法删除: **LFU 算法**

   - Redis LRU
     1. 由于 LRU 算法的缺点: redis 采用的是近似算法
     2. Redis 通过对少量的 key 采样, 并淘汰采样的数据中最久没被访问过的 key
     3. Redis 可以配置样本数量来调整算法的精度: 使其近似接近真实的 LRU 算法, 同时又避免了内存的消耗
     4. 记录对象最后一次被应用程序访问的时间: lru:LRU_BITS[24 位只能存储 194 天], 一旦超过 194 天之后就会重新从 0 开始计算[lru 属性大于全局的 lru_clock]
     5. 但是 redis 并不是比较 lru 和当前时间, 而是维护了一个全局属性 lru_clock[定时更新 100ms], 最终比较的是 lru_clock 和 lru, 节约了每次获取当前系统时间
        - lruclock > lru: 则使用 lruclock - lru 得到空闲时间
        - lruclock < lru: 则使用 lruclock_max（即 194 天） - lru + lruclock 得到空闲时间
        - 不准确, 但是本身就是近似算法无所谓啦: 如对象 A 记录的 lru 是 1 天[本质是 195 但是存不下了], lruclock 是 10 天, 这时候就会导致计算结果只有 10-1=9 天, 实际上应该是 194+10-1=203 天
   - redis lru flow
     1. Redis 在淘汰数据时, 第一次随机选出 N(maxmemory-samples) 个数据放到候选集合, 将 lru 字段值最小的数据淘汰
     2. 当再次需要淘汰数据时, 会重新挑选数据放入第一次创建的候选集合: [挑选标准]进入该集合的数据的 lru 的值必须小于候选集合中最小的 lru 值
     3. 如果新数据进入候选集合的个数达到了 maxmemory-samples 设定的值, 那就把候选集合中 lru 最小的数据淘汰

6. Redis 的 LFU: lru 的高 16 位记录访问时间, 低 8 位[0-255]记录访问频率

   - Redis 使用的是一种基于概率的对数器来实现 counter 的递增
   - r 给定一个旧的访问频次, 当一个键被访问时, counter 按以下方式递增：

     - 提取 0 和 1 之间的随机数 R。
     - counter - 初始值（默认为 5）, 得到一个基础差值 baseval, 如果这个差值小于 0, 则直接取 0
     - 概率 P 计算公式为：`1/(baseval * lfu_log_factor + 1)`: lfu_log_factor 对数因子[10]
     - 如果 R < P 时, 频次进行递增（counter++）
     - `random(0, 1) < 1 /((old_counter - 5)*lfu_log_factor + 1) ? counter++ : counter`

     ![avatar](/static/image/db/redis-flu.png)

   - 默认访问 1m 才会到最大值
   - counter 一直会增加, 所以不能反映热度, 需要一段时间不访问了就降下来
   - counter 的减少速度由参数 `lfu-decay-time[1]` 进行控制: N 分钟内没有访问, counter 就要减 N
     - 取出当前的时间戳和对象中的 lru 属性进行对比
     - 计算出当前多久没有被访问到: 比如计算得到的结果是 100 分钟没有被访问
     - 然后再去除配置参数 lfu_decay_time, 如果这个配置默认为 1 也即是 100/1=100, 代表 100 分钟没访问: 所以 counter 就减少 100。

### 查看

![avatar](/static/image/db/redis-memory-info.png)

1. info memory

   |         属性名          |                           属性说明                            |
   | :---------------------: | :-----------------------------------------------------------: |
   |       used_memory       | Redis 分配器分配的内存总量, 指 Redis 存储的所有数据所占的内存 |
   |    used_memory_human    |                 以可读的形式返回 user_memory                  |
   |     used_memory_rss     |                 Redis 进程占用的物理内存总量                  |
   |    used_memory_peak     |                    used_memory 使用的峰值                     |
   | used_memory_peak_human  |                  可读格式返回 usedmemorypeak                  |
   |     used_memory_lua     |                    Lua 引擎消耗的内存大小                     |
   | mem_fragmentation_ratio |          usedmemoryrss/used_memory 比值, 内存碎片率           |
   |      mem_allocator      |            Redis 所使用的内存分配器, 默认 jemalloc            |
   |      evicted_keys       |              由于最大内存限制被移除的 key 的数量              |

2. 内存: 对象内存 + 缓冲内存 + 自身内存 + 内存碎片
3. 对象内存

   - 占用最大的一块, 存储着所有的用户数据
   - key 对象是字符串
   - value 对象: String、Hash、List、Set、Zset, 每种数据类型在使用的时候占用的内存不同

4. 缓冲内存: 客户端缓冲、AOF 缓冲区、复制积压缓冲区

   - 客户端缓冲: 普通的客户端连接
   - AOF 缓冲区: AOF 在写入文件之前会先写入到缓冲区, 然后根据不同的持久化策略向磁盘进行同步 + AOF 重写时也有一个 AOF 重写缓冲区 + 一般 AOF 缓冲区都会比较小
   - 复制积压缓冲区: 主要用于主从同步. 在进行主从同步时, Redis 会将最新的命令写入到复制积压缓冲区, 在进行复制的时候, 会校验复制偏移量是否在复制积压缓冲区中, 如果是则进行部分复制, 否则进行全量复制. 它默认情况下是 1MB, 我们需要根据实际请求适当调整他的大小, 毕竟设置太小的话, 可能会使部分复制退化为全量复制

5. 自身内存

   - 自身内存主要指 AOF/RDB 的时候 Redis 创建子进程内存的消耗, 一般这部分的消耗会比较小

6. 内存碎片

   - 内存分配策略: 目前可选的分配器有 jemalloc、glibc、tcmalloc, 默认 jemalloc

     1. jemalloc 按照固定的空间分配, 比如 8 字节、32 字节....4KB 等
     2. 当应用程序申请的内存接近某个固定值的时候, jemalloc 则会分配固定的大小
     3. 比如申请了 6 字节, 则会分配 8 字节的空间
     4. 好处: 会减少内存分配的次数{比如申请了 20 字节的内存, 实际分配的是 32 字节的内存空间, 当应用再写入 10 字节的数据时, 则不会再次分配, 剩余的 12 字节足够用了}
     5. 缺点: 申请的和分配的空间不一样, 则剩余的空间很可能形成内存碎片, 一旦内存碎片多了,内存利用率也会随之降低, 这是很可怕的

   - **出现高内存碎片问题的情况**: 内存分配策略, 大量的更新操作, 比如 append、setrange; 大量的过期键删除, 释放的空间无法得到有效利用

     1. 分配与使用
     2. 键值对的修改{可能会以待后面使用}会造成空间的扩容或者释放并不是都会进行的
     3. 如果键值对删除了, 则会释放掉占用的空间, 形成空闲空间{并不一定能分配出去}

   - mem_fragmentation_ratio:

     1. `1~1.5`: 合理, 大部分情况下操作系统分配的内存总是总是大于实际申请的空间
     2. `>1.5`: 表明内存碎片率已经超过 50%, 此时需要采取一些措施来降低碎片率了
     3. `<1`: 表明实际分配的内存小于申请的内存了, 很显然内存不足了, 这样会导致部分数据写入到 Swap 中, 之后 Redis 访问 Swap 中的数据时, 延迟会变大, 性能会降低

   - 解决办法:

     1. 数据对齐
     2. 安全重启[高可用/主从切换]
     3. redis 4.x 配置, 通过复制拷贝将不连续的存放的数据搬到一起形成一块连续的内存空间

     ```conf
     # 开启清理内存碎片
     config set activedefrag yes

     ### 注意这两个必须全部满足才会清理碎片
     # [1/2]如果内存碎片达到了400mb: 开始清理
     active-defrag-ignore-bytes 400mb
     # [2/2]内存碎片空间占操作系统分配给 Redis 的总空间比例达到20%时: 开始清理
     active-defrag-threshold-lower 20：


     # redis 提供参数控制了清理过程中的CPU时间占比: 保证了正常处理请求不受影响
     # 表示自动清理过程所用 CPU 时间的比例不低于 25%, 保证清理能正常开展
     active-defrag-cycle-min 25
     # 表示自动清理过程所用 CPU 时间的比例不高于 75%: 一旦超过就停止清理，从而避免在清理时, 大量的内存拷贝阻塞, 导致响应延迟升高
     active-defrag-cycle-max 75
     ```

### others

1. overcommit: Linux 对绝大多数内存申请都会回复 yes, 以便运行更多的程序[因为申请内存后, 并不会马上使用内存]

   | 值  |                   含义                    |
   | :-: | :---------------------------------------: |
   |  0  | 内核检查是否内存足够,有则通过。没有则失败 |
   |  1  |   表示内核允许超量使用内存直到用完为止    |
   |  2  |        表示内核绝不过量的使用内存         |

   - redis 建议设置成 1: `sysctl vm.overcommit_memory=1`
   - redis 的建议是为了在极端情况下 linux 可以挤出来一些内存供 Redis 备份
   - **但是更建议优先配置好 maxmemory, 给机器留 20%~30% 的空闲内存优先配置好 maxmemory**

---

## reference

1. [redis-lru/lfu](https://blog.csdn.net/zwx900102/article/details/113806440)
