## Redis[remote dictionary server]: NoSQL

### 简介

1. redis 简介

   - key-value 的 NoSQL {内存级别}开源数据库
   - [集群]高并发 + 高性能 + 高扩展 + 高可用
   - 多种数据结构[本质是计算向数据移动{server 有很多方法 | 与 memcache 的 string 比可以只取一些字段}] + 速度快
   - 内存 + 异步持久化 + string max 512m
   - 解决[分布式]缓存{超热的 key} + 锁 + 数据存储 + 解决方案
   - feature: IO{epoll} + 线程{单线程}
   - redis 不适合一个操作占用大量时间, 或者存储大数据块

2. comparison k-v production

   - redis 数据可以持久化, 可以将内存中的数据写入磁盘, 重启的时候可以再次加载进入内存使用[推荐使用 aof[执行级别的, 但是指令多的化重启就会变慢] + rbd[数据级别的, 会丢数据]
   - redis 提供了 string, hash, list, set, zset 的数据结构
   - redis 支持数据备份, master-slave

3. redis 线程问题

   - 运算都是内存级别的运算
   - 单线程避免了多线程的切换性能损耗
   - 非阻塞 IO - IO 多路复用: redis 利用 epoll 来实现 IO 多路复用, 将连接信息和事件放到队列中, 依次放到文件事件分派器, 事件分派器将事件分发给事件处理器

   ![avatar](/static/image/db/rredisthread.png)

4. 基本的数据结构

   ![avatar](/static/image/db/redis-data-generic.png)
   ![avatar](/static/image/db/redis-data-struct.png)
   <!--
     ![avatar](/static/image/db/rredis-data.png)
    -->

- string: 是二进制安全的, 一个 redis 中字符串 value 最多可以是 512M
- hash: 存储对象
- list: 底层是双向无环链表
- set
- zset: 跳跃表

4. redis 底层实现 key-value 的存储使用的是 hashtable, 而且会频繁的 re-hash

   - 减少 hash 碰撞

   ![avatar](/static/image/db/rredis-data-store.png)

5. redis 作为数据库和缓存的区别

   - 作为高效缓存时, 数据安全不能得到保证
   - 缓存不是全量数据, 热点数据
   - 缓存应该随着访问变化而变化

6. redis 作为消息队列 和 MQ 的区别

### 安装

1. 默认安装目录: `/usr/local/bin`

   ```shell
   root@7d41c0bd290a:/usr/local/bin# ls -la

   ├── redis-benchmark # 性能测试工具
   ├── redis-check-aof # 修复有问题的 AOF 文件
   ├── redis-check-rdb # 修复有问题的 dump.rdb 文件
   ├── redis-cli       # 客户端入口
   ├── redis-sentinel  # 哨兵
   └── redis-server    # 服务端
   ```

2. 启动关闭

   ```shell
   # 搞一份 conf 之后
   # start up
   /usr/local/bin/redis-server /usr/local/etc/redis/redis.conf
   # shut down
   /usr/local/bin/redis-cli shutdown
   /usr/local/bin/redis-cli -p 6379 shutdown
   ```

3. docker

### 常见数据类型及指令

![avatar](/static/image/db/redis-data-type.png)
![avatar](/static/image/db/redis-data-detail.png)

![avatar](/static/image/db/redis-string-int.png)
![avatar](/static/image/db/redis-data-hash.png)
![avatar](/static/image/db/redia-data-ziplist.png)
![avatar](/static/image/db/redis-data-linkedlist.png)
![avatar](/static/image/db/redis-data-intset.png)

1. key 命令在数据很多时不建议使用: 消耗资源
   - 使用 scan 替代: cursor + key 的正则模式 + 遍历的 limit hint
2. generic

   - bluk operation: mset/mget, hmset ...
   - 原子操作: incr/decrby/hincrby
   - common
     ```shell
     # 切换数据库
     SELECT 0
     # 查看数据库key的数量
     DBSIZE
     # 清空DB
     FLUSHDB
     FLUSHALL
     ```
   - key: 查询不存在的 key 返回 nil
     ```js
     del key
     keys *
     dump key
     exists key
     expire key second
     ttl/pttl  key
     type key
     move key db
     persist ket // 删除过期时间
     rename key newKey
     ```

#### 3-1 string

0. 二进制安全

   - 二进制安全: redis server 与客户端交互式使用的是字节流[一字符对应一字节], 而不是字符流[各个语言间的对数字宽度的理解可能不一样: 数字上可能出现溢出];
   - 字节流: 只要使用的客户端具有一致的编解码, 数据就不会被破坏
   - **redis 没有数据类型的概念: 客户端存 2L, 但是 redis 返回的就是 2 字节, 此时就需要客户端自己判断类型做转换了**

1. string -- int

2. string -- sds

   - 字符串是一个字符串值并且长度大于 32 个字节就会使用 SDS 方式进行存储, 并且 encoding 设置为 raw
   - 若是「字符串长度小于等于 32 个字节」就会将 encoding 改为 embstr 来保存字符串
   - sds01: 获取字符串只要读取 len 的值就可，时间复杂度变为 O(1)
   - sds02: 会先根据 len 属性判断空间是否满足要求, 若是空间不够, 就会进行相应的空间扩展, 所以「不会出现**缓冲区溢**出的情况」
   - sds03: 提供「空间预分配」和「惰性空间释放」两种策略, 减少连续的执行字符串增长带来内存重新分配的次数; 压缩也不会立即回收{free 记下来后面使用}
   - sds03 空间预分配: 当修改字符串后的长度 len 小于 1MB, 就会预分配和 len 一样长度的空间, 即 len=free; 若是 len 大于 1MB, free 分配的空间大小就为 1MB
   - sds04: SDS 是二进制安全的, 除了可以储存字符串以外还可以储存二进制文件{c 语言中的字符串是以空字符串作为结束符, 一些图片中含有结束符, 因此不是二进制安全的}
   <!--
        |                c-string                 |               sds               |
        | :-------------------------------------: | :-----------------------------: |
        |       获取长度的时间复杂度为 O(n)       |   获取长度的时间复杂度为 O(1)   |
        | n 次增长字符串必然会带来 n 次的内存分配 | n 次增长字符串内存分配的次数<=n |
        |            不是二进制安全的             |         是二进制安全的          |
        |             只能保存字符串              |      还可以保存二进制数据       |
        |    数据溢出{导致其他字符串值被修改}     |
    -->

3. 字符串命令: 数值{点赞,预扣库存减少数据库} || string || bitmmap || redis 在使用时一定要统一客户端的编码

   ```js
   // CRUD + 长度
   get / mget || set / mset / setnxex || getset || del || strlen;
   // 追加/覆盖/部分获取
   append || setrang || getrange
   // 原子: 只能是整数[1.6 incr 会报错]
   incr / decr / incrby / decrby / ~~decrbyfloat~~
   // 一定返回
   type k1 string
   // k1 对应的 value 是 string 返回 embstr || raw{bitset 也是}
   // k1 对应的 value 是 int 返回 int: 因为可以做 incr 操作嘛
   // k1 对应的 value 是 float 返回 embstr
   object encoding k1            // key 上的 encoding 是为了优化, 如果是 int 则可以直接 incr 操作; 如果是 embstr 则会先判断能否转换为 int[能则incr, 不能则报错]
   ```

   ```js
   // 二进制安全
   set k1 99999                  // keylen 是 5, 不会存成4字节的整数
   set k1 中                     // keylen 是 2[gbk]/3[utf8], 具体和客户端传过来时的字符集相关: 客户端先变成字节数组在出去 server
   ```

   - bitmap: 登录{key 是用户}/活跃用户个数{key 是日期+bitop or}

     ```js
     // bitmap: 长度=offset/8 + 1
     setbit k1 0  1                 // 长度为 1
     setbit k1 7  1                 // 长度为 1
     setbit k1 8  1                 // 长度为 2
     setbit k1 30 1                 // 长度为 4

     // 从(0)*8 - (1+1)*8即0-15 的二进制位上找第一个出现 1 的位置(在整个k1中): 最后两个参数不是二进制位置
     bitpos k1 1 0  1               // 0
     bitpos k1 1 2  3               // 30

     bitop and/or k1 k2
     bitcount k1 1 0  1             // 3 {0-15二进制上的1的个数}
     ```

#### 3-2 hash: k, map<k, v>

1. hash: ht + ziplist
2. hash 命令

   ```js
   // 添加
   hset/hmset/hsetnx
   HSET key k1 v1 // HGET key k1 [v1]
   // 查找
   hget/hmget/hgetall
   hscan key cursor [pattern] [count]
   // 原子
   hincrby/hincrbyfloat
   // 删除
   hdel
   // 长度
   hlen
   // 判断
   hexists key / hkeys / hvals;
   ```

#### 3-3 list: 存取有序

1. 3.2 之前是 ziplist + linkedlist; 之后是 quicklist{双向链表 + 压缩列表}
2. list: 链表的操作无论是头和尾效率都极高, 可以当做 stack 或者 queue 或者 数组[lset/lindex] 使用

   ```js
   // 个数
   llen

   // 添加
   lpush/rpush
   // 删除
   lpop/rpop
   ltim k1 start stop // 只保留 [start, stop] 数据
   // 获取所有
   lrange key 0 -1

   // used as array
   lindex key 2
   // 修改第3+1个元素为 v1
   lset k1 3 v1
   // 删除count个v1: count 为负数这从后面开始删
   lrem k1 [-]count v1
   // 在 第一个 v1 后面插入一个 v2
   linsert k1 after/before v1 v2
   ```

#### 3-4 set

1. set: intset + hashtable
2. set

   ```js
   // 添加
   sadd key v1 [v2 ...]
   // 删除
   srem key member [member ...]
   // 获取所有
   smembers key
   // 判断
   sismember key
   // 个数
   scard key

   // 随机找出: 不删除
   srandommember key COUNT
      // COUNT 正数: 取出一个去重的结果集{不能超过已有集}
      // COUNT 负数: 取出一个有重的结果集{一定满足 count 个数}
      // COUNT 0: 不返回
   // 随机找出: 删除
   spop key COUNT

   // 差集: 在k1中且不在k2中
   sdiff k1 k2
   // 交集
   sinter[store] key key
   // 并级
   sunion key key
   ```

#### 3-1 list

7. zset

   ```js
   127.0.0.1:6379> zadd k1  8 apple 2 banana 3 orange             // (integer) 0
   127.0.0.1:6379> zrange k1 0 -1 withscores
      // 1) "banana"
      // 2) "2"
      // 3) "orange"
      // 4) "3"
      // 5) "apple"
      // 6) "8"
   127.0.0.1:6379> zrange k1 0 -1
      // 1) "banana"
      // 2) "orange"
      // 3) "apple"
   // 取分数是 3-8 之间的
   127.0.0.1:6379> ZRANGEBYSCORE k1 3 8
      // 1) "orange"
      // 2) "apple"
   // 取分数最低的两个
   127.0.0.1:6379> ZRANGE k1 0 1
      // 1) "banana"
      // 2) "orange"
   // 取分数最高的两个
   127.0.0.1:6379> ZrevRANGE k1 0 1
      // 1) "apple"
      // 2) "orange"
   // 查看分数
   127.0.0.1:6379> zscore k1 apple
      // "8"
   // 查看排名
   127.0.0.1:6379> zrevrank k1 apple
   (integer) 0

   // 集合操作: 权重/聚合
   127.0.0.1:6379> zadd k1 80 tom 60 sean 70 bady     // (integer) 3
   127.0.0.1:6379> zadd k2 60 tom 40 sean 70 zack     // (integer) 3
   127.0.0.1:6379> ZUNIONSTORE unkey 2 k1 k2          // (integer) 4
   127.0.0.1:6379> ZRANGE unkey 0 -1 withscores
      // 1) "bady"
      // 2) "70"
      // 3) "zack"
      // 4) "70"
      // 5) "sean"
      // 6) "100"
      // 7) "tom"
      // 8) "140"
   ```

8. geo

   |      command      |          function          |               sample               |
   | :---------------: | :------------------------: | :--------------------------------: |
   |      GEOADD       |        添加地理位置        |       GEOADD KEY l l member        |
   |      GEODIST      |       两点之间的距离       | GEODIST KEY member1 member2 [unit] |
   |      GEOHASH      |        返回 geohash        |         GEOHASH KEY member         |
   |      GEOPOS       |       返回经纬度位置       |         GEOPOS KEY member          |
   |     GEOREDIUS     |       半径圆内的用户       |      GEOREDIUS KEY l l 300 m       |
   | GEOREDIUSBYMEMBER | 半径圆内的用户: 用户为中心 | GEOREDIUSBYMEMBER KEY member 300 m |

9. HyperLogLog: 伯努利实验

   - 节约空间, 时间, 性能: 12k 的内存就可以统计 2^64 个数据[误差率 0.81%]
   - 统计的数据不是精确的[有一定的误差], 但是此业务是允许的

10. pipeline

### config

1. units

   - 1k --> 1000 bytes
   - 1kb --> 1024 bytes
   - units are case insensitive so 1GB 1Gb 1gB are all the same.

2. INCLUDES

   - Include one or more other config files here.

3. NETWORK

   - daeminize: run as a daemon, if run in docker, it will need change to `no`
   - pidfile: run as a daemon and write pid in specify file
   - port
   - timeout: Close the connection after a client is idle for N seconds (0 to disable)
   - bind:
   - protected-mode: set auth, then change it to no

4. GENERAL

   - loglevel/logfile: [debug / verbose / notice / warning]
   - tcp-keepalive
   - syslog-enabled / syslog-ident / syslog-facility
   - databases

5. SNAPSHOTTING

   - RDB 是整个内存的压缩过的 Snapshot
   - save <seconds> <change>
   - rdbcompression: 对存储的快照进行压缩, 消耗 CPU
   - rdbchecksum: 存储完成后使用 CRC64 对数据进行校验, 消耗 10% CPU
   - dbfilename
   - dir

6. MEMORY MANAGEMENT

   - maxmemory:
   - maxmemory-policy: 缓存淘汰策略

7. REPLICATION

8. SECURITY

   - requirepass: 设置密码

9. APPEND ONLY MODE

   - appendonly
   - appendfilename
   - appendfsync <[always / everysec/ no]>
   - `no-appendfsync-on-rewrite no`: 重写时是否使用 appendfsync, no 保证数据的安全性
   - auto-aof-rewrite-percentage 100
   - auto-aof-rewrite-min-size 64mb

### 内存相关

1. 缓存淘汰策略

   - 当 Redis 内存超出物理内存限制时, 内存的数据会开始和磁盘产生频繁的交换 (swap)
   - 限制最大使用内存: Redis 提供了配置参数 maxmemory 来限制内存超出期望大小, 超过配置的大小时会淘汰一部分之前的数据 key-value: volatile-xxx 处理带有过期时间的数据
   - volatile-lru: 针对设置了过期时间的 key least recent used
   - allkeys-lru: 针对所有 key
   - volatile-random: 随机淘汰带有过期时间的 key
   - allkeys-random: 是随机的淘汰 key
   - noeviction: 不在提供写服务, 只提供读删除操作
   - volatile-ttl: Remove the key with the nearest expire time (minor TTL)

     ```C
     typedef struct redisObject {
        unsigned type:4;//对象类型（4位=0.5字节）
        unsigned encoding:4;//编码（4位=0.5字节）
        unsigned lru:LRU_BITS;//记录对象最后一次被应用程序访问的时间（24位=3字节）
        int refcount;//引用计数。等于0时表示可以被垃圾回收（32位=4字节）
        void *ptr;//指向底层实际的数据存储结构，如：SDS等(8字节)
     } robj;
     ```

2. Redis 的 LRU

   - redis 的 LRU 算法并不是真实的 LRU 算法
     - **通过抽样的方式进行删除: Redis 随机取出若干 key 在进行最近最少使用**
     - LRU 需要额外的空间进行存储[pre/next]: LRU=DLinkedList + HashMap
     - 可能存在某些 key 值使用很频繁, 但是最近没被使用, 从而被 LRU 算法删除
   - maxmemory-samples: 5
     - 3 最快, 内存少, 但是准确性太差
     - 5 平衡的好
     - 10 接近 LRU 但是耗内存
   - LRU 实现的数据类型的选择

     - DLinkedList: 新来的放入 head 单链表也可以, 但是淘汰最后一个单链表就需要遍历[因此需要使用 DlinkedList]
     - HashMap: 保存和查找都是 hash O(1)
     - 实现思路:
       1. save(key, value): 在 HashMap 找到 Key 对应的节点
          - 如果节点存在, 更新节点的值, 并把这个节点移动队头
          - 如果不存在, 需要构造新的节点, 并且尝试把节点塞到队头
          - 如果 LRU 空间不足, 则通过 tail 淘汰掉队尾的节点, 同时在 HashMap 中移除 Key
       2. get(key): 通过 HashMap 找到 LRU 链表节点
          - 因为根据 LRU 原理, 这个节点是最新访问的, 所以要把节点插入到队头, 然后返回缓存的值

   - Redis LRU
     - 记录对象最后一次被应用程序访问的时间: lru:LRU_BITS[24 位只能存储 194 天]
     - 但是 redis 并不是比较 lru 和当前时间, 而是维护了一个全局属性 lru_clock[定时更新 100ms], 最终比较的是 lru_clock 和 lru, 节约了每次获取当前系统时间

3. Redis 的 LFU: lru 的高 16 位记录访问时间， 低 8 位[0-255]记录访问频率

   - Redis 使用的是一种基于概率的对数器来实现 counter 的递增
   - r 给定一个旧的访问频次，当一个键被访问时，counter 按以下方式递增：

     - 提取 0 和 1 之间的随机数 R。
     - counter - 初始值（默认为 5），得到一个基础差值 baseval，如果这个差值小于 0，则直接取 0
     - 概率 P 计算公式为：`1/(baseval * lfu_log_factor + 1)`: lfu_log_factor 对数因子[10]
     - 如果 R < P 时，频次进行递增（counter++）
     - `random(0, 1) < 1 /((old_counter - 5)*lfu_log_factor + 1) ? counter++ : counter`

   ![avatar](/static/image/db/redis-flu.png)

   - 默认访问 1m 才会到最大值
   - counter 一直会增加, 所以不能反映热度, 需要一段时间不访问了就降下来
   - counter 的减少速度由参数 `lfu-decay-time[1]` 进行控制: N 分钟内没有访问，counter 就要减 N
     - 取出当前的时间戳和对象中的 lru 属性进行对比
     - 计算出当前多久没有被访问到: 比如计算得到的结果是 100 分钟没有被访问
     - 然后再去除配置参数 lfu_decay_time，如果这个配置默认为 1 也即是 100/1=100，代表 100 分钟没访问: 所以 counter 就减少 100。

### durable: 默认开启 RDB[断电丢数据问题]

1. 持久化

   - AOF: 指令级别的, 设置多久改动一次就执行一次 aof; redis 重启时数据恢复很慢[数据量大的话]
     - aof 文件重写: 将多次操作 key 的指令把柄成一个[为了恢复数据嘛]
   - RDB: 数据级别的, 快照, 设置多久改动一次就执行一次快照, 会丢数据, 数据恢复快
   - 同时打开 AOF 和 RDB, 但是没有打开 混合持久化 时重启会使用 AOF 策略
   - 混合持久化: 需要保证 aof 和 rdb 都打开

     ```js
     aof-use-rdb-preamble no
     ```

     - bgrewriteaof: 会将 此时的 rdb 文件写入 aof[为了快速重启], 重写期间的新命令会在内存中, 直到重写结束后才会 以 aof 文件的方式写入 aof 文件

#### RDB: 会丢数据, 但是恢复快[只在 Slave 上持久化 RDB 文件]

1. rdb 存盘的是某一时刻的数据:

   - ~~单线程阻塞不对外提供服务~~
   - linux 的父子进程, 常规上是数据隔离的

     ```shell
     echo $$ | more # 输出父进程ID, 原因是 $$ 优先级高于 |
     echo $BASHPID | more # 输出子进程ID

     num=1
     echo $num       # 1
     /bin/bash       # 开启子进程
     echo $num       # --, 此时可以 export num 就可以看见了
     exit
     echo $num       # 1

     # export 的变量 子进程修改对父进程不可见
     # export 的变量 父进程修改对子进程不可见
     ```

   - 创建子进程的问题: fork
     1. 速度
     2. 内存空间问题

2. 相关命令: `save/bgsave`

   - 目录配置
     1. 默认是 rdb 文件名为 dump.rdb
     2. dir
     3. dbfilename
     4. 存储的文件: dbfilename + dir
   - 触发快照: 一个执行完后一个才能执行, 顺讯写
     1. 手动触发 save <seconds> <change>: 阻塞{比如关机维护}
     2. 手动触发 bgsave(fork): 非阻塞
     3. 配置文件中 save: 其实触发的是 bgsave
     4. `save ""` 标识禁用 rdb
     5. flushall 也会产生 dump.rdb 文件, 但是内容 null

3. 概念

   - 在指定时间隔内将内存中的数据集快照写入磁盘, 恢复时直接将快照文件读到内存
   - redis 会单独创建[fork]一个子线程来进行持久化, 先将数据写到一个临时文件中, 带到持久化结束后替换场次的持久化文件
   - 父进程继续接收并处理客户端发来的命令, 而子进程开始将内存中的数据写入硬盘中的临时文件
   - 持久化过程, 主线程不进行任何 IO[fork 结束之后就可以对外提供服务, 其他的 IO 操作由子进程进行]

4. fork[指针+cow]: 速度快, 占用空间小

   - 复制一个与当前进程完全一样的进程[**变量, 环境变量, 程序计数器**]等, 并且作为原进程的子进程`[会造成间断性的暂停服务] + master 不要有rdb操作`
   - fork 进程时 redis 是不对外提供服务的
   - 在执行 fork 的时候操作系统[Unix]会使用写时复制[copy-on-write]策略, 即**fork 函数发生的一刻父子进程共享同一内存数据**, 当父进程要更改其中某片数据时[如执行一个写命令], 操作系统会将该片数据复制一份在修改以保证子进程的数据不受影响, 所以新的 RDB 文件存储的是执行 fork 一刻的内存数据
   - 为此需要确保 Linux 系统允许应用程序申请超过可用内存[物理内存和交换分区]的空间, 方法是在/etc/sysctl.conf 文件加入 vm.overcommit_memory = 1, 然后重启系统或者执行 sysctl vm.overcommit_memory=1 确保设置生效
   - RDB 文件是经过压缩[可以配置 rdbcompression 参数以禁用压缩节省 CPU 占用]的二进制格式, 所以占用的空间会小于内存中的数据大小, 更加利于传输

5. feature

   - 优点: 适合大规模的数据恢复
   - 缺点: 只有一个 rdb 文件, 要是坏了就糟了
   - 缺点: 对数据的完整性要求不高, 丢数据可能性大一点
   - ~~fork 时需要 2 倍的内存~~: 这个是错误的
   - bgsave/save 会触发 IO 操作, 所以也不会让一个 redis 的内存过于大

6. 执行时机

   - 手动执行 bgsave
   - 手动执行 save
   - 自动执行 save
   - 从节点连接到主节点发送 sync 命令, master 会执行 bgsave
   - shutdown/flushall

7. conclusion

   ![avatar](/static/image/db/redis-rdb.png)

#### AOF

1. 概念: **全量**

   - 以日志的形式来记录每个`写操作`, 重启时从头到尾执行一遍
   - aof 文件很大的话会很慢

2. 存储的文件
   - 开启: appendonly yes/no
   - 文件名称: appendfilename
3. aof 文件恢复

   - 备份被写坏的 aof 文件
   - redis-check-aof --fix
   - restart

4. rewrite

   - bgrewriteaof: 会将 此时的 rdb 文件写入 aof[为了快速重启], 重写期间的新命令会在内存中, 直到重写结束后才会 以 aof 文件的方式写入 aof 文件
   - redis 会当 aof 文件大于 64M 且 size{重写后的 size} 翻倍时重写
   - 4.0 之前会 fork 出一个新的进程将文件重写[先写入临时文件]: ~~是删除抵消的命令 + 合并重复的命令~~
   - 4.0 之后会 rbd + aof

5. 触发 aof: 调用 flush 进行刷盘

   - appendfsync always: 性能差一些
   - appendfsync everysec: 异步每秒一个, 如果一秒内当即会有数据丢失, buffer 满了会自动刷盘, 所以最多丢一个 buffer
   - appendfsync no: ~~不同步~~, 这个是交给系统决定, 不是不同步, 可能会丢失一个 buffer 大小的数据

6. feature

   - 数据丢失概率小
   - 如果同时开启了 RDB 和 AOF, 数据恢复时只会使用 AOF
   - aof 文件大于 rdb 时重启恢复慢: bgrewriteaof
   - no 时效率与 rdb 相同
   - flushall 发生之后且没有发生 rewriteaof 数据是可以恢复的

7. conclusion

   ![avatar](/static/image/db/redis-aof.png)

#### 混合持久化{4.0}: RDB 的快 + AOF 的全量

1. 需要保证 aof 和 rdb 都打开

   ![avatar](/static/image/db/redis-durable.png)

   ```js
   aof-use-rdb-preamble no
   ```

### transaction

1. 一次执行多个命令, 一个事务中的所有的命令都会序列化, 串行的排他的执行

   - watch: 可以在事务之前也可以之后, 是一个乐观锁, redis 事务提供的 cas 行为, 可以监控一个或多个 key, 一旦其中的值被修改或删除, 之后的事务就不会执行, 监控知道 exec 命令结束
   - multi 开始事务, 会将客户端状态的 flags 属性打开 redis_multi 标识, 接下来的命令都会以 redis_multi 为起点的 queued
   - queued, 入 queue 的语法错误则关闭 redis_multi[事务结束], 并返回错误信息; 否则入 queue
   - exec/discard: 如果客户端的 flags 不包含 redis_multi 或者包含了 redis_dirty_cas 或者 包含了 redis_dity_exec 则取消事务的执行, 否则认为可以执行事务[遍历事务 queue FIFO, 顺序输出结果, 且逻辑的错误不会回滚整个事务]

2. command

   ```js
   discard // 取消事务, 放弃事务内的所有命令
   exec    // 执行事务内的所有的命令
   multi   // 标记事务块的开始
   unwatch // 取消watch 命令对所有key的监视
   watch key [key ...] // 监视key, 如果事务执行之前被watch则事务会被打断
   ```

3. practice: **两个客户端之间的顺序是谁的 exec 先达到谁先执行**

   - normal case

   ```shell
   127.0.0.1:6379> MULTI
   OK
   127.0.0.1:6379> set id 12
   QUEUED
   127.0.0.1:6379> get id
   QUEUED
   127.0.0.1:6379> INCR id
   QUEUED
   127.0.0.1:6379> INCR tl
   QUEUED
   127.0.0.1:6379> INCR tl
   QUEUED
   127.0.0.1:6379> get tl
   QUEUED
   127.0.0.1:6379> exec
   1) OK
   2) "12"
   3) (integer) 13
   4) (integer) 1
   5) (integer) 2
   6) "2"
   127.0.0.1:6379>
   ```

   - 放弃事务

   ```shell
   127.0.0.1:6379> MULTI
   OK
   127.0.0.1:6379> set id 12
   QUEUED
   127.0.0.1:6379> get id
   QUEUED
   127.0.0.1:6379> INCR id
   QUEUED
   127.0.0.1:6379> INCR tl
   QUEUED
   127.0.0.1:6379> INCR tl
   QUEUED
   127.0.0.1:6379> get tl
   QUEUED
   127.0.0.1:6379> discard
   OK
   127.0.0.1:6379>
   ```

   - 全体连坐: 语法上的错误

   ```shell
   127.0.0.1:6379> MULTI
   OK
   127.0.0.1:6379> set name zz
   QUEUED
   127.0.0.1:6379> get name
   QUEUED
   127.0.0.1:6379> incr tl
   QUEUED
   127.0.0.1:6379> get tl
   QUEUED
   127.0.0.1:6379> set email
   (error) ERR wrong number of arguments for 'set' command
   127.0.0.1:6379> exec
   (error) EXECABORT Transaction discarded because of previous errors.
   127.0.0.1:6379> get tl
   "2"
   ```

   - 冤有头债有主: 运行时错误[为了性能]

   ```shell
   127.0.0.1:6379> MULTI
   OK
   127.0.0.1:6379> set age 11
   QUEUED
   127.0.0.1:6379> INCR ti
   QUEUED
   127.0.0.1:6379> set emial zack
   QUEUED
   127.0.0.1:6379> INCR emial
   QUEUED
   127.0.0.1:6379> get age
   QUEUED
   127.0.0.1:6379> exec
   1) OK
   2) (integer) 1
   3) OK
   4) (error) ERR value is not an integer or out of range
   5) "11"
   127.0.0.1:6379>
   ```

4. watch

   - watch 类似乐观锁[CAS], 事务提交时, 如果 key 的值被别人修改了, 则这个事务放弃
   - 放弃之后会返回 Nullmuti-bulk 应答通知调用者事务执行失败

5. 特点

   - 单独的隔离操作: 事务中的命令会序列化顺序且排他的执行, 不会被打断
   - 没有隔离级别的概念: 提交之前都不会执行
   - 没有原子性: redis 中同一事物如果有一条失败, 其他命令依旧可以执行成功
   - 不支持回滚: 官方说明是为了保证 redis 的快速和简单

### MQ

![avatar](/static/image/db/redis-mq.png)

## others

1. 脑裂 || 分区容错
