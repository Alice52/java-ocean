## redis

### 1.redis 的数据结构和使用场景

1. string: 计数[喜欢的文章数量/点赞数/临时存储位], 分布式锁[原子操作]
2. ~~hash: 存储大对象[少量属性变化], 购物车, 一般对象用 string + json 存储,对象中某些频繁变化的属性抽出来用 hash 存储~~

   ```java
   Map<string, Map<K, V>>
   // 1. hset     shopcart:uid productid count  新增商品
   //    hget     shopcart:uid productid
   // 2. hincrby  shopcart:uid productid count  商品 +1
   // 3. hdel     shopcart:uid productid        删除商品
   // 4. hlen     shopcart:uid                  商品总数
   // 5. hgetall  shopcart:uid                  所有商品
   ```

3. ~~list: 列表数据小空间存储, 公众号列表[别人发布文章就会 push 进我的 list]~~
   - 实现栈: LPUSH + LPOP
   - 实现队列: LPUSH + RPOP
   - BlockingQueue: BLPUSH + BRPOP
4. set: **抽奖[SRANDMEMBER/SPOP]**/微信的点赞[可见性 sinter]/推荐可能认识的人[sdiff]/社交的共同关注[sinter]
5. zset: 排行榜[不停的被刷新], 热搜
6. bit: 签到 [SETBIT key offset(512m) value/getbit, bitcount]

   - 一个以每天日期为 key, 每个 uid 为偏移量
   - 一个以用户 uid 为 key, 当天在一年中的索引为偏移量,

7. 类型相关的命令

   ```shell
   set age 12
   set name zack
   type age # string
   type name # string
   object encoding age # int
   object encoding name # embStr
   ```

8. 做 IM 系统

### 2.redis 快的原因/6.0 的线程模型

1. 内存级别的存取
2. 单线程, 不需要线程切换, 不需要考虑并发锁问题
3. 多路复用 IO + 线程模型

   - I/O ：网络 I/O
   - 多路：多个 TCP 连接
   - 复用：共用一个线程或进程

4. 合理的数据结构
5. 数据编码: 根据字符串的长度及元素的个数适配不同的编码格式

### 12.redis 常见的数据结构

1. sds: c 的字符串+len 属性+free 属性

   - len: c 语言里面 `\0` 表示结束, 如果字符串里包含则会出现之后字符丢失的问题; sds 是根据 len 进行读取的, 因此二进制安全 + `获取长度时 O(1)的复杂度`
   - free: 内存预分配[不需要每次都重新分配空间], 空间预分配[len < 1M, 会多分配一个 len; len > 1M, 多分配 1m] + `惰性空间释放`
   - 最后会有 `\0` 为了兼容 c 的函数库
   - struct

     ```c#
     // redis 3.2
     struct sdshdp {
        int len;  // 空间有浪费
        int free; // 空间有浪费
        char bug[];
     };

     // redis 3.2 later
     len and free is less for less memory and with flag to mark[1byte] type
     ```

2. linkedlist: len + 双向无环链表, 具有 stack 和 queue 的特性
3. hashtable: 2 个 key-链地址法[单向链表], rehash 是渐进式的[服务的高可用]
4. skiplist: 在链表的基础上增加了多级索引来提升查找效率, zset + cluster node, zskiplist[hNode, tNode, len], zskiplistNode[1-32, 分可以相同, 对象不同], 取[分后对象大小]

   - 每一层都有一条有序的链表, 最底层的链表包含了所有的元素(O(logN))

5. intset: 不重复的中枢集合
6. ziplist: 压缩空间发明的数据结构, 所有的操作都是通过指针与解码出来的偏移量进行的. 并且压缩列表的内存是连续分配的, 遍历的速度很快. 多个 Node[1 个字节数据/1 个整数值]

---

7. 字符串对象 string：int 整数、embstr 编码的简单动态字符串、raw 简单动态字符串
8. 集合对象 set：intset、hashtable
9. 列表对象 list：ziplist、linkedlist
10. 有序集合对象 zset：ziplist、skiplist
11. 哈希对象 hash：ziplist、hashtable

### 3.redis 的持久化

### 4.redis 使用场景

1. 高并发/高性能/高可用
2. 减小 mysql 的压力, 快速的响应[内存界别的操作]
3. 超热的 key 就可以放到 redis 中:

### 5.redis 内存满了怎么办

1. 过期策略: redis 使用了 惰性删除 和 定期删除(Redis 每秒 10 次)
   - [省内存耗性能]定时删除: 数据过期后马上就被删除, CPU 要时刻计算着过期的 key 压力过大
   - [耗内存省性能]惰性删除: 数据过期不处理, 等到下次使用的时候判断是否过期, 会导致有很多不被访问的 Key
   - 定期删除: 是对上两种的折中, 每隔一段时间执行一次删除, 限制删除操作的时长和频率减少删除操作对 CPU 的影响
     - 周期性轮询, 随机抽取[一部分 key]{20 个}, 删除其中过期的 key, 如果过期占比大于 25%, 则继续抽样过期(利用占比控制删除频率)
     - **检测频率时长可以自定义**, 内存压力也不大
     - 还是可能导致一些 key 到期不会被删除
     - 使用前还是需要看是否过期[惰性检查]
2. Redis 是使用了 惰性删除 + 定期删除

   - 定期删除: 定期扫描只会扫描设置了过期时间的键, 设置过期时间的 Key Redis 会单独存储
   - volatile 表示设置过期时间的 key
   - redis 会记录对象最后一次被应用程序访问的时间, 一个 key 到期了并不是马上就被删除

3. 缓存淘汰策略:
   - noeviction 满了之后会 set 操作会 OOM
   - 其他策略会删除 key 释放空间, 如果释放的空间不足则报错

### 6.缓存淘汰策略 6 + 2

1. noeviction
2. volatile-lru
3. **allkeys-lru**
4. volatile-lfu
5. allkeys-lfu
6. volatile-random
7. allkeys-random
8. volatile-ttl
9. LRU 是一种常用的页面置换算法: hash + 双向链表

### 7.常见的命令

### 8.事务: 分布式锁的解锁问题

### 9.常见的配置项

1. 可以通过配置文件配置 & 也可以通过 config 命令行配置
2. aof/rdb: aof-use-rdb-preamble no
3. memory
4. log
5. daeminize: docker
6. protected-mode + requirepass: auth
7. REPLICATION
   - cluster-enabled
   - cluster-config-file
   - cluster-node-timeout

### 10.高可用

1. sm
2. cluster
3. sentinel

### 11.分布式锁

1. 单机版在多线程下需要加锁
2. 微服务: 单机版锁值管自己的 JVM 层面的, 可能会导致 2 个服务买同一个商品
3. 分布式锁的注意点

   - 加锁的原子性: setnxex
   - 解锁的原子性: lua 或者 ~~redis 事务: watch + transaction+ multi+delete + unwatch~~
   - 解锁代码的一定执行 + ex
   - 解决业务超时问题锁续期问题 + 只能删除自己的锁
   - redis 集群时异同同步数据导致的 set 丢失问题: 自己手动修复数据

### 12.生产上 redis 内存陪多大, 怎么修改

1. maxmemory 不配置默认 64bit 使用最大内存
2. maxmemory 参数是字节
3. 查看: info memory / config maxmemory / 配置文件

### 13.常见的问题

1. 缓存穿透: 查询一个不存在（DB）的 Key, 缓存不能命中, 数据库也没有记录[无法缓存], 导致每次都要查数据库, `缓存失效`

   - 做严格的限制, 尽量过滤无效的请求
   - solution: 缓存 Null 且加`短暂的过期时间`[解决的是使用某个 key 的大量并发], 此时如果被攻击
   - [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

     1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
     2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

        ![avatar](/static/image/db/redis-bloom-filter.png)

     3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
        - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
     4. 判断的时候
        - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
        - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 则判断为可能存在

2. 缓存击穿: 某个 Key(DB 有) 是高频热点, 但是在大并发下下缓存过期了 || 不存在

   - solution: 加锁, 大并发下只让一个线程去查数据库, 其他人等待, 查到以后释放锁; 其他线程获取到锁, 先查询缓存
   - **数据预热**

3. 缓存雪崩: 大量的 Key 的同时失效, 请求压力都转到了数据库, redis 挂了

   - solution: 在原有的失效时间上添加一个随机数以降低重复概率/永不失效
   - AKF 分治: 让其不同的 key 落在不同的分片上执行加锁查数据库的逻辑
   - redis 高可用
   - 限流降级: 缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个 key 只允许一个线程查询数据和写缓存, 其他线程等待。

4. 可以考虑在业务层面上解决 12306

### 14. 海量数据下怎么快速查找一条记录

1. 使用布隆过滤器, 快速过滤不存在的数据[spring cache 中有笔记]
2. 在 redis 中建立数据缓存

   - 以普通的字符串存储(user-id -> user object) / 以 hash 存储(user-id k->v)`[会存在大量的 key]`
   - 使用一个 hash 存储所有的数据(user-info user-id->uo)`[key 是减少了, 一个 可以存 2^32-1 个键值对]`
   - 存在缓存穿透: 由于布隆过滤器的误判导致的
   - 存在缓存击穿: key 失效导致的, 可以使用锁机制[一个线程写缓存]

3. 查询优化
   - redis 数据是按槽位计算分配存储空间的
   - ~~自己实现槽位计算, 自己计算数据在那台机器上, 然后进行查找~~

#### 布隆过滤器: 基于概率的数据结构

1. 当布隆过滤器说某个值存在时,这个值可能不存在; 当它说不存在时, 那就肯定不存在
2. 特点

   - 一个非常大的二进制位数组(数组中只存在 0 和 1）
   - 拥有若干个哈希函数(Hash Function）
   - 在空间效率和查询效率都非常高
   - 布隆过滤器不会提供删除方法, 在代码维护上比较困难
     - 删除的话就需要在每个 bit 位上记录出现次数: 带有计数器的布隆过滤器会占用更大的空间

3. 要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:
   - 哈希函数的好坏
   - 存储空间大小
   - 哈希函数个数

#### [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

   ![avatar](/static/image/db/redis-bloom-filter.png)

3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
   - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
4. 判断的时候
   - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
   - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 则判断为可能存在

### 15.分布式缓存

1. 客户端缓存: 页面/浏览器缓存, APP 缓存, H5 缓存, Localstrage, session-storage
2. CDN 缓存: 内容存储, 数据存储, 内容分发[负载均衡]
3. nginx 缓存: 静态资源
4. 服务器缓存: 本地缓存, 外部缓存
5. 数据库缓存: 持久层缓存[mybatis 缓存], mysql 服务的缓存
6. 操作系统缓存: Page Cahce, Buffer Cache

### 16.渐进式 rehash 机制

1. redis 是通过 Dict 存储 K-V, 底层是 hashtable, 存放不同的 K-V, 但是存在 hash 冲突, 就会 rehash
2. 采取分而治之的方式, 将 rehash 键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上, 从而避免了集中式 rehash 而带来的庞大计算量

   ```c#
   typedef struct dict {
      dictType *type;         // 指向 dictType 结构的指针
      void *privdata;         // 保存了需要传给那些类型特定函数的可选参数
      dictht ht[2];           // 在字典内部, 维护了两张哈希表
                              // 一般情况下,  字典只使用 ht[0] 哈希表
                              // ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用
      long rehashidx;         // 记录了 rehash 目前的进度, -1标识不在 rehash
      unsigned long iterators; /* number of iterators currently running */
   } dict;

   // This is our hash table structure. Every dictionary has two of this as we
   // implement incremental rehashing, for the old to the new table.
   typedef struct dictht {
      dictEntry **table;         // 哈希表数组, 数组的每个项是dictEntry链表的头结点指针
      unsigned long size;        // 哈希表大小；在redis的实现中, size也是触发扩容的阈值
      unsigned long sizemask;    // 哈希表大小掩码, 用于计算索引值；总是等于 size-1 ；
      unsigned long used;        // 哈希表中保存的节点的数量
   } dictht;

   typedef struct dictEntry {
      void *key;                //键
      union {
         void *val;            //值
         uint64_t u64;
         int64_t s64;
         double d;
      } v;
      struct dictEntry *next; //指向下一个节点, 形成链表
   } dictEntry;
   ```

3. rehash 扩容

   - redis 中, 每次插入键值对时, 都会检查是否需要扩容。如果满足扩容条件, 则进行扩容
   - 在 redis 中 hash 表也是采用延迟初始化策略: 创建时没分配内存, 当第一次插入时才分配内存
   - rehash 条件: 则将哈希表大小扩容为原来的两倍
     - 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 1
     - 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 5

4. rehash 缩容

   - 条件:
     - 当哈希表的负载因子小于 0.1 时
     - 如果当前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 则不进行缩容
   - 缩容后的哈希表大小为当前哈希表中 key 数量的 2 的 n 次方, 最小容量为 4

5. 渐进式 rehash

   - 在 dict 层打开 rehash 的标志, 并分配新的 hashtable 内存
   - 操作辅助 rehash: 每一个增删改查命令中都会判断数据库字典中的哈希表是否正在进行渐进式 rehash, 如果是则帮助执行一次
   - 定时辅助 rehash: 服务器比较空闲, redis 数据库将很长时间内都一直使用两个哈希表, 有字典正在进行渐进式 rehash 操作, 则会花费 1 毫秒的时间, 帮助一起进行渐进式 rehash 操作

6. 小结

   - 在 redis 中, 扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面, 但是 rehash 动作并不是一次性、集中式地完成的, 而是分多次、渐进式地完成的: 服务器性能[集中式 rehash 而带来的庞大计算量]
   - rehash 步骤
     - 为 ht[1] 分配空间: 让字典同时持有 ht[0] 和 ht[1] 两个哈希表
     - rehashidx=0: 它的值设置为 0, 表示 rehash 工作正式开始
     - 在 rehash 进行期间, 每次对字典执行添加、删除、查找或者更新操作时, 程序除了执行指定的操作以外, 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] , 当 rehash 工作完成之后, 程序将 rehashidx 属性的值增一
     - 随着字典操作的不断执行, 最终在某个时间点上, ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1 , 表示 rehash 操作已完成, ht[1]变为 ht[0]
     - 因为在进行渐进式 rehash 的过程中, 字典会同时使用 ht[0] 和 ht[1] 两个哈希表, 所以在渐进式 rehash 进行期间, 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行[ 要在字典里面查找一个键的话, 程序会先在 ht[0] 里面进行查找, 如果没找到的话, 就会继续到 ht[1] 里面进行查找]
     - 在渐进式 rehash 执行期间, 新添加到字典的键值对一律会被保存到 ht[1] 里面, 而 ht[0] 则不再进行任何添加操作
   - 同时有两个 hash 表在使用, 会使得 redis 内存使用量瞬间突增: 在 Redis 满容状态下由于 Rehash 会导致大量 Key 驱逐

### 17.如何优化 redis 的性能

1. 客户端优化
   - pipeline
   - 连接池
2. 淘汰机制
   - 内存大小
   - 过期时间
   - 淘汰策略
3. key 与 value 的优化: big key`redis-cli --bigkeys || ui tools` + big value: `10k 1w` 打满网卡
   - key 的设计: 可读性 + 可管理性[前缀名 :] + 简洁性[key 本身不要太长] + 不要包含特殊字符
   - value 的设计: 拒绝 bigkey[慢查询||打满网卡] + 选择合理的数据类型[hash 不会序列化, 频繁修改的数据可以使用 hash]
   - 尽量都设置过期时间
4. 禁止使用耗时操作

   - `keys *`: scan
   - big key delete
   - flushall

5. 慢查询优化

   ```shell
   # 1. 开启 redis 慢查询监控
   slowlog-log-slower-than 10000000
   slowlog-max-len 128
   # 2. 查看慢查询
   slowlog get count # id + start-time + nan-consuming + command
   ```

### 18.bigkey 问题

1. find

   ```shell
   # ui tools github
   redis-cli --bigkeys
   memory usage username # bits

   # 可以使用 scan 脚本去一点一点扫描计算并获取 key 的大小
   ```

2. string value > 1024k || element size > 10240
3. 删除
   - 4.0 之后: 提供异步删除 key 的 unlink, 将 key 的释放放在 background io 的单独的子线程处理, 减少对主线程的影响
   - 4.0 之前: `hscan scan ltrim zscan sscan`

### 19.cap: `p -> c -> a`

- 分布式下 P 要保留为了 HA, 此时主从集群, 若主机挂了: 立马从机变主机则是 AP; ~~或不对外提供服务了则是 CP~~
- 分布式是把一个复杂功能拆分成不同的子业务, 之后部署在不同的服务器上[每个子业务都可以是集群]
- 分布式部署[]
- 把数据复制到多个节点, 就会带来一致性的问题, 就是多个节点上面的数据可能是不一致的; 要保证一致, 每次写操作就都要等待全部节点写成功, 而这等待又会带来可用性的问题

1. C: 数据一致性[~~同一时刻~~访问~~不同的实例~~得到的数据是一致的{所有节点数据一致}] + **~~[业务上保证读取和插入的数据一致]~~** + _~~访问集群对外提供的数据是一一致的{多线程并发访问 key 得到的值是一样的}~~_

   - [针对一个人的]访问数据一致性的保证是可以实现的, 通过 block 用户不返回[直到所有的实例同步数据]
   - explain: 比如 A(下单)->B(扣库存) 是等待 B 完成之后 A 才返回, 这就叫 `C`
   - explain: redis 数据写到一个实例上, 等到所有实例同步该数据之后才告诉用户插入成功, 此时才是严格意义上的 `C`
   - 但是 redis 每次只有一个主节点在服务, 所以也可以保证每次访问的结果是一致的
   - 分类: `强一致性|| ~~弱一致性||最终一致性~~`

2. A: 可用性[是否对外提更服务]`好的响应性能`, 用户访问集群中的任意节点都应该在合理的时间内~~无错的~~返回[有限的时间内给出~~非错~~响应]`~~而宕机{分区}的处理是不考虑在内的~~`

   - **`[错]`**~~发生网络分区此时这台 server 对外不能体提供服务, 不具有可用性~~
   - 违反可用性: 阻塞客户端直至超时
   - 违反可用性: 返回出错响应，提示其重试
   - ~~违反可用性: redis 选举期间服务不可用~~
   - explian: 比如 A(下单)->B(扣库存) 是不等待 B 完成 A 直接返回, 这就叫 `A(快)`

3. P[分片/主备]: network tolerate`必选`

   - 分区: 部分节点故障/宕机, 无法与其他节点通信, 产生了网络分区[导致当系统不能在时限内达成数据一致性]
   - 分区容错: 是系统的特性[指的是系统对于分区这种现象有多高的容错能力]; 特征[分布式系统在遇到任何网络分区故障时, 仍然可以对外提供满足一致性和可用性的服务`系统原本是 CP 的，就仍然满足 CP，AP 同理`]
   - **意思就是某个节点挂了, 不会影响正常服务**
   - 在分布式系统中 P 是一定需要的, 网络问题+宕机问题无法避免, 不能一个节点有问题就不对外服务了`所以P一定要`
   - 举例: 比如注册中心出现分区{或者脑裂}, 其实时可以很大程度上容忍的

4. P 为什么一定要存在

   - 如果我们选择了 CA 而放弃了 P
   - 那么当发生分区现象时, 为了保证 C, 系统需要禁止写入, 当有写入请求时, 系统返回 error
   - 这又和 A 冲突了, 因为 A 要求返回 no error 和 no timeout

5. ~~`HA 是靠 P 来保证的, 而不是A`~~: 我觉得 HA 和 CAP 没有关系

   - 某个节点挂了, 请求就不分发给此节点
   - `||` 某个节点挂了, 备份节点马上顶上来服务

6. CA: oracle/mysql 单体应用

   - 一个实例没有数据一致性问题
   - a 也是满足的[不需要节点间数据同步]
   - 但是没有 HA

7. CP

   - 允许访问失效/失败, 因为系统等待期间不可用
   - A->B 的例子中可以阻塞直到 B 成功, 才返回成功[用户体验差]
   - 节点之间的数据同步[需要时间的], 等到故障分区恢复, 同步完成, 才恢复服务, 可能导致无限阻塞
   - redis 的选举期间服务不可用

8. AP

   - 对一致性要求不高, 但仍需保证最终一致性[否则就是一堆无用的数据]
   - 节点间数据没有进行同步, 可能导致数据丢失或者读取节点的数据不一样
   - A->B 的例子中可以 A 成功直接返回成功[B 操作完全失败就出现了数据不一致], 但是也需要保证 B 的库存被扣除[异步，或者错误后的补偿机制或者人工干预][用户体验好]

9. redis 中的 CAP

   - 单机版没有 CAP 问题, ~~就是 CA 的[check later]~~
   - redis 集群: `无法保证强一致性` ~~CP~~
     1. sm 同步的时间差内: 数据不一致 `同步完成保证最终一致性`
     2. sm 过程中 s 挂了: 数据就丢失了 + 所以出现持久化之同步复制 + `redis集群是没有实现强一致`
     3. sm 的主从翻转: server: `A,B,C,A1,B1,C1`; client: `Z1`; Z1 和 B 在一个网络分区, 但是 B 在集群中被认为失败 + B1 会变成 s[通知 Z1 去和 B1 数据交互`如果大的分区里面的 slave 节点升为 master 节点，小分区里面的 master 节点将不再接受写请求`]: 此时 Z1 之前在 B 写的数据都丢失了[引入了 node timeout 概念]

### 20.BASE

1. 简介

   - 是对 CAP 中**一致性和可用性权衡的结果**, 其来源于对大规模互联网系统**分布式实践的结论**
   - 互联网中对可用性要求非常高, 但对一致性要求要少点
   - 比如发一个消息给用户, 用户不用立即收到, 晚个一两秒也 OK 的
   - 所以可以牺牲 CAP 中 C, **`BASE理论大部分是对AP的补充和权衡`**
   - 提出通过牺牲强一致性来获得可用性, 并允许数据在一段时间内是不一致的, 但最终达到一致状态

2. BA[asically Available]: 基本可用

   - 响应时间上的损失: 流量增加或者故障使得响应时间变长
   - 功能上的损失[服务降级]: 部分非核心业务退让 + 服务挂了之后的 fallback[比如系统升级期间的错误展示或挂了后的友好提示]
   - 比如购物系统正常, 消费者可以正常购物; 但是大促的时候由于消费者的购物行为激增, 为了保护购物系统的稳定性, 部分消费者可能会被引导到一个降级页面 || 或者部分业务不可用[比如图片和一些不重要的业务等]

3. S[Soft State]: 软状态 [支付库存可用应用, 但是转账等金融必须强一致性]

   - **数据可以有一个中间状态， 而且不会影响系统的可用性**
   - 比如服务 A 更新数据, 读取 B 服务时, 允许存在一定的延迟, 客户端读取的为中间状态[支付中]

4. E[Eventually Consistent]: 最终一致性
   - **节点同步延迟 || A -> B A 成功则成功[B 异步减库存]**
   - 强一致性: `[弱一致性的一种]` 关系型数据库 或者 A->B 阻塞直到 B 成功
   - 弱一致性: 读取到暂时不正确的数据 比如 A->B A 成功直接返回, 此时访问库存看到的结果就是不准确的
   - 最终一致性: 经过一段时间后要求能访问到更新后的数据, 比如等一会 B 扣库存成功了则此时在去读是具有一致性的数据

### 21.数据一致性模型

1. 强一致性: **银行转账**

   - 完成更新, 后面的所有进程都应该读取到新的值
   - _对用户也是一种友好: 写了什么, 看到就还是什么_
   - 在 CAP 中时需要牺牲一致性的

2. 弱一致性: _dns 解析_

   - 完成更新后, 不承诺可以读取到新的值
   - 也不承诺多久之后才能读取到新的值
   - 需要一定的时间来达到数据一致性: 不一致性窗口

3. 最终一致性

   - 是弱一致性的一种特例
   - 强调所有的数据副本在经过一定时间的同步后, 最终都可以达到一致性的状态
   - 本质是需要系统自身保证最终数据能达到一致性, 不需要实时保证系统数据的强一致性
   - `不一致性窗口:` 受通信延迟 + 系统负载 + 节点数量等因素影响

4. 最终一致性通过其不同保证可以划分为

   - 因果一致性: `A 修改 a=1; B 修改 a++[基于 A 修改后的值]`
   - 读己之所写: `A 更新后必须 A 每次都读取到新的值` + `特殊的因果一致性`
   - 会话一致性: `同一个会话读取到最新值`
   - 单调读一致性: `如果一个进程从系统中读取出一个数据项的某个值后, 那么系统对于该进程后续的任何数据访问都不应该返回更旧的值`
   - 单调写一致性: `单调写一致性是指, 一个系统需要能够保证来自同一个进程的写操作被顺序地执行`

## 22.Quorum & Waro

1. Waro: CAP 强一致性的协议[kafka ack.all]

   - **副本控制协议**
   - 写操作时只有所有副本都写入成功才算写入成功
   - 优先保证读: 任何节点读到的数据都是最新的, 但是牺牲了服务的可用性
   - 只要有一个服务宕机了, 则写服务都不能成功
   - 但是只要好存活一个节点都可以提供读服务

2. Quorum

   - core: `10个副本, 一次成功更新3个则认为成功操作成功 + 那么如果想一定读取到最新的数据则最少需要读去8个节点`
   - 无法保证强一致性: 无法实现任何时刻任何节点都能读取到最新的数据
   - 需要配合一个获取最新成功提交的本版本号的 metadata 的服务, 这样可以确定最新成功提交的版本号, 进而判断读取的 8 个节点中哪个时最新的数据

## redis - project

## redis - redission

1. 使用 redission unlock 的时候需要注意

   ```java
   // IllegalMonitorStateException: attemp to unlock lock, not locked by currentId
   if(lock.isLocked() && lock.isHeldByCurrentThread()) {
     lock.unlock();
   }
   ```

2. redission 的源码 + 看门狗

## 缓存数据的一致性问题

1. 双写模式: `第二个线程写缓存先执行了导致`的不一致, 而且缓存有时不是淡出的数据[经过相关的逻辑结果、频繁呗修改但是没有使用(更新缓存是没有意义的)]

   ![avatar](/static/image/db/redis-data-consistency.png)

2. 失效模式: 先写数据库, 之后再删除缓存

   - `第三个执行查询写入 redis 快于第二个, 会导致多查数据库`
   - `1 删除结束, 3 进行数据库查询, 2 更新了数据库并删除了缓存, 3 开始写如redis, 此时的数据就不会死最新的[2操作后的数据时最新的]`

   ![avatar](/static/image/db/redis-data-consistency-v2.png)

   - solution1: 可以使用读写锁, 2 在写时, 3 读会被阻塞
   - solution2: 使用 BlockingQueue 进行排序

3. 失效模式: 先删除缓存, 之后再写数据库

   - issue: 删除换粗失败则数据就不对了 & 删除缓存之后写入数据库之前有查询则缓存旧的数据
   - solution3: 延时双删[先删除缓存, 在写数据库, 之后休眠一会才删除缓存]

4. **延时双删**: 一致性要求比较高, 但不是必须是适合采用

5. 解决方案

   - 如果时用户维度的数据(订单数据, 用户数据), 并发几率小, `缓存+过期时间+失效模式` 就可以了
   - 如果时菜单, 商品介绍等数据[可以长时间数据不一致]: `canal-binlog`
   - 要求一致性高的可以考虑加锁: `读写锁`
   - 遇到实时性一致性要求超高的, 应该直接查询数据库

## 使用场景: `缓存只保证最终一致性`

1. 即时性, 数据一致性要求不高: _物流信息_, _商品分类_
2. 访问量大, 但是更新频率不高的数据`[读多写少]`: _商品信息_
3. 遇到实时性一致性要求超高的, 应该直接查询数据库

## 缓存分类

1. 本地缓存

   - 比如存在 Map 中, 只适用于单体应用
   - 分布式下存在数据不一致问题

2. 分布式缓存

### 本地缓存锁

![avatar](/static/image/db/redis-standalone.png)

1. 确保以下 3 个动作是原子的, 二期是在锁住的方法内
   - query from redis cache
   - query database
   - put result to redis cache.-

### 分布式缓存锁

![avatar](/static/image/db/redis-distribute.png)

1. core: 在指定地方占一个位置, 占上位置就可以执行逻辑, 否则等待
2. 加锁[原子操作]: `SET K V NX EX`
3. 释放锁[原子操作]: `if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end` 返回值时 Long
4. 只能删除自己的锁, 业务逻辑时间长导致的 redis key 过期而引起的删除别人持有的锁: 可以适当的设置 redis key 过期时间长一点
5. processor

   ![avatar](/static/image/db/redis-distribute-v1.png)
   ![avatar](/static/image/db/redis-distribute-v2.png)
   ![avatar](/static/image/db/redis-distribute-v3.png)
   ![avatar](/static/image/db/redis-distribute-v4.png)

6. redission 也还是会出现主从同步锁丢失的问题:

   - Zookeeper 可以解决这个问题(CP)
   - 也可以使用 RedLock 向多个 redis 内加锁, 半数成功才认为加锁成功

7. 继续优化
   - 分段锁: 将库存分为多个阶段, 对每个阶段进行加锁减库存操作
   - 读写锁

### 分布式缓存框架 Redisson

1. Redisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格[In-Memory Data Grid]
2. 它不仅提供了一系列的分布式的 Java 常用对象, 还提供了许多分布式服务
   - BitSet
   - Set
   - Multimap
   - SortedSet
   - Map
   - List
   - Queue
   - BlockingQueue
   - Deque
   - BlockingDeque
   - Semaphore
   - Lock
   - AtomicLong
   - CountDownLatch
   - Publish / Subscribe
   - Bloom filter
   - Remote service
   - Spring cache
   - Executor service
   - Live Object service
   - Scheduler service
3. Redisson 提供了使用 Redis 的最简单和最便捷的方法
4. Redisson 的宗旨是促进使用者对 Redis 的关注分离[Separation of Concern], 从而让使用者能够将精力更集中地放在处理业务逻辑上
5. Redisson 实现类 JUC 的锁
6. 锁续期: 看门狗
7. 还是会出现主从同步锁丢失的问题

#### lock

1. redisson 获取锁时时阻塞等待, 而不是自旋
   - lock.lock(long leaseTime, TimeUnit unit): 不会自动续期, 过期之后就会被删除
2. redisson 获取分布式锁, 名字相同即为一把锁
3. redisson 不会出现死锁: 锁的过期时间默认为 30s
4. redisson 锁的自动续期: 看门狗
   - lock(-1, TimeUnit unit): 获取锁, 设置默认的时间哪位 30s, 并在占锁成功之后设置一个定时器对锁进行续期[30s/3=10s]
5. 最佳实战:
   - `lock(20, TimeUtil.SECONDS): 省下了续期操作, 手动解锁`

#### tryLock

1. 最大等待时间, 否则就放弃
   - boolean b = lock.tryLock(100, 10, TimeUnit.SECONDS): `最大等待100s, 最长持有时间 10s就释放锁`

#### FairLock: 公平锁

1. 有顺序的获取锁

   - RLock lock = redisson.getFairLock("anyLock")

#### 读写所: `经常读, 很少写`

1. 允许多个读锁和一个写锁处于加锁状态

   ```java
   RReadWriteLock rwlock = redisson.getReadWriteLock("rwlock");
   rwlock.readLock().lock();
   rwlock.writeLock().lock();
   ```

2. 读数据使用读锁, 写数据使用写锁

3. 读写锁也会自动续期, 但是可以读到最新的数据[修改期间会阻塞所有操作]
   - 写 + 读: 等待写锁释放
   - 写 + 写: 阻塞写
   - 读 + 写: 等待写锁释放
   - 读 + 读: 无锁, 只会记录所有的读锁, 都能加锁成功

#### 闭锁

1. demo: 等 5 个班都锁门, 才可以锁学校大门
2. getCountDownLatch Key 过期时间 -1
3. latch count 为 0, 最小值为 0
4. getCountDownLatch 会阻塞, 直到 count=0 时才执行

#### 信号量: 限流

1. demo: 停车场, 限流
2. park 过期时间为 -1
3. 当没有车位时, 停车动作会被阻塞, 直到有车离开[空出车位]
4. 车离开没有限制
5. 限流:

   - 信号量为 1000, 当线程来时取一个, 执行结束则返还, 1000 个信号量被取完则线程需要等待
   - code

     ```java
     boolean acquire = park.tryAcquire();
     if(acquire) {
        // buz logic
     } else {
        return "当前流量过大";
     }
     ```

---

## interview question v2

1. 什么是 redis

   - key-value 的 NoSQL 开源数据库
   - 高性能 + 高扩展 + 高稳定 + 集群
   - 多种数据结构[本质是计算向数据移动{server 有很多方法 | 与 memcache 的 string 比可以只取一些字段}] + 速度快
   - 内存 + 异步持久化 + string max 512m
   - 解决[分布式]缓存 + 锁 + 数据存储 + 解决方案

2. 如果设置了最大使用的内存, 则数据已有记录数达到内存限值后不能继续插入新值
3. redis 适用于的场景

   - 会话缓存: session + 分布式 + 持久化
   - 全页缓存: FPC
   - 队列: list & set
   - 排行榜/计数器/锁

4. 排行榜的实现问题

   - 数据修改之后会存数据库操作
   - 但是会维护 redis 的排行榜: 避免每次都去查询数据库
   - redis command

     ```shell
     # 1. 设置玩家分数: O(log(N))
     # zadd 排行榜名称 分数 玩家标识
     zadd lb 89 user1
     zadd lb 95 user2
     zadd lb 95 user3

     # 2. 查看玩家分数: O(1)
     # zscore 排行榜名称 玩家标识
     zscore lb user2

     # 3. 按名次查看排行榜: O(log(N)+M)
     # zrevrange 排行榜名称 起始位置 结束位置 [withscores]
     zrevrange lb 0 -1 withscores

     # 4. 查看玩家的排名: O(log(N))
     # zrevrank 排行榜名称 玩家标识
     zrevrank lb user3 #0

     # 5. 增减玩家分数: O(log(N)), 没有的话默认为0
     # zincrby 排行榜名称 分数增量 玩家标识
     zincrby lb 6 user4

     # 6. zrem: O(log(N))
     # zrem 排行榜名称 玩家标识
     zrem lb user4

     # 7. 删除排行榜
     del lb
     ```

5. CAS: 事务

   - 原子性: 不保证原子性[语法性错误会全体回滚{如参数个数}, 具体的指令错误不影响其他的{如 str+1}] 事务中的所有命令都将会被串行化的顺序执行, 不能加三
   - 事务数据的持久化: `当使用Append-Only模式时, Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃, 如电源故障导致的宕机, 那么此时也许只有部分数据被写入到磁盘, 而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测, 一旦发现类似问题, 就会立即退出并给出相应的错误提示`
   - WATCH+ CAS 可以实现 incr: `WATCH mykey val = GET mykey val = val + 1 MULTI SET mykey $val EXEC`

6. 假如 Redis 里面有 1 亿个 key, 其中有 10w 个 key 是以某个固定的已知的前缀开头的, 如果将它们全部找出来

   - keys reg: 单线程会 block 所有的 redis 操作
   - scan: 时间比他长, 但是被分散开了, 可能重复[需要去重]

7. Redis 做异步队列: `消息可能丢失`

   - 不能做到先放入队列之后再通知订阅者, 内存级别的消息很大的话会占内存
   - 一般使用 list 结构作为队列, rpush 生产消息, lpop 消费消息
   - 当 lpop 没有消息的时候, 要适当 sleep 一会再重试: blpop
   - 使用 pub/sub 主题订阅者模式, 可以实现 1:N 的消息队列
   - redis 如何实现延时队列:
     - 使用 sortedset, 拿时间戳作为 score,
     - 消息内容作为 key 调用 zadd 来生产消息, 消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理

8. Pipeline

   - 可以将多次 IO 往返的时间缩减为一次, 前提是 pipeline 执行的指令之间没有因果相关性。
   - 使用 redis-benchmark 进行压测的时候可以发现影响 redis 的 QPS 峰值的一个重要因素是 pipeline 批次指令的数目

9. 怎么保证 redis 中的数据是热点数据
   - key 的过期时间: 时间段 || 到指定时间
     - 写(包括重写)时除非指定过期时间, 否则就是-1
     - 访问是不会延长时间的
   - 缓存淘汰机制
