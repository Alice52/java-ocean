## redis

### 1.redis 的数据结构和使用场景

1. string: 计数[喜欢的文章数量/点赞数/临时存储位], 分布式锁[原子操作]
2. ~~hash: 存储大对象[少量属性变化], 购物车, 一般对象用 string + json 存储,对象中某些频繁变化的属性抽出来用 hash 存储~~

   ```java
   Map<string, Map<K, V>>
   // 1. hset     shopcart:uid productid count  新增商品
   //    hget     shopcart:uid productid
   // 2. hincrby  shopcart:uid productid count  商品 +1
   // 3. hdel     shopcart:uid productid        删除商品
   // 4. hlen     shopcart:uid                  商品总数
   // 5. hgetall  shopcart:uid                  所有商品
   ```

3. ~~list: 列表数据小空间存储, 公众号列表[别人发布文章就会 push 进我的 list]~~
   - 实现栈: LPUSH + LPOP
   - 实现队列: LPUSH + RPOP
   - BlockingQueue: BLPUSH + BRPOP
4. set: **抽奖[SRANDMEMBER/SPOP]**/微信的点赞[可见性 sinter]/推荐可能认识的人[sdiff]/社交的共同关注[sinter]
5. zset: 排行榜[不停的被刷新], 热搜
6. bit: 签到 [SETBIT key offset(512m) value/getbit, bitcount]

   - 一个以每天日期为 key, 每个 uid 为偏移量
   - 一个以用户 uid 为 key, 当天在一年中的索引为偏移量,

7. 类型相关的命令

   ```shell
   set age 12
   set name zack
   type age # string
   type name # string
   object encoding age # int
   object encoding name # embStr
   ```

### 2.redis 快的原因

1. 内存级别的存取
2. 单线程, 不需要线程切换
3. 多路复用 IO + 线程模型

   - I/O ：网络 I/O
   - 多路：多个 TCP 连接
   - 复用：共用一个线程或进程

4. 合理的数据结构
5. 数据编码: 根据字符串的长度及元素的个数适配不同的编码格式

### 12.redis 常见的数据结构

1. sds: c 的字符串+len 属性+free 属性

   - len: c 语言里面 `\0` 表示结束, 如果字符串里包含则会出现之后字符丢失的问题; sds 是根据 len 进行读取的, 因此二进制安全 + `获取长度时 O(1)的复杂度`
   - free: 内存预分配[不需要每次都重新分配空间], 空间预分配[len < 1M, 会多分配一个 len; len > 1M, 多分配 1m] + `惰性空间释放`
   - 最后会有 `\0` 为了兼容 c 的函数库
   - struct

     ```c#
     // redis 3.2
     struct sdshdp {
        int len;  // 空间有浪费
        int free; // 空间有浪费
        char bug[];
     };

     // redis 3.2 later
     len and free is less for less memory and with flag to mark[1byte] type
     ```

2. linkedlist: len + 双向无环链表, 具有 stack 和 queue 的特性
3. hashtable: 2 个 key-链地址法[单向链表], rehash 是渐进式的[服务的高可用]
4. skiplist: 在链表的基础上增加了多级索引来提升查找效率, zset + cluster node, zskiplist[hNode, tNode, len], zskiplistNode[1-32, 分可以相同, 对象不同], 取[分后对象大小]

   - 每一层都有一条有序的链表, 最底层的链表包含了所有的元素(O(logN))

5. intset: 不重复的中枢集合
6. ziplist: 压缩空间发明的数据结构, 所有的操作都是通过指针与解码出来的偏移量进行的. 并且压缩列表的内存是连续分配的, 遍历的速度很快. 多个 Node[1 个字节数据/1 个整数值]

---

7. 字符串对象 string：int 整数、embstr 编码的简单动态字符串、raw 简单动态字符串
8. 集合对象 set：intset、hashtable
9. 列表对象 list：ziplist、linkedlist
10. 有序集合对象 zset：ziplist、skiplist
11. 哈希对象 hash：ziplist、hashtable

### 3.redis 的持久化

### 4.redis 使用场景

1. 高并发/高性能/高可用
2. 减小 mysql 的压力, 快速的响应[内存界别的操作]
3. 超热的 key 就可以放到 redis 中:

### 5.redis 内存满了怎么办

1. 过期策略
   - [省内存耗性能]定时删除: 数据过期后马上就被删除, CPU 要时刻计算着过期的 key 压力过大
   - [耗内存省性能]惰性删除: 数据过期不处理, 等到下次使用的时候判断是否过期, 会导致有很多不被访问的 Key
   - 定期删除: 是对上两种的折中, 每隔一段时间执行一次删除, 限制删除操作的时长和频率减少删除操作对 CPU 的影响
     - 周期性轮询, 随机抽取[一部分 key], 利用占比控制删除频率
     - **检测频率时长可以自定义**, 内存压力也不大
     - 还是可能导致一些 key 到期不会被删除
     - 使用前还是需要看是否过期[惰性检查]
2. Redis 是使用了 惰性删除 + 定期删除

   - 定期删除: 定期扫描只会扫描设置了过期时间的键, 设置过期时间的 Key Redis 会单独存储
   - volatile 表示设置过期时间的 key
   - redis 会记录对象最后一次被应用程序访问的时间, 一个 key 到期了并不是马上就被删除

3. 缓存淘汰策略:
   - noeviction 满了之后会 set 操作会 OOM
   - 其他策略会删除 key 释放空间, 如果释放的空间不足则报错

### 6.缓存淘汰策略 6 + 2

1. noeviction
2. volatile-lru
3. **allkeys-lru**
4. volatile-lfu
5. allkeys-lfu
6. volatile-random
7. allkeys-random
8. volatile-ttl
9. LRU 是一种常用的页面置换算法: hash + 双向链表

### 7.常见的命令

### 8.事务: 分布式锁的解锁问题

### 9.常见的配置项

1. 可以通过配置文件配置 & 也可以通过 config 命令行配置
2. aof/rdb: aof-use-rdb-preamble no
3. memory
4. log
5. daeminize: docker
6. protected-mode + requirepass: auth
7. REPLICATION
   - cluster-enabled
   - cluster-config-file
   - cluster-node-timeout

### 10.高可用

1. sm
2. cluster
3. sentinel

### 11.分布式锁

1. 单机版在多线程下需要加锁
2. 微服务: 单机版锁值管自己的 JVM 层面的, 可能会导致 2 个服务买同一个商品
3. 分布式锁的注意点

   - 加锁的原子性: setnxex
   - 解锁的原子性: lua 或者 ~~redis 事务: watch + transaction+ multi+delete + unwatch~~
   - 解锁代码的一定执行 + ex
   - 解决业务超时问题锁续期问题 + 只能删除自己的锁
   - redis 集群时异同同步数据导致的 set 丢失问题: 自己手动修复数据

### 12.生产上 redis 内存陪多大, 怎么修改

1. maxmemory 不配置默认 64bit 使用最大内存
2. maxmemory 参数是字节
3. 查看: info memory / config maxmemory / 配置文件

### 13.常见的问题

1. 缓存穿透: 查询一个不存在的 Key, 缓存不能命中, 数据库也没有记录[无法缓存], 导致每次都要查数据库, `缓存失效`

   - 做严格的限制, 尽量过滤无效的请求
   - solution: 缓存 Null 且加`短暂的过期时间`[解决的是使用某个 key 的大量并发], 此时如果被攻击
   - [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

     1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
     2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

        ![avatar](/static/image/db/redis-bloom-filter.png)

     3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
        - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
     4. 判断的时候
        - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
        - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 则判断为可能存在

2. 缓存击穿: 某个 Key 是高频热点, 但是在大并发下下缓存过期了

   - solution: 加锁, 大并发下只让一个线程去查数据库, 其他人等待, 查到以后释放锁; 其他线程获取到锁, 先查询缓存
   - 数据预热

3. 缓存雪崩: 大量的 Key 的同时失效, 请求压力都转到了数据库, redis 挂了

   - solution: 在原有的失效时间上添加一个随机数以降低重复概率/永不失效
   - redis 高可用
   - 限流降级: 缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个 key 只允许一个线程查询数据和写缓存, 其他线程等待。

4. 可以考虑在业务层面上解决 12306

### 14. 海量数据下怎么快速查找一条记录

1. 使用布隆过滤器, 快速过滤不存在的数据[spring cache 中有笔记]
2. 在 redis 中建立数据缓存

   - 以普通的字符串存储(user-id -> user object) / 以 hash 存储(user-id k->v)`[会存在大量的 key]`
   - 使用一个 hash 存储所有的数据(user-info user-id->uo)`[key 是减少了, 一个 可以存 2^32-1 个键值对]`
   - 存在缓存穿透: 由于布隆过滤器的误判导致的
   - 存在缓存击穿: key 失效导致的, 可以使用锁机制[一个线程写缓存]

3. 查询优化
   - redis 数据是按槽位计算分配存储空间的
   - ~~自己实现槽位计算, 自己计算数据在那台机器上, 然后进行查找~~

#### 布隆过滤器: 基于概率的数据结构

1. 当布隆过滤器说某个值存在时,这个值可能不存在; 当它说不存在时, 那就肯定不存在
2. 特点

   - 一个非常大的二进制位数组(数组中只存在 0 和 1）
   - 拥有若干个哈希函数(Hash Function）
   - 在空间效率和查询效率都非常高
   - 布隆过滤器不会提供删除方法, 在代码维护上比较困难
     - 删除的话就需要在每个 bit 位上记录出现次数: 带有计数器的布隆过滤器会占用更大的空间

3. 要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:
   - 哈希函数的好坏
   - 存储空间大小
   - 哈希函数个数

#### [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

   ![avatar](/static/image/db/redis-bloom-filter.png)

3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
   - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
4. 判断的时候
   - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
   - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 则判断为可能存在

### 15.分布式缓存

1. 客户端缓存: 页面/浏览器缓存, APP 缓存, H5 缓存, Localstrage, session-storage
2. CDN 缓存: 内容存储, 数据存储, 内容分发[负载均衡]
3. nginx 缓存: 静态资源
4. 服务器缓存: 本地缓存, 外部缓存
5. 数据库缓存: 持久层缓存[mybatis 缓存], mysql 服务的缓存
6. 操作系统缓存: Page Cahce, Buffer Cache

### 16.渐进式 rehash 机制

1. redis 是通过 Dict 存储 K-V, 底层是 hashtable, 存放不同的 K-V, 但是存在 hash 冲突, 就会 rehash
2. 采取分而治之的方式, 将 rehash 键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上, 从而避免了集中式 rehash 而带来的庞大计算量

   ```c#
   typedef struct dict {
      dictType *type;         // 指向 dictType 结构的指针
      void *privdata;         // 保存了需要传给那些类型特定函数的可选参数
      dictht ht[2];           // 在字典内部, 维护了两张哈希表
                              // 一般情况下,  字典只使用 ht[0] 哈希表
                              // ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用
      long rehashidx;         // 记录了 rehash 目前的进度, -1标识不在 rehash
      unsigned long iterators; /* number of iterators currently running */
   } dict;

   // This is our hash table structure. Every dictionary has two of this as we
   // implement incremental rehashing, for the old to the new table.
   typedef struct dictht {
      dictEntry **table;         // 哈希表数组, 数组的每个项是dictEntry链表的头结点指针
      unsigned long size;        // 哈希表大小；在redis的实现中, size也是触发扩容的阈值
      unsigned long sizemask;    // 哈希表大小掩码, 用于计算索引值；总是等于 size-1 ；
      unsigned long used;        // 哈希表中保存的节点的数量
   } dictht;

   typedef struct dictEntry {
      void *key;                //键
      union {
         void *val;            //值
         uint64_t u64;
         int64_t s64;
         double d;
      } v;
      struct dictEntry *next; //指向下一个节点, 形成链表
   } dictEntry;
   ```

3. rehash 扩容

   - redis 中, 每次插入键值对时, 都会检查是否需要扩容。如果满足扩容条件, 则进行扩容
   - 在 redis 中 hash 表也是采用延迟初始化策略: 创建时没分配内存, 当第一次插入时才分配内存
   - rehash 条件: 则将哈希表大小扩容为原来的两倍
     - 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 1
     - 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 5

4. rehash 缩容

   - 条件:
     - 当哈希表的负载因子小于 0.1 时
     - 如果当前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 则不进行缩容
   - 缩容后的哈希表大小为当前哈希表中 key 数量的 2 的 n 次方, 最小容量为 4

5. 渐进式 rehash

   - 在 dict 层打开 rehash 的标志, 并分配新的 hashtable 内存
   - 操作辅助 rehash: 每一个增删改查命令中都会判断数据库字典中的哈希表是否正在进行渐进式 rehash, 如果是则帮助执行一次
   - 定时辅助 rehash: 服务器比较空闲, redis 数据库将很长时间内都一直使用两个哈希表, 有字典正在进行渐进式 rehash 操作, 则会花费 1 毫秒的时间, 帮助一起进行渐进式 rehash 操作

6. 小结

   - 在 redis 中, 扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面, 但是 rehash 动作并不是一次性、集中式地完成的, 而是分多次、渐进式地完成的: 服务器性能[集中式 rehash 而带来的庞大计算量]
   - rehash 步骤
     - 为 ht[1] 分配空间: 让字典同时持有 ht[0] 和 ht[1] 两个哈希表
     - rehashidx=0: 它的值设置为 0, 表示 rehash 工作正式开始
     - 在 rehash 进行期间, 每次对字典执行添加、删除、查找或者更新操作时, 程序除了执行指定的操作以外, 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] , 当 rehash 工作完成之后, 程序将 rehashidx 属性的值增一
     - 随着字典操作的不断执行, 最终在某个时间点上, ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1 , 表示 rehash 操作已完成, ht[1]变为 ht[0]
     - 因为在进行渐进式 rehash 的过程中, 字典会同时使用 ht[0] 和 ht[1] 两个哈希表, 所以在渐进式 rehash 进行期间, 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行[ 要在字典里面查找一个键的话, 程序会先在 ht[0] 里面进行查找, 如果没找到的话, 就会继续到 ht[1] 里面进行查找]
     - 在渐进式 rehash 执行期间, 新添加到字典的键值对一律会被保存到 ht[1] 里面, 而 ht[0] 则不再进行任何添加操作
   - 同时有两个 hash 表在使用, 会使得 redis 内存使用量瞬间突增: 在 Redis 满容状态下由于 Rehash 会导致大量 Key 驱逐

## redis - project

## redis - redission

1. 使用 redission unlock 的时候需要注意

   ```java
   // IllegalMonitorStateException: attemp to unlock lock, not locked by currentId
   if(lock.isLocked() && lock.isHeldByCurrentThread()) {
     lock.unlock();
   }
   ```

2. redission 的源码 + 看门狗

---

## interview question v2

1. 什么是 redis

   - key-value 的 NoSQL 开源数据库
   - 高性能 + 高扩展 + 高稳定 + 集群
   - 多种数据结构 + 速度快
   - 内存 + 异步持久化 + string max 512m
   - 解决[分布式]缓存 + 锁 + 数据存储 + 解决方案

2. 如果设置了最大使用的内存, 则数据已有记录数达到内存限值后不能继续插入新值
3. redis 适用于的场景

   - 会话缓存: session + 分布式 + 持久化
   - 全页缓存: FPC
   - 队列: list & set
   - 排行榜/计数器/锁

4. 排行榜的实现问题

   - 数据修改之后会存数据库操作
   - 但是会维护 redis 的排行榜: 避免每次都去查询数据库
   - redis command

     ```shell
     # 1. 设置玩家分数: O(log(N))
     # zadd 排行榜名称 分数 玩家标识
     zadd lb 89 user1
     zadd lb 95 user2
     zadd lb 95 user3

     # 2. 查看玩家分数: O(1)
     # zscore 排行榜名称 玩家标识
     zscore lb user2

     # 3. 按名次查看排行榜: O(log(N)+M)
     # zrevrange 排行榜名称 起始位置 结束位置 [withscores]
     zrevrange lb 0 -1 withscores

     # 4. 查看玩家的排名: O(log(N))
     # zrevrank 排行榜名称 玩家标识
     zrevrank lb user3 #0

     # 5. 增减玩家分数: O(log(N)), 没有的话默认为0
     # zincrby 排行榜名称 分数增量 玩家标识
     zincrby lb 6 user4

     # 6. zrem: O(log(N))
     # zrem 排行榜名称 玩家标识
     zrem lb user4

     # 7. 删除排行榜
     del lb
     ```

5. CAS: 事务

   - 原子性: 不保证原子性[语法性错误会全体回滚{如参数个数}, 具体的指令错误不影响其他的{如 str+1}] 事务中的所有命令都将会被串行化的顺序执行, 不能加三
   - 事务数据的持久化: `当使用Append-Only模式时, Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃, 如电源故障导致的宕机, 那么此时也许只有部分数据被写入到磁盘, 而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测, 一旦发现类似问题, 就会立即退出并给出相应的错误提示`
   - WATCH+ CAS 可以实现 incr: `WATCH mykey val = GET mykey val = val + 1 MULTI SET mykey $val EXEC`

6. 假如 Redis 里面有 1 亿个 key, 其中有 10w 个 key 是以某个固定的已知的前缀开头的, 如果将它们全部找出来

   - keys reg: 单线程会 block 所有的 redis 操作
   - scan: 时间比他长, 但是被分散开了, 可能重复[需要去重]

7. Redis 做异步队列: `消息可能丢失`

   - 一般使用 list 结构作为队列, rpush 生产消息, lpop 消费消息
   - 当 lpop 没有消息的时候, 要适当 sleep 一会再重试: blpop
   - 使用 pub/sub 主题订阅者模式, 可以实现 1:N 的消息队列
   - redis 如何实现延时队列:
     - 使用 sortedset, 拿时间戳作为 score,
     - 消息内容作为 key 调用 zadd 来生产消息, 消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理

8. Pipeline
   - 可以将多次 IO 往返的时间缩减为一次, 前提是 pipeline 执行的指令之间没有因果相关性。
   - 使用 redis-benchmark 进行压测的时候可以发现影响 redis 的 QPS 峰值的一个重要因素是 pipeline 批次指令的数目
